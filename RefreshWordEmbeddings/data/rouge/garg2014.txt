Three artificial intelligence (AI) methods for modeling output voltage of microbial fuel cell (MFC) system is discussed. AI models efficiently establish the relationship between output voltage and input factors of MFC. Out of three methods, MGGP evolves a model with better generalization ability. MGGP shows excellent potential to predict performance of MFC and can be used to gain better insights into MFC system.

0.185377 - In the present study, performance of microbial fuel cell (MFC) has been modeled using three potential artificial intelligence (AI) methods such as multi-gene genetic programming (MGGP), artificial neural network and support vector regression.
0.137337 - The effect of two input factors namely, temperature and ferrous sulfate concentrations on the output voltage were studied independently during two operating conditions (before and after start-up) using the three AI models.
0.086101 - The data is randomly divided into training and testing samples containing 80% and 20% sets respectively and then trained and tested by three AI models.
0.214523 - Based on the input factor, the proposed AI models predict output voltage of MFC at two operating conditions.
0.297747 - Out of three methods, the MGGP method not only evolve model with better generalization ability but also represents an explicit relationship between the output voltage and input factors of MFC.
0.279365 - The models generated by MGGP approach have shown an excellent potential to predict the performance of MFC and can be used to gain better insights into the performance of MFC.
0.089328 - Microbial fuel cell (MFC) is an electrochemical device that converts the chemical energy in organic wastes into electricity by means of catalytic activities (reactions) of living microorganisms (Wei, Yuan, Cui, Han, & Shen, 2012).
0.076336 - The phenomenon of generation of electricity from the contaminants in wastewater could provide environmental and economic benefits.
0.022409 - Researchers have conducted several studies on power generation from the organic wastes in water.
0.063872 - MFC technology has promising benefits but its practical implementation is limited due to low power generation, low energy efficiency as well as high material costs involved.
0.081274 - According to recent developments in microorganisms, electrodes, operating conditions, matrix, ionic strength, different substrates and electrochemical characteristics, it was found that both microorganism as well as a biological factors has a significant impact on the power generation and thus responsible for the successful implementation of MFC (Logan et al., 2006).
0.115942 - Researchers pointed out that number of factors influence the power generation in MFC.
0.065268 - One such factor is temperature which directly influences growth and reproduction of microorganism thus affecting intracellular and extracellular chemical process.
0.124390 - Experimental studies are often conducted to determine the effect of various factors that influence the performance of MFC.
0.117379 - The effect of temperature and anode media on the performance of MFC was studied by Min, Roman, and Angelidaki (2008).
0.037736 - The maximum power density estimated at temperatures 30 °C and 22 °C was found to be 70 mW/m2 and 43 mW/m2 respectively.
0.011594 - It was also noticed that at 15 °C, there was no power generation.
0.111116 - The reason for this behavior of MFC can be that the catalytic activity of microorganism could have become inactive at 15 °C.
0.119387 - Similar behavior of MFC was observed by Zhang and Shen (2006).
0.047597 - It can be observed from this study that the microbial activity became inactive at 50 °C.
0.108778 - Enhanced performance of the MFC is observed in the temperature range of 25–45 °C.
0.000000 - Wei et al.
0.122468 - (2012) studied the effect of temperature and hydraulic retention on the performance of a two-chambered MFC.
0.101365 - Their studies showed that the MFC exhibited a rapid start-up for high substrate concentrations and was able to generate maximum power for long period of time.
0.090162 - It is also important to note that though experiments can satisfactorily determine the influence of various factors on the performance characteristics of fuel cell, limitations exists on the factors of cost and time required to perform the experiments.
0.079841 - To overcome this limitation, several studies focused on developing mathematical models for estimating the performance of MFC (Choi, Jung, Kim, & Jung, 2003; Picioreanu, Katuri, van Loosdrecht, Head, & Scott, 2010; Pinto, Srinivasan, Manuel, & Tartakovsky, 2010; Pinto, Tartakovsky, & Srinivasan, 2012; Sousa & Gonzalez, 2005; Yao et al., 2004).
0.091043 - These mathematical models (Vijayaraghavan & Wong, 2013a; Wong & Vijayaraghavan, 2012b) prove to be an effective tool for investigating the influence of various factors on MFC performance in addition to being cost effective and less time consuming (Oliveira, Simões, Melo, & Pinto, 2013).
0.074866 - The mathematical models are generally formulated using differential and algebraic equations (Vijayaraghavan & Wong, 2013b; Wong & Vijayaraghavan, 2012a) and their derivation is based on the different phenomenon taking place inside the MFC.
0.143571 - Although, these models provide accurate prediction, the formulation of these models requires a thorough knowledge on the functionality and the configuration of the MFC system.
0.158978 - Application of soft computing methods such as genetic programming (GP), artificial intelligence (AI), fuzzy logic and neural networks can be used as an alternative method for modeling complex physical non-linear systems such as a fuel cell system.
0.110841 - These methods require input training data which can be obtained from the experimental data that is based on a specific design and operating condition of a fuel cell.
0.048583 - Based on the input, the soft computing method can then be able to generate meaningful solutions for complicated problems (Castelli, Vanneschi, & Silva 2013; Garg, Rachmawati & Tai, 2013a; Garg, Tai, Lee, & Savalani, 2013b; Nazari, 2012; Peteiro-Barral, Guijarro-Berdiñas, Pérez-Sánchez, & Fontenla-Romero, 2013).
0.045070 - Additionally, among the various soft computing methods described above, GP offers the advantage of a fast and cost-effective explicit formulation of a mathematical model based on multiple variables without any pre-definition of non-linear structure of the model (Al-Sahaf, Song, Neshatian, & Zhang, 2012; Giot, & Rosenberger, 2012; Kala, 2012; Kovacic & Brezocnik, 2003; Mabu, Hirasawa, Obayashi, & Kuremoto 2013; Mabu, Tjahjadi, & Hirasawa, 2012; Milfelner, Kopac, Cus, & Zuperl, 2005; Tsakonas, 2013; Tsakonas & Gabrys, 2012).
0.120363 - The analytical model hence obtained can then be used by fuel cell developers to optimize the performance of their fuel cell based on specific operating conditions.
0.126978 - It is to the best of authors’ knowledge that limited or no work exists on the application of soft computing methods on the performance prediction of an MFC system.
0.119658 - Hence, in the present study, the performance characteristics of a MFC is modeled using three soft computing techniques viz., multi-gene genetic programming (MGGP), support vector regression (SVR) and artificial neural network (ANN).
0.122772 - These methods are applied to model the operating voltage of MFC based on two input parameters (temperature and ferrous sulfate concentrations) at two operating conditions such as before start-up (BS) and after start-up (AS).
0.139100 - An explicit formulation is derived for the output voltage as a function of time and each input parameter (temperature and ferrous sulfate concentrations) for BS and AS operation of MFC.
0.141298 - Additionally, the performance of MGGP method to those of SVR and ANN has been compared.
0.080808 - The remainder of this paper is organized as follows.
0.104348 - In Section 2, the experimental details of the MFC are discussed in brief.
0.119452 - In Section 3, three AI methods namely the MGGP, SVR and ANN are discussed and applied to data collected in Section 2.
0.169735 - In Section 4, the performance of three AI methods is compared.
0.038835 - Finally, Section 5 concludes with the recommendations for future work.
0.122817 - Data collection from microbial fuel cell (MFC) The experimental data was collected from the literature and used to train and test different AI models (Wei et al., 2012).
0.090703 - The data obtained from the experiment comprise of two input parameters namely, temperature and ferrous sulfate concentrations and output parameter voltage.
0.036036 - The experimental description is provided as discussed in (Wei et al., 2012).
0.077480 - Experiments were performed on two-chambered MFC comprising of two plexiglass bottles, which served as an anode and a cathode, each with an operating volume of 1 L. The carbon paper (5 × 5 cm each), proton exchange membrane (PEM), adjustable resistor and data acquisition system (DAS) were used in the system.
0.107527 - In order to study the effects of different temperatures and ferrous sulfate concentrations on MFC performance, the experiments were divided into two series.
0.075534 - To explore the effect of different temperatures on MFC performance, the MFC was operated at five different temperatures of 40, 35, 25, 20, or 15 °C identified as MT1, MT2, MT3, MT4 and MT5, respectively.
0.079295 - To study the effect of ferrous sulfate concentrations on MFC performance, experiments were divided into four groups identified as MFe1, MFe2, MFe3 and MFe4 with ferrous sulfate at concentrations increment of 50, 100, 200 and 400 mg/L in anolyte respectively.
0.070175 - The MFC was operated in a batch mode.
0.074074 - Each experiment was repeated at least three times with all data reported as the average of replicate experiments.
0.068817 - The external resistance of the set was initially 99999.9 U and this was changed to 2000 U after 48 h of operation.
0.045977 - After the internal resistance test (the time period between 50 and75 h), the external resistance was changed to 1000 U and all tests were operated under this condition for 525 h (Wei et al., 2012).
0.126507 - Data preparation for training of the three AI models The voltage was measured as a function of time and each input parameter independently for before start-up (BS) as well as after start-up (AS) operating condition.
0.048048 - Table 1 shows the input parameter considered for the two operating conditions.
0.066472 - For measuring temperature effect on fuel cell performance, 95 and 60 data samples were obtained for BS and AS operating condition respectively.
0.066472 - For measuring concentration effect on fuel cell performance, 76 and 60 data samples were obtained for BS and AS operating condition respectively.
0.051780 - In this way we have four set of data samples.
0.108844 - For better training of models, each data set is divided randomly into training and testing data of 80% and 20% respectively.
0.121088 - In the following section, the AI methods are discussed and applied to this set of data.
0.000000 - Table 1.
0.024922 - Input parameter considered for each operating condition (Wei et al., 2012).
0.000000 - No.
0.007797 - Operating condition Input parameter Unit 1 BS Temperature °C 2 AS Temperature °C 3 BS Ferrous sulfate concentration mg/L 4 AS Ferrous sulfate concentration mg/L
0.082156 - Multi-gene genetic programming This section gives an overview of the theory and principle of the genetic programming (GP) method followed by discussion on the multi-gene genetic programming method (MGGP).
0.071247 - GP based on principle of Darwinian natural selection generates computer programs or models for solving regression problems.
0.084211 - The extension of genetic algorithms (GAs) is GP.
0.038095 - The only difference between GP and GA is that the solutions are represented by tree structures in GP while the solutions are represented in string form in GAs.
0.040580 - In brief, the GA is parameter optimization while GP is structural optimization method.
0.075055 - For proper selection of subset for training and testing, various performance evaluation methods such as Kennard-stone algorithm, cross validation methods etc.
0.045506 - can be applied.
0.096692 - The initial population of models/trees is randomly created by combining elements of function and terminal sets.
0.080997 - The elements of function and terminal set are chosen by user.
0.053476 - A function set F contains basic arithmetic operations (+, −, ×, /, etc), Boolean operators (AND, OR etc), or other operators whereas the terminal set T consists of numerical constants, input parameters of the process.
0.084142 - Each member of the initial population is a tree structure.
0.089239 - An example of a GP model represented by a tree structure is shown in Fig 1.
0.079093 - The performance of initial population is evaluated on the training data based on the fitness function.
0.075574 - The fitness function generally used is root mean square error (RMSE) given by (1) where Gi is the valued predicted of ith data sample by the GP model, Ai is the actual value of the ith data sample and N is the number of training samples.
0.040404 - GP model (11+cos(x))(10+y) Fig 1.
0.043956 - GP model (11 + cos(x))(10 + y).
0.055888 - If the termination criterion is not met, the members of the population are selected based on fitness function value for genetic operations resulting in new generation.
0.097377 - The termination criterion defined by the user can be the maximum number of generations and the threshold error of the GP model.
0.066225 - The genetic operations such as cross over, mutation and reproduction on the initial population of individuals form new set of population/generation.
0.070175 - The crossover operation (see Fig 2) generally used is sub-tree crossover in which a branch of tree is randomly selected from the two members and swapped.
0.044693 - The mutation operation in Fig 3 shows that the terminal or the functional node is selected at random from the tree and is mutated by the randomly generated tree.
0.012461 - The mutation operator plays an important role in avoiding local minima.
0.067146 - The iterative or the evolutionary process of forming new generations continues as long as the termination criterion is met.
0.096692 - The best model is selected based on minimum error on training data from entire set of generations.
0.000000 - Crossover operation in GP Fig 2.
0.000000 - Crossover operation in GP.
0.000000 - Mutation operation in GP Fig 3.
0.000000 - Mutation operation in GP.
0.081871 - Unlike traditional GP, each model participating in the evolutionary process is made of several set of trees/genes combined together in multi-gene genetic programming (MGGP) method.
0.118519 - The MGGP model formed is a weighted linear combination of output values from the number of trees/genes.
0.113208 - Fig 4 illustrates the formulation of the MGGP model that predicts output based on the two input decision variables such as x1 and x2.
0.115456 - The MGGP model comprises of nonlinear terms but is linear in parameters with respect to the coefficients Ko, K1, K2 and K3, which are estimated using least squares method.
0.102249 - To exert control over the complexity of the MGGP model, restrictions are imposed on the maximum depth of gene and maximum number of genes Gmax.
0.045351 - During the evolution, the genes are combined and deleted using a special crossover operator known as two-point high-level crossover.
0.081720 - Such type of crossover allows the exchange of individuals and is used in addition to the traditional crossover such as sub-tree crossover.
0.063768 - An example of two-point high-level crossover is shown by following example.
0.077921 - Suppose, the selected first parent consists of three genes (G1, G2, G3) and the second parent consist of five genes (G4, G5, G6,G7, G8).
0.042042 - Two points for crossover are randomly selected and the genes are exchanged.
0.020997 - The genes resulting from this crossover is as (G1, G6,G7, G3) (G4, G5, G2,G8).
0.067227 - The example shows that how the genes are inserted in both of the parents.
0.032129 - Genes can also be deleted.
0.052142 - Suppose if the resulting child has the number of genes more than Gmax, the genes are selected at random and deleted, until the maximum number of genes reaches Gmax.
0.036036 - In MGGP, standard sub-tree crossover is referred as low-level crossover.
0.049080 - In this operation, gene is chosen at random from the parent which replaces a gene is replaced by the chosen gene of the second parent.
0.060837 - For implementing mutation, six methods are available: (1) sub-tree mutation (2) mutation of constants using Gaussian function (3) Substitution and replacement of randomly selected nodes (4) assign randomly selected constant to zero (5) assign randomly selected constant to one (6) substitute randomly selected constant with another randomly generated constant.
0.075362 - The settings of probabilities of crossover and mutation are set by the user.
0.122977 - Formulation of MGGP model using least squares method Fig 4.
0.133333 - Formulation of MGGP model using least squares method.
0.103704 - Parameter settings of MGGP For the successful implementation of MGGP method, the parameters need to be properly adjusted.
0.102569 - The parameters selection influences the generalization ability of the formed GP models.
0.071578 - Trial-and-error approach is used to select the parameter settings and is shown in Table 2.
0.072250 - Basic arithmetic operators and some mathematical functions are chosen as elements for function set F. The broader set of functions is chosen in function set since this can provide broader variety of nonlinear mathematical models.
0.094276 - The parameter population size represents the number of models.
0.061069 - The number of generations set the number of genetic operations that an algorithm makes before it terminates.
0.081301 - The population size and number of generations fairly depends on the complexity of the problem.
0.062397 - Based on literature review by Garg and Tai (2012a), the population size and number of generations should not be high in case of large number of data samples to avoid the problem of over-fitting.
0.083832 - The maximum number of genes and maximum depth of the gene influences the size of search space and number of models to be searched in space.
0.068817 - Based on trial-and-error approach, the maximum number of genes and maximum depth of gene is kept at 8 and 6 respectively.
0.043360 - In this work, only two-point high level crossover and sub-tree mutation is used.
0.049887 - Based on Koza (1994), probabilities of crossover, mutation and reproduction are set at 0.85, 0.05 and 0.10 respectively.
0.000000 - Table 2.
0.050633 - Parameter settings for MGGP.
0.068071 - Parameters Values assigned Runs 20 Population size 200 Number of generations 100 Tournament size 2 Max depth of tree 6 Max genes 6 Functional set (F) (multiply, plus, minus, exp, tan, tanh, square, psqroot, plog, sin, cos) Terminal set (T) (x1, x2, x3, [-10 10]) Crossover probability rate 0.85 Reproduction probability rate 0.10 Mutation probability rate 0.05 The multigene genetic programming for the prediction of output voltage of MFC is implemented in MATLAB R2010b using software GPTIPS.
0.051282 - This software is a new “Genetic Programming and Symbolic Regression” code written based on Multigene GP for use with MATLAB.
0.078078 - MGGP method is applied to the data set collected in Section 2.
0.052569 - For measuring temperature effect on MFC voltage, the MGGP models for BS (MGGPBST, see Eq (2), where x1 and x2 are time and temperature respectively) and AS (MGGPAST, see Eq (3), where x1 and x2 are time and temperature respectively) operating condition are selected based on minimum RMSE on training data from all runs.
0.062975 - For measuring ferrous sulfate concentration effect on MFC voltage, the MGGP models for BS (MGGPBSC, see Eq (4), where x1 and x2 are time and concentration of ferrous sulfate respectively) and AS (MGGPASC, see Eq (5), where x1 and x2 are time and concentration of ferrous sulfate) operating condition are selected based on minimum RMSE on training data from all runs.
0.143156 - The performance of the four MGGP models on training and testing data is discussed in Section 4.
0.000000 - (2) (3) (4) (5) 3.2.
0.104632 - Support vector regression The artificial intelligence method well known for invoking generalization ability in models is support vector regression (SVR) (Byvatov & Schneider, 2003; Hua & Sun, 2001; Liu & Sun 2013).
0.096509 - The origin of SVR is support vector machines (SVM) which has been used to solve classification problems (Gupta, 2010).
0.026936 - SVM applied to regression problems is known as SVR.
0.064198 - Unlike regression analysis, SVR is not void of statistical assumptions such as model structure assumption, error dependency etc.
0.090090 - and formulates models based on the only data obtained from the system.
0.072072 - The framework of SVR is derived from structural risk minimization (SRM) principle.
0.058957 - SRM principle is modification of empirical risk minimization (ERM) principle and minimizes an upper bound on the expected risk (Vapnik, 1998).
0.040201 - The hyperspace function transforms the input decision space to the higher dimensional space h. It implies that the nonlinear regression problem is converted to a linear regression problem when the decision space is transformed.
0.068524 - Various hyperspace functions can be used for this transformation.
0.079840 - SVR model is formulated based on the training data , where xi the input is process input parameter and yi is the actual value of the process.
0.048048 - In present work, there are two input variables and one output variable.
0.049200 - The SVR model is given by (6) where the function is a space which has been converted into higher dimensional space, and The hyperspace function (see Eq (6)) is projected in the higher dimensional space h. The nonlinear regression model gets converted to a linear regression model in the higher dimensional space.
0.028777 - Based on data collected in Section 2, the kernel function chosen learns and minimizes the regularized risk function (L).
0.031596 - The parameters namely, support vector weight (j) and bias (d) are estimated that minimizes the function L. (7) Where The optimum balance between the weight vector norm and the approximation error is determined by the regularisation parameter (.
0.061069 - By increasing the value of regularisation parameter () or decreasing weight vector norm, the approximation error is decreased.
0.124079 - This may not ensure the high generalization ability of the model and can cause over-fitting of model.
0.074766 - The definition of ε -insensitive loss function ( is given in Eq (7).
0.069735 - If the predicted values of the model v(x) lies within the defined tolerance level ε, the loss function is zero and for the points outside ε, the loss function is the absolute of the difference between the values predicted by the model and tolerance level ε.
0.009070 - The points on the margin lines ( ) are called support vectors whereas those outside are known as error set (See Fig 5).
0.028070 - Loss function (L) and its parameters Fig 5.
0.030651 - Loss function (L) and its parameters.
0.043165 - Parameter settings of SVR The kernel function plays an important role in learning the hyperspace from the training data.
0.082111 - In this work, RBF kernel function is chosen since it is more compact and well known for its shorter training process and imparting high generalization ability to the model.
0.041995 - LS-SVM toolbox built for MATLAB is applied on the data set shown in Table 3.
0.064516 - Several applications of this toolbox (Garg et al., 2013b; Çaydaş & Ekici, 2012) in the field of production and chemical industry have been reported.
0.081720 - The parameters and of the radial basis function are determined using a combination of coupled simulated annealing (CSA) and a grid search method.
0.078212 - Firstly, the CSA determines the good initial values of and , and then these are passed to the grid search method which uses cross-validation to fine tune the parameters.
0.104712 - A SVR models for BS and AS operating conditions for measuring the effect of temperature and ferrous sulfate concentrations on MFC are formed with an optimal values and shown in Table 3.
0.127888 - The performance of the four SVR models on training and testing data is discussed in Section 4.
0.000000 - Table 3.
0.071197 - SVR Models for four operating conditions and their parameter values.
0.000000 - No.
0.037152 - Operating condition Model 1 Temperature effect (BST) on MFC Voltage during BS SVRBST 117.26 0.97 2 Temperature effect (AST) on MFC Voltage during AS SVRAST 346.02 0.34 3 Ferrous sulfate concentration effect (BSC) on MFC Voltage during BS SVRBSC 60.88 0.65 4 Ferrous sulfate concentration effect (ASC) on MFC Voltage during AS SVRASC 3.18 0.55 3.3.
0.082270 - Artificial neural network ANN possesses the ability to learn efficiently from the given data and for this reason it is used as modeling tools in number of applications (Belman-Flores et al 2013; Di Noia et al., 2013; Irani & Nasimi 2013; Maric 2013).
0.060002 - The network of ANN (see Fig 6) is made of three layers: an input layer which takes input variables, hidden layer having few neurons, output layer having one neuron which is same as number of output variable (Gou & Fyfe, 2004; Luong and Spedding, 1995; Xu, Zhang, & Wang, 2010; Çaydaş & Ekici, 2012).
0.083951 - Both hidden and output layer is composed of some number of neurons that utilize a specific nonlinear function.
0.086624 - The weighted links are used to connect neurons of one layer to the neurons of pre and after layer.
0.106443 - Each neuron of the hidden and output layer is offset by a threshold value.
0.037383 - The input variables multiplied by weights are sent to the neuron.
0.057554 - The neuron sums the weighted inputs and passes it to the non-linear transfer function and produces output Ypred.
0.062378 - (8) where wi is weight, xi is the ith input variable, A is nonlinear transfer or activation function and ∅ is the threshold or offset of the neuron.
0.059259 - The most frequently used activation function is sigmoid logistic function given by (9) Architecture of ANN Fig 6.
0.071111 - Architecture of ANN.
0.069999 - Back Propagation algorithm is used to train the network and compute the weights.
0.101010 - The computation of weights is iterative and consumes time.
0.080893 - The difference between the output value of network and actual value for a sample i is given by (10) where Ai and Mi are actual and predicted values for ith sample respectively and P is the number of neurons in the output of network.
0.062350 - The average error for the whole network is given by (11) where N is the total number of samples.
0.047962 - For minimizing Errorp, the weights are adjusted and updated during the training procedure until the threshold error is achieved.
0.081955 - The Levenberg- Marquardt algorithm that works on the principle of the second derivative is used to optimize the Errorp and update weights [38].
0.050697 - The simpler form of Hessian matrix is used and the algorithm iterates weights using the formulae: (12) where J is the Jacobian matrix that consists of the first derivatives of the network errors, e is a vector of network errors, μ is the learning rate and I is the identity matrix.
0.058957 - Parameter settings of ANN In this work, three-layer feed forward neural network is implemented in statistical software JMP Version 9.
0.056075 - The parameter settings used for ANN is shown in Table 4.
0.070640 - The optimal network of ANN is determined based on the minimum value of RMSE of the model on the training data set.
0.081425 - A trial-and-error approach is adopted to select the number of neurons in the hidden layers.
0.086022 - Fig 7 and Table 5 shows the optimum number of neurons selected for four ANN models based on minimum RMSE on training data.
0.133065 - The performance of the selected ANN models is discussed in Section 4.
0.000000 - Table 4.
0.017778 - Parameters for ANN.
0.043781 - Parameters Values assigned Training data set 80% Testing data set 20% Number of hidden layer 1 Number of neurons in hidden layer 2–9 Activation function Sigmoid Number of epochs 3000 Learning rate 0.70 Architecture selection Trial-and-error Target goal mean square error 10−5 Minimum performance gradient 10−5 ANN models for BS and AS operation having RMSE with different number of neurons Fig 7.
0.106443 - ANN models for BS and AS operation having RMSE with different number of neurons.
0.000000 - Table 5.
0.087227 - Optimum Number of neurons in hidden layer for four ANN models.
0.000000 - No.
0.051977 - Operating condition Model Optimum number of neurons in hidden layer 1 Temperature effect (BST) on MFC Voltage during BS ANNBST 7 2 Temperature effect (AST) on MFC Voltage during AS ANNAST 8 3 Ferrous sulfate concentration effect (BSC) on MFC Voltage during BS ANNBSC 9 4 Ferrous sulfate concentration effect (ASC) on MFC Voltage during AS ANNASC 7
0.131314 - Models for each AI method were formulated for measuring the effect of each input parameter (temperature and ferrous sulfate concentration) on MFC Voltage at two operating conditions (BS and AS).
0.108518 - Square of correlation coefficient (R) used to evaluate the performance of three AI methods MGGP, SVR and ANN is given by (13) where Mi and Ai are predicted and actual values respectively, Mi and are the average values of predicted and actual respectively, n is number of training samples.
0.081800 - The results obtained from the experimental studies and predicted by using MGGP, SVR and ANN models on training and testing data is shown in Figs.
0.000000 - 8–15 respectively.
0.098160 - The effect of each input parameter on MFC Voltage was studied as follows: Comparison between predicted values and experimental values on training data… Fig 8.
0.049383 - Comparison between predicted values and experimental values on training data for measuring temperature effect during BS operating condition.
0.057971 - Comparison between predicted values and experimental values on testing data for… Fig 9.
0.049383 - Comparison between predicted values and experimental values on testing data for measuring temperature effect during BS operating condition.
0.048048 - Comparison between predicted values and experimental values on training data… Fig 10.
0.049383 - Comparison between predicted values and experimental values on training data for measuring temperature effect during AS operating condition.
0.057971 - Comparison between predicted values and experimental values on testing data for… Fig 11.
0.049383 - Comparison between predicted values and experimental values on testing data for measuring temperature effect during AS operating condition.
0.048048 - Comparison between predicted values and experimental values on training data… Fig 12.
0.046620 - Comparison between predicted values and experimental values on training data for measuring ferrous sulfate concentration effect during BS operating condition.
0.057971 - Comparison between predicted values and experimental values on testing data for… Fig 13.
0.046620 - Comparison between predicted values and experimental values on testing data for measuring ferrous sulfate concentration effect during BS operating condition.
0.048048 - Comparison between predicted values and experimental values on training data… Fig 14.
0.046620 - Comparison between predicted values and experimental values on training data for measuring ferrous sulfate concentration effect during AS operating condition.
0.057971 - Comparison between predicted values and experimental values on testing data for… Fig 15.
0.046620 - Comparison between predicted values and experimental values on testing data for measuring ferrous sulfate concentration effect during AS operating condition.
0.072072 - Temperature effect on MFC voltage during BS and AS operating condition Figs.
0.144114 - 8–11 shows the performance of three models on training and testing data for measuring temperature effect on MFC voltage during BS and AS operation respectively.
0.079665 - For the BS start-up operation, the results obtained from the predicted models MGGP, SVR and ANN are very close to the experimental results.
0.109623 - The graph shown in Fig 8 indicates that all three methods have impressively well learned the non-linear relationship between the input and output process parameters with high correlation values.
0.110676 - The result of testing phase shown in Fig 9 indicates that the MGGP model has perform slightly better than those of SVR and ANN models with R2 value of 0.98.
0.060606 - Between SVR and ANN, both have shown comparable performance.
0.083885 - For the AS operation, the results obtained from the predicted models MGGP, SVR and ANN are very close to the experimental results.
0.109623 - The graph shown in Fig 10 indicates that all three methods have impressively well learned the non-linear relationship between the input and output process parameters with high correlation values.
0.110676 - The result of testing phase shown in Fig 11 indicates that the MGGP model has perform slightly better than those of SVR and ANN models with R2 value of 0.95.
0.080808 - Between SVR and ANN, SVR have shown better performance.
0.067227 - Ferrous sulfate concentration effect on MFC voltage during BS and AS operating condition Figs.
0.137508 - 12–15 shows the performance of three models on training and testing data for measuring Ferrous sulfate concentration effect on MFC voltage during BS and AS operation respectively.
0.083885 - For the BS operation, the results obtained from the predicted models MGGP, SVR and ANN are very close to the experimental results.
0.109623 - The graph shown in Fig 12 indicates that all three methods have impressively well learned the non-linear relationship between the input and output process parameters with high correlation values.
0.110676 - The result of testing phase shown in Fig 13 indicates that the MGGP model has perform slightly better than those of SVR and ANN models with R2 value of 0.98.
0.080808 - Between SVR and ANN, ANN has shown better performance.
0.083885 - For the AS operation, the results obtained from the predicted models MGGP, SVR and ANN are very close to the experimental results.
0.109623 - The graph shown in Fig 14 indicates that all three methods have impressively well learned the non-linear relationship between the input and output process parameters with high correlation values.
0.110676 - The result of testing phase shown in Fig 15 indicates that the MGGP model has perform slightly better than those of SVR and ANN models with R2 value of 0.83.
0.084142 - Between SVR and ANN, ANN has shown the better performance.
0.078103 - Temperature and ferrous sulfate concentration effect on MFC voltage for BS and AS operating condition for the best model The analysis conducted in Sections 4.1 and Sections 4.1 and 4.2 reveals that the MGGP model has outperformed the other two methods.
0.131586 - In this section, performance of the MGGP model is studied with respect to each operating condition.
0.000000 - Figs.
0.107784 - 16–19 shows the predicted values of MGGP models and actual values for range of temperature and ferrous sulfate concentration at BS and AS operations respectively.
0.051988 - It can be infer from the Figs.
0.153616 - 16–19 that the MGGP model has been able to capture the non-linearity and dynamics of the MFC system with the predicted values well in agreement with the experimental data.
0.194485 - Thus, it can be concluded that the MGGP method can be deployed as a powerful tool for modeling the voltage output of MFC.
0.057971 - Comparison between predicted values and experimental values on overall data for… Fig 16.
0.049383 - Comparison between predicted values and experimental values on overall data for measuring temperature effect during BS operating condition.
0.057971 - Comparison between predicted values and experimental values on overall data for… Fig 17.
0.046620 - Comparison between predicted values and experimental values on overall data for measuring ferrous sulfate concentration effect during BS operating condition.
0.057971 - Comparison between predicted values and experimental values on overall data for… Fig 18.
0.049383 - Comparison between predicted values and experimental values on overall data for measuring temperature effect during AS operating condition.
0.057971 - Comparison between predicted values and experimental values on overall data for… Fig 19.
0.046620 - Comparison between predicted values and experimental values on overall data for measuring ferrous sulfate concentration effect during AS operating condition.
0.119995 - The paper addresses the problems while modeling complex MFC systems using differential and algebraic equations.
0.206809 - To counter these issues, three AI models namely, MGGP, SVR and ANN were proposed for modeling the voltage parameter of MFC system during BS and AS operating condition.
0.119944 - The performance of these potential methods was compared.
0.154063 - The results conclude that the MGGP model have shown better generalization ability than those of SVR and ANN models.
0.080808 - Between SVR and ANN, ANN has shown better performance.
0.112164 - The estimated computational time for the implementation of MGGP is also relatively less when compared to other two AI methods.
0.120664 - Excellent statistical values of R2 of the MGGP model on training and testing data for two operating conditions reflects its higher generalization ability.
0.116576 - This peculiarity of the MGGP model is beneficial for chemical industry experts who are currently looking for high fidelity models that predict the MFC voltage under uncertain input process conditions.
0.114943 - MGGP method evolves models (see Eqs.
0.067227 - (2)–(5)) that represents the explicit formulation between the input and output process parameters.
0.153571 - The models can be used offline for prediction and can be further optimized to determine the optimum value of input process parameters that maximizes the output voltage (power generation).
0.134585 - By regulating the input factors such as temperature and ferrous sulfate using the MGGP model, MFC voltage i.e.
0.057082 - power generation can be estimated.
0.084132 - Thus, important economic factors such as time and cost for estimating voltage (power) generation using trial-and-error experiments can be reduced.
0.079254 - In the present work, it was observed that the complexity of the MGGP model have an impact on its accuracy.
0.065681 - The larger the size of the model (higher number of nodes of MGGP tree), the higher the accuracy but this may not always be true as it depends on the nature of the regression problem.
0.094488 - In the current work, we have found that MGGP models of small size have higher accuracy.
0.093827 - Therefore, the number of nodes cannot be defined as an appropriate measure of complexity of the MGGP models.
0.134616 - Future work to be done include the introduction of new complexity measures of MGGP models that can give better generalization ability on testing data.

[Frase 6] The models generated by MGGP approach have shown an excellent potential to predict the performance of MFC and can be used to gain better insights into the performance of MFC.
[Frase 1] In the present study, performance of microbial fuel cell (MFC) has been modeled using three potential artificial intelligence (AI) methods such as multi-gene genetic programming (MGGP), artificial neural network and support vector regression.
[Frase 30] Application of soft computing methods such as genetic programming (GP), artificial intelligence (AI), fuzzy logic and neural networks can be used as an alternative method for modeling complex physical non-linear systems such as a fuel cell system.
[Frase 273] Future work to be done include the introduction of new complexity measures of MGGP models that can give better generalization ability on testing data.
