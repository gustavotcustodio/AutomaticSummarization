A course timetabling system is implemented in the CLIPS language. Because the CLIPS inference is time consuming, the rules are inferred in parallel. Improper division of rules can result in a false conclusion or runtime errors. Two possible problems caused by improper rule division are identified. Three partitioning guidelines are then used to cope with these problems.

0.068510 - Course timetabling is a complex task that cannot be achieved using only a few general principles.
0.064561 - This work integrates expert systems and constraint programming to generate a novel artificial intelligence approach for a course timetabling system.
0.021858 - This approach can be easily reformulated and customized to sup-port requirement changes.
0.032787 - Furthermore, the difference between hard and soft constraints can be also addressed easily.
0.127287 - However, achieving a feasible timetable is very time consuming because the inference engine is CLIPS-based.
0.114650 - Notably, CLIPS is a rule-based language that relies on the repeated matching of facts with rules to generate conclusions.
0.117727 - To overcome the problem, this work parallelizes the execution of the timetabling system in emerging cluster systems.
0.077965 - However, scheduling courses in parallel without solving assignment conflicts is difficult.
0.095451 - To conquer the inherent serialization of the inference of course timetabling, courses are scheduled one by one and the schedule for one course is parallelized.
0.055202 - This work utilizes the inference process for scheduling one course that behaves similar to the nested if–then–else structure.
0.114283 - The rules for the inference process of scheduling one course are partitioned into multiple rule clusters, where each rule cluster is inferred by a slave process.
0.067797 - After receiving all feasible solutions generated by slave processes, the master decides which solution to adopt for a current course according to rule priorities.
0.267851 - However, improper division of rules can result in a false conclusion or runtime errors.
0.238807 - To ensure that a correct timetable is obtained, two possible problems caused by improper rule division are identified.
0.226074 - Three partitioning guidelines are then used to cope with these problems.
0.092105 - For implementation, this work applied a novel programming model that transmits facts in C and infers rules in CLIPS.
0.095900 - Experimental results demonstrate that the proposed parallel timetabling system achieves superlinear speedup when running in a cluster system.
0.104555 - The proposed method also helps parallelize CLIPS-based expert systems that have similar inference behavior to that in the course timetabling system.
0.088125 - The course timetabling problem is to allocate a set of courses into predetermined time slots (typically within one week), while satisfying a set of constraints.
0.054645 - This complex problem cannot be dealt with using only a few general principles.
0.019185 - To address this timetabling problem, most work has employed graph coloring (de Werra, 1997), integer programming (Daskalaki & Birbas, 2005), tabu search (Santos, Ochi, & Souza, 2005; Schaerf, 1999), genetic algorithms (Ueda, Ouchi, Takahashi, & Miyahara, 2004), neural networks (Carrasco & Pato, 2004), human-machine interactions (Mulvey, 1982), decision support systems (Dimopoulou & Miliotis, 2001; Foulds & Johnson, 2000), constraint programming (Deris, Omatu, & Ohta, 2000; Valouxis & Housos, 2003), or expert systems (Gunsdhi, Anand, & Yong, 1996; Isaai & Cassaigne, 2001).
0.085314 - A course timetabling system is implemented using a novel artificial intelligence approach that integrates expert systems and constraint programming (Lai, Wu, Hsueh, Huang, & Hwang, 2008).
0.043478 - The proposed approach has the following advantages.
0.088167 - (1) Timetabling systems are easily reformulated or customized to support changes, as the timetabling problem varies significantly from institution to institution in terms of specific requirements and constraints.
0.066163 - (2) One can easily capture knowledge and incorporate this knowledge into a timetabling system as expertise reduces the search space and fits the solution to the context.
0.034188 - (3) The difference between hard constraints and soft constraints can be addressed.
0.103134 - Although the proposed course timetabling system is superior to previous work, achieving a feasible solution is very time-consuming because the inference engine of the proposed expert system is C Language Integrated Production System (CLIPS)-based (CLIPS, 2009).
0.059406 - Unlike conventional algorithmic languages, such as C, Java, and Visual Basic, a CLIPS programmer does not have to give the exact details on how a problem will be solved.
0.070707 - Instead, the programmer only has to specify the goal and rules for handling various conditions.
0.073491 - The underlying mechanism of the inference engine implementation itself tries to satisfy the goal.
0.090668 - Because the key feature of expert systems is to solve problems for which no algorithms exist, CLIPS language is more suitable than any conventional algorithmic language for building expert systems.
0.075117 - To reduced execution time for CLIPS-based programs, this work parallelizes timetabling execution in emerging cluster systems.
0.050942 - A cluster system is a parallel and distributed processing system consisting of a collection of interconnected stand-alone computers working as a single, integrated computing resource (Buyya, 1999).
0.041152 - A computer node can be a single- or multi-processor system, such as Personal Computers (PCs), workstations, or Symmetric Multiprocessors (SMPs).
0.061712 - Nodes can exist in a single cabinet or be physically separated and connected via a Local Area Network (LAN).
0.047904 - Assisted by a cluster middleware and related software, an interconnected computer cluster can appear as a single system to users and applications.
0.046998 - Such a system is a much more cost-effective method than traditional expensive supercomputers for gaining similar features and benefits.
0.071038 - The advantages of cluster systems are low cost, high performance, configurability, and scalability.
0.052632 - Cluster systems are rapidly becoming standard platforms for high-performance computing, and a variety of clusters has been constructed.
0.147901 - The most significant challenge in parallelizing a course timetabling system is its inherent serialization of inference.
0.077965 - Scheduling courses in parallel without solving assignment conflicts is extremely difficult.
0.068732 - Therefore, rather than scheduling courses by a certain scheduling resource, this work schedules courses in a one-by-one manner and parallelizes the inference process of scheduling one course because the process has a behavior similar to that of the nested if–then–else structure.
0.149746 - The CLIPS rules are divided into multiple rule clusters for parallel inferences.
0.072993 - According to inference priority, one parallel inference result will be chosen for scheduling a current course.
0.204723 - However, an improper rule partition can result in a false conclusion, an infinite loop, or runtime errors.
0.086687 - Therefore, this work introduces three partitioning guidelines for dividing rules and designing safe CLIPS codes.
0.110981 - To execute a CLIPS application in parallel in a cluster system, the MPICH library is used for inter-processor communication.
0.050919 - However, CLIPS programs cannot be parallelized directly because CLIPS language does not support this feature.
0.100817 - Thus, this work modified the CLIPS inference engine by adding MPICH library functions because the inference engine is based on C language.
0.128625 - Furthermore, the facts from the CLIPS program are removed and added to a C file, leaving only rules in the original CLIPS program.
0.045351 - To integrate CLIPS data into the C file, the facts must be converted into the C data format.
0.070175 - During run time, the C-format facts are distributed to multiple processes to reduce execution time for making inferences.
0.062878 - After receiving the C-format facts, each slave process must convert the facts into CLIPS-format facts and insert these facts into the fact list in the inference engine.
0.040230 - Similarly, following inference, each slave process extracts the inference result from its inference engine, converts the inference result back into the C format, and sends the C-format inference result back to the master process.
0.115025 - This work implemented the proposed parallel timetabling system in a cluster system.
0.053571 - Experimental results demonstrate that the proposed parallel system achieves superlinear speedup.
0.100002 - For CLIPS-based expert systems that have an inference feature similar to that of course timetabling, these systems can be parallelized using the proposed method with a reasonable response time.
0.058824 - The remainder of this paper is organized as follows.
0.000000 - Section 2 introduces related work.
0.066070 - Section 3 presents the proposed course timetabling expert system.
0.088512 - Section 4 demonstrates how to parallelize the course timetabling system.
0.016260 - Section 5 gives experimental results.
0.016260 - Finally, Section 6 provides conclusions.
0.091168 - A wide variety of approaches to the timetabling problem have been proposed.
0.036745 - Monfroglio (1988) proposes a Prolog-based system that employs backtracking for finding feasible timetables.
0.067797 - The system decomposes and classifies constraints with respect to message passing and constraint ordering in order to minimize the backtracking and maximize the parallelism.
0.000000 - Deris et al.
0.078740 - (2000) propose a constraint-based reasoning algorithm to model and solve the timetabling problem.
0.075179 - The proposed system is implemented via an object-oriented approach, and can therefore be easily adapted to support changes.
0.074631 - In Valouxis and Housos (2003), operational research models and local search techniques are used to assist the constraint programming search process by effectively reducing the solution search space.
0.062992 - The authors propose a minimum cost matching algorithm to relax the constraint satisfaction model.
0.021390 - Constraint logic programming integrates logic programming and constraint solving so as to tackle combinatorial problems such as planning, scheduling, and resource allocation (Boizumault, Delon, & Peridy, 1996).
0.011905 - This combination helps to make constraint logic programs expressive and flexible.
0.000000 - Gunsdhi et al.
0.017544 - (1996) introduce an automated timetabler that combines a data model and a knowledge base, developed via object-oriented methodology.
0.038647 - Separating out the data, the knowledge, and the algorithms provides the flexibility to deal with changes, and the incorporation of human expertise helps to reduce the feasible solution search space.
0.063694 - Solotorevsky, Gudes, and Meisels (1994) develop a rule-based language, called RAPS, for specifying resource allocation problems and timetabling problems.
0.095238 - The language enables the specification of a problem in terms of resources, activities, allocation rules, and constraints, and thereby provides a convenient knowledge acquisition tool.
0.052083 - Dhar and Ranganathan (1990) propose the use of an expert system, called PROTEUS, for the allocation of teachers to courses, and compare it with integer programming techniques.
0.045198 - For predictive scheduling of passenger trains, Isaai and Cassaigne (2001) introduce a lookahead, constraint-based algorithm that is designed using an object-oriented approach.
0.079840 - In their approach, expert knowledge is used as a heuristic for finding practical solutions and is combined with the constraint-propagation technique.
0.073376 - CLIPS (C Language Integrated Production System) is a popular tool for building expert systems (CLIPS, 2009).
0.081964 - It consists of three components: facts, rules, and an inference engine, where the rules form the knowledge base.
0.089239 - To solve a problem, CLIPS must have data or information with which to reason.
0.061856 - Each chunk of information is called a fact.
0.127287 - CLIPS contains an inference engine which controls the execution of the rules in the knowledge base.
0.049887 - The basic strategy used is known as forward chaining; this leads naturally to bottom-up, data-driven reasoning.
0.136778 - The agenda is how CLIPS keeps track of which rules are to be executed next.
0.125683 - A rule is added to the agenda when all its conditions are satisfied.
0.082575 - The activated rule with the highest priority in the agenda will be selected and executed repeatedly until the agenda becomes empty.
0.067941 - To specify which rule should be matched before which rule, each rule is associated with a user-defined salience value.
0.063260 - A rule with a larger salience value implies it has higher priority of performing pattern matching.
0.101838 - Therefore, all the rules will be matched in the order specified by their salience values.
0.093502 - If all the conditions of a rule are satisfied, its actions, listed on the right hand side of the rule, will be fired.
0.082680 - The fired actions usually assert new facts into the knowledge base, resulting in that the inference engine will match the newly asserted facts with all rules for further inference.
0.099036 - Due to the characteristics of rule-based languages, CLIPS usually needs to take a very long time to complete an execution.
0.054645 - There has been some research done previously to improve the performance by parallelization.
0.058957 - Riley (1987) parallelized CLIPS on a FLEX 32 platform that is a large-grain shared-memory parallel computer.
0.072476 - He proposed to divide the whole set of rules into several subsets and to allocate these subsets to several processors.
0.045584 - Hall, Bennett, and Tello (1994) implemented the parallelization on Intel Hypercubes architecture.
0.080997 - The user interface is the same as the original CLIPS.
0.070500 - They only inserted some parallel calls and commands to make the CLIPS able to run on each node of the Hypercubes.
0.056338 - Furthermore, the parallel commands can insert or remove the facts into/from the memory of remote nodes.
0.031153 - Gagne and Garant (1994) combined CLIPS and distributed system architecture.
0.072464 - DAI-CLIPS is a distributed computational environment.
0.068536 - Each CLIPS in it is an active independent computational entity.
0.057971 - They can communicate with other CLIPS processes.
0.077381 - Also, they can create, modify, or delete the expertise of CLIPS.
0.047619 - Myers and Pohl (1994) parallelized CLIPS by PVM (Parallel Virtual Machine).
0.054983 - PVM is a library of C and FORTRAN.
0.013746 - It supports distributive computing on distributed UNIX systems.
0.078947 - They used the MPMD model to parallelize CLIPS, and made it able to run in heterogeneous distributive computing environments.
0.065476 - Another related work is about Jess, a Java version of CLIPS.
0.024922 - Petcu (2005) proposed parallel Jess for homogeneous cluster of workstations.
0.052288 - He used JPVM to parallelize an expert system application.
0.051643 - A wrapper was designed to allow the cooperation between several instances of Jess running on different computers.
0.048662 - The wrapper must be the same or slightly different for most of the available expert systems.
0.102956 - In our previous work, we have proposed two methods to parallelize the CLIPS-based expert systems.
0.027211 - Both of them adopt the SPMD (Single Program Multiple Data) programming model for easy maintenance (Wilkinson & Allen, 2005).
0.096663 - In the first method, we propose a Grid-enabled CLIPS language that is extended by using the interface of the External Function Definition provided by the CLIPS interpreter (Wu, Lai, & Chang, 2008a, 2008b).
0.075758 - In this way parallel syntax can be defined based on the original CLIPS programming style.
0.093418 - As a result, the proficient CLIPS programmers have no need to learn the C language to develop parallel expert systems.
0.042904 - They only need to learn the basic parallel programming knowledge and use the simple CLIPS-style parallel routines such as send, receive, and synchronization to develop parallel CLIPS applications.
0.094387 - The supported parallel syntaxes are simplified for the CLISP language by implementing various complicated message passing mechanisms with the MPICH Library in the interpreter.
0.036281 - The method only provides an essential parallelization framework; programmers still have to design parallel algorithms for their applications.
0.105912 - Even if we parallelize the course timetabling system by this method, we still have to address the same partitioning problems described in this paper.
0.099036 - In the second method, a dynamic load balancing programming model is proposed for the parallel CLIPS application (Wu, Lai, & Chang, 2009).
0.034188 - The programmers have no need to write any code for load balancing.
0.050019 - Instead, with our proposed directives, they only need to indicate (1) which facts can be executed in parallel, (2) which asserted facts should be sent back to the master, (3) what the slave process should do, and (4) what are the reduce operations after the master receives the returned facts.
0.068022 - Accordingly, the interpreter will assign the appropriate chunk of facts to each slave depending on the individual computing power, resulting in better load balancing.
0.063260 - Therefore, it is very easy for programmers to write parallel CLIPS applications with load balancing capacities.
0.105369 - Because the method is only applicable to the applications full of data parallelism, we cannot parallelize the course timetabling system by this method.
0.073555 - We proposed integrating expert systems and constraint programming to implement a course timetabling system (Lai et al., 2008).
0.076722 - Expert systems are utilized to incorporate knowledge into the timetabling system and to provide a reasoning capability for knowledge deduction.
0.055556 - The constraint hierarchy and the constraint network are utilized to capture hard and soft constraints and to reason about constraints by using constraint satisfaction and relaxation techniques.
0.072012 - We propose a 4-tier system framework to implement timetabling systems.
0.066131 - In the presentation tier, clients can manipulate data (e.g., courses, instructors, classrooms, preference time slots and exclusion time slots) via a browser.
0.038251 - The flow control tier receives requests from clients and controls the system flow.
0.058379 - In the business logic tier, the application software receives system messages from the web server and accesses the database in the DB server.
0.089286 - Scheduling rules and domain knowledge are incorporated into the knowledge base.
0.072476 - When scheduling starts, data stored in the DB server are translated into facts that are loaded into the working memory.
0.089147 - By matching facts and rules, the inference engine can make inferences that achieve a solution based on the scheduling rules and domain knowledge.
0.110685 - The results are stored in the database and are displayed in the web page.
0.075758 - The clients then decide to approve, adjust or reschedule according to the analysis of results.
0.076722 - Expert systems are utilized to incorporate knowledge into the timetabling system and to provide the reasoning capability for knowledge deduction.
0.069959 - CLIPS is a productive development and delivery expert system tool that provides a complete environment for the construction of expert systems.
0.081967 - The Web pages and the application software are implemented using JSP and Java.
0.095900 - We adopt JClips (Menken, 2009) to combine CLIPS with Java by embedding the CLIPS engine in Java applications.
0.064298 - In our previous work (Lai, 2007), we proposed a Knowledge Management through Knowledge Engineering (KMKE) approach to capturing knowledge Conceptual Graphs (CGs) and translating knowledge into CLIPS rules.
0.113710 - Both scheduling rules and domain knowledge are represented as CLIPS rules and are stored in the knowledge base.
0.079772 - A feasible solution can be inferred from these rules and existing facts.
0.109958 - The inference engine makes inferences by deciding which rules are satisfied by facts and then applies the satisfied rules.
0.063694 - Separating out the knowledge base, the facts, and the inference engine in expert systems provides greater flexibility in supporting changes.
0.078015 - Changes in requirements can be mapped to the modification of corresponding rules in the knowledge base, while changes in data can be mapped to the modification of facts.
0.063260 - When facts need to be changed, the clients can modify the database via a web page.
0.089688 - New data can then be translated automatically into CLIPS facts in the working memory.
0.095238 - On the other hand, knowledge engineers can add or modify the corresponding rules when the requirements are changed.
0.109453 - Furthermore, as the inference engine is independent of the actual rules and facts, it can remain unchanged while the rules and facts are changed.
0.073993 - Course timetabling can be formulated as a constraint satisfaction problem by (1) treating the time slots of courses as a set of variables, each of which must be instantiated in a particular domain and (2) considering constraints as predicates on variables.
0.065657 - A solution means a state in which the values of variables satisfy all predicates simultaneously.
0.027491 - Constraints can be classified as hard or soft.
0.059288 - A feasible solution to course timetabling should satisfy all hard constraints and as many soft constraints as possible.
0.026316 - We utilize a constraint hierarchy to capture hard and soft constraints and a constraint network to reason about constraints.
0.069959 - A constraint hierarchy (Kumar, 1992) can be established in terms of the strength (denoted as C0, …, Cn) associated with each constraint.
0.062678 - Constraints at the C0 level are the strongest and cannot be violated.
0.073643 - The remaining constraints are classified into different levels of strength (i.e., C1, …, Cn) and can be relaxed to attain a feasible solution.
0.030303 - This constraint hierarchy is useful for reasoning about constraints using constraint satisfaction and relaxation techniques.
0.062016 - A constraint network (Mackworth, 1977) can then be built level by level from the constraints at the top level of the hierarchy downwards.
0.045267 - A feasible solution is achieved when all top-level constraints and as many weak constraints as possible can be satisfied simultaneously.
0.113710 - We adopt the salience of rules (the priority of rules) in CLIPS to realize the strength of constraints.
0.084967 - Rules with higher salience are executed and satisfied first.
0.111525 - All scheduling constraints in the constraint hierarchy can be represented as CLIPS rules with salience.
0.086690 - The clients manipulate data via web pages, and the data stored in the Oracle DB server are translated into CLIPS facts.
0.105301 - The CLIPS inference engine can then make inferences that achieve a feasible solution for the constraint network automatically.
0.088353 - To construct the course timetabling expert system, the requirements of instructors and resources are translated into facts; expert knowledge, hard and soft constraints are converted into rules; and the inference can draw a feasible timetable according to the facts and rules, as shown in Fig 1.
0.087870 - The construction of the course timetabling expert system Fig 1.
0.097010 - The construction of the course timetabling expert system.
0.120261 - Although the proposed course timetabling expert system is applicable to any department by establishing scheduling rules, time before a feasible timetable is available is considerable because the inference engine is CLIPS-based.
0.089558 - Notably, CLIPS is not an algorithmic language; thus, no explicit algorithm is exists in a CLIPS program.
0.142268 - To reduce execution time, the course timetabling system is executed in parallel on the emerging cluster system.
0.057018 - Section 4.1 introduces the basic parallelization method and Section 4.2 further explains how to divide rules correctly.
0.089913 - Finally, Section 4.3 implements the parallel version of the course timetabling system on a cluster system.
0.094937 - Parallelization method The greatest challenge is inherent serialization of the inference on course timetabling.
0.041667 - Basically, courses must be scheduled on a one-by-one basis.
0.058379 - When scheduling a course, one has to determine whether the course satisfies all constraints and whether it conflicts with other courses already scheduled.
0.090278 - If the timetabling is parallelized by partitioning the inference according to a certain resource, such as a class or professor, the merging process remains a sequential procedure.
0.047619 - One has to determine whether the merged result satisfies all constraints.
0.090621 - For example, if the whole process of timetabling is divided according to classes, different class timetables can be scheduled independently and executed in parallel.
0.086996 - However, due to multiple class timetables are scheduled in parallel, more than one class timetable may require the same classroom or professor during the same time slot.
0.041237 - Therefore, the merging process has to solve conflicts.
0.071066 - Similarly, if a whole timetable is divided according to professor, two professors may have the same class for the same time slot, even though they teach different courses.
0.072779 - Regardless of which resource is used to divide the timetable, the problem of allocating the same resource to more than one timetable for the same time slot always exists.
0.027211 - To solve such conflicts, each timetable has must be compared with another timetable to determine whether conflicts exist.
0.075230 - However, since all scheduling results for timetables must be analyzed one by one, the merging process may generate a new performance bottleneck because the merging process must be executed sequentially by the CLIPS inference engine.
0.041237 - Therefore, timetabling must be parallelized using different method.
0.103578 - Instead of dividing the whole inference process according to a resource, courses are scheduled in a one-by-one manner and the inference process of scheduling one course is parallelized according to the following observation.
0.100963 - When a course, represented as a fact, is selected for inference, all rules will be matched with the course using a one-by-one method in the decreasing order of the salience value of rules.
0.077414 - If a course is scheduled in some time slots by a certain rule, the remaining rules with relatively lower priorities will not be inferred for this course; thus, another course will be selected for the next scheduling step, which again starts from the rule with the highest salience value.
0.075908 - For instance, we assume the inference process for scheduling one course consists of three rules, RA, RB and RC, and their salience values are 30, 20, and 10, respectively.
0.109991 - In the original sequential inference process, when a course can be scheduled by rule RA, whether rules RCB and RCC can be used to schedule the course is not tested.
0.085215 - However, if rule RA cannot be used for a course, rule RB will be inferred next for the same course.
0.068127 - Similarly, if the course can be scheduled using rule RB, rule RC will not be tested.
0.056338 - Thus, rule RC will be tested when RA and RB cannot be applied to schedule the course.
0.091552 - Basically, the inference behavior for scheduling one course is the same as the nested if–then–else structure in a conventional algorithmic language such as C and Java.
0.069959 - To parallelize the nested if–then–else-like inference process for scheduling one course, this work uses a novel parallelization method.
0.085763 - The rules for scheduling one course are divided into multiple prioritized rule clusters according to the salience value, where each rule cluster consists of multiple rules.
0.121305 - When a course is scheduled, all rule clusters are executed in parallel by slave processes and each reports whether it has obtained a feasible solution.
0.083592 - After the master process receives all scheduling results from slave processes, a course is scheduled according to the feasible solution returned from the rule cluster that has the highest priority among pieces with feasible solutions.
0.068376 - No complex merging phase is required when using the proposed parallelization method.
0.114041 - The following partitioning guideline is utilized to divide all the rules for scheduling one course into rule clusters.
0.047790 - Partitioning guideline 1.
0.089869 - Rules are sorted and divided according to their individual salience values.
0.046693 - If a rule Ri in one rule cluster RCA has a salience value exceeding that of a rule Rj in another rule cluster RCB, any rule in RCA must have a salience value exceeding that of any rule in RCB.
0.044118 - Similarly, if a rule Ri in one rule cluster RCA has a salience value smaller than that of a rule Rj in another rule cluster RCB, any rule in RCA must have a salience value smaller than that of any rule in RCB.
0.077859 - Any two rules that have the same salience value must belong to the same rule cluster.
0.046205 - For example, if six rules exist, R1, R2, R3, R4, R5 and R6, for scheduling one course, their salience values are 60, 50, 40, 30, 20 and 10, respectively.
0.061728 - When scheduling one course, R1 will be checked first to determine whether the course can be scheduled according to this rule.
0.027491 - If so, another course will then be scheduled.
0.029762 - However, if R1 cannot schedule the course, R2 will be tested.
0.140459 - The remaining rules are tested in a one-by-one manner using the same above process according to their inference priorities.
0.060135 - Generally, a rule Ri will be tested only when any rule Rj cannot be applied to schedule a course, where j < i.
0.094755 - To parallelize the inference, if we want to divide the six rules into three rule clusters, RCA, RCB and RCC, there are 10 possible partition results (Fig 2).
0.093458 - Ten possible partition results for the six rules Fig 2.
0.103093 - Ten possible partition results for the six rules.
0.000000 - Without loss generality, we assume RCA includes R1 and R2, RCB includes R3 and R4, and RCC includes R5 and R6.
0.126171 - To schedule one course, the three rule clusters will be executed in parallel.
0.098039 - Each rule cluster is inferred by a slave process.
0.035354 - Initially, the master process broadcasts all slaves for the course that will be scheduled next.
0.109958 - Next, each slave performs inference for the course by matching the course with the rules in its rule cluster.
0.074074 - Note that each rule cluster is inferred by an independent inference engine.
0.051282 - After inference, each slave process sends a message back to the master process, reporting whether it has found a solution for scheduling the current course.
0.061355 - Finally, the master process decides which solution will be adopted by selecting the solution inferred by the rule cluster that has the highest priority among all rule clusters with solutions.
0.050505 - Before scheduling the next course, the chosen solution must be asserted into each inference engine.
0.060606 - This is necessary because each inference engine must know which time slots have been allocated to the current course before it starts scheduling the next course.
0.000000 - We assume that only RCB and RCC have solutions (Fig 3).
0.042254 - Since RCB has a higher priority than RCC, solution SB will be adopted for the current course.
0.098039 - The parallel execution of three rule clusters Fig 3.
0.108696 - The parallel execution of three rule clusters.
0.098607 - Improper partitioning problems According to the proposed parallelization method described in the previous subsection, rules will be divided into several rule clusters according to the first partitioning guideline in the preceding subsection.
0.129045 - However, some restrictions must be applied to rule partitioning; otherwise, improper division may result in incorrect solutions, infinite loops or even runtime errors because of CLIPS properties.
0.034632 - Consider the following example.
0.051896 - A rule Rx has one action, Am, listed on its right hand side, where Am must be inferred by another rule Ry.
0.081635 - If all conditions of rule Rx are satisfied at run time, action Am will be asserted into the knowledge base for further inference.
0.098750 - The inference engine then uses Ry to infer Am.
0.074450 - However, if Rx is in rule cluster RCA, and Ry is in RCB, after division, action Am cannot be inferred because Ry is not in its rule cluster.
0.082295 - To cope with this problem, RCB should include Ry to ensure that Am can be inferred by Ry.
0.087719 - However, after inferring Am by Ry, the inference engine may require other rules not in RCB for further inference.
0.109175 - Thus, an increasing number of rules must be included in RCB to draw a conclusion by further inference.
0.089387 - That is, all rules in the inference chain must be included in the same rule cluster; this is what we call self-containment.
0.090469 - If this situation occurs, parts of the inference for scheduling one course will be executed concurrently on multiple rule clusters, resulting in poor or no performance improvement.
0.132703 - To cope with this problem, the following partitioning guideline is proposed.
0.047790 - Partitioning guideline 2.
0.058824 - Each rule cluster must satisfy the self-containment property.
0.075217 - Moreover, except rules consisting of only leaf actions, no rules can be replicated in multiple rule clusters, where a leaf action is an action that does not require other rules for further inference.
0.089286 - For example, a CLIPS program consists of five rules (Fig 4).
0.067633 - Two rules, rule-1 and rule-5, will assert fact-A into the knowledge base, such that rule-6 is needed for rule-1 and rule-5 for further inference.
0.042042 - Rule-3 will assert fact-1, such that both rule 1 and rule 2 are required for rule-3 for further inference, and rule-4 will assert fact-3, which requires rule-3.
0.075758 - Fig 5 shows the inference relationship between rules; each relationship is indicated by an arrow.
0.077098 - Generally, if rule A requires rule B for further inference, an arrow is drawn from A to B.
0.082305 - To satisfy the self-containment property, rule-1, rule-2, rule-3 and rule-6 are grouped into a rule cluster.
0.062992 - Similarly, rule-4, rule-5 and rule-6 are grouped into another rule cluster.
0.088302 - Notably, although rule-6 is replicated in these two rule clusters, the partition still follows the proposed partitioning guideline because rule-6 only has a leaf action, i.e., 〈action 6〉, which does not require other rules for further inference.
0.074766 - An example CLIPS program consisting of five rules Fig 4.
0.082474 - An example CLIPS program consisting of five rules.
0.101010 - The inference relation between rules and how they are partitioned into two rule… Fig 5.
0.104987 - The inference relation between rules and how they are partitioned into two rule clusters.
0.105286 - Another problem may occur when rules are divided improperly.
0.034632 - Consider the following example.
0.045455 - Three rules, R1, R2 and R3, have salience values of 100, 80 and 60, respectively.
0.064698 - All these rules infer facts of the same type, called Type t. Moreover, rule R3 will modify a fact of Type t, such that all Type t facts will be re-matched with the three rules.
0.012461 - Consequently, an inference loop exists among R1, R2 and R3.
0.064412 - That no possible ways to infer the current fact is common; thus, a scheduled fact must be removed or modified to find a way to re-schedule the current fact.
0.097202 - For example, in the course timetabling application, many possible ways exist for scheduling a course.
0.092001 - If all these rules fail to schedule a course, the rule with the lowest priority will remove a scheduled course to open up time slots.
0.115497 - After a scheduled course is removed, all rules are applied again to the current course as new time slots are available.
0.121184 - Notably, the three rules are not interdependent; thus, these rules are called parallel rules.
0.148121 - In the proposed parallelization method, these rules can be divided and then inferred in parallel.
0.100877 - If R3 and R1 are inserted into the same rule cluster, these two rules construct a new inference loop.
0.112539 - Consequently, the inference engine may draw a false conclusion or fall into an infinite inference loop because rule R2 is not considered.
0.126677 - A similar problem occurs when only R3 and R2 are in the same rule cluster.
0.114283 - Conversely, no problem occurs when R3 is in an independent rule cluster, regardless of whether R1 and R2 are in the same rule cluster or not.
0.151618 - Another possible problem-free method is to group these three rules in the same rule cluster.
0.068127 - However, if an inference loop has too many rules, the loop may become a performance bottleneck.
0.120523 - In the worst case, all rules in a CLIPS program, such as the course timetabling application, will construct a single inference loop.
0.037116 - Therefore, this work proposes another partitioning guideline.
0.047790 - Partitioning guideline 3.
0.073384 - If an inference loop has too many rules, the rule with the lowest priority in an inference loop should be in an independent rule cluster, and the other rules in the loop can be divided arbitrarily.
0.101190 - For example, a CLIPS program consists of three rules (Fig 6).
0.101254 - Apparently, these rules do not rely on one another for further inference and can be inferred in parallel utilizing the proposed parallelization method.
0.076538 - However, because the rule rule-none-matched will retract a fact of the type data, the knowledge base is modified and the inference engine will then re-match the fact, whose status field is enabled, with rule-1 and rule-2.
0.075601 - Thus, these three rules construct an inference loop.
0.111323 - According to the third partitioning guideline, two possible partitioning methods exist (Fig 7) because the rule-none-matched rule must be in an independent rule cluster.
0.122421 - In the first partitioning method, rule-1 and rule-2 are grouped into a single rule cluster.
0.122421 - In the second partitioning method, rule-1 and rule-2 are assigned to two different rule clusters.
0.087227 - An example CLIPS program consisting of three rules Fig 6.
0.096220 - An example CLIPS program consisting of three rules.
0.071429 - Two partitioning methods for the example CLIPS program (Fig Fig 7.
0.074766 - Two partitioning methods for the example CLIPS program (Fig 6).
0.105130 - Implementation To execute a CLIPS-based expert system in parallel in a cluster system, the application must be parallelized with MPICH library functions.
0.042752 - However, CLIPS language does not support this feature, i.e., one cannot utilize MPICH functions directly from a CLIPS program.
0.121655 - Therefore, this work modified the CLIPS inference engine to execute the CLIPS file in parallel because the inference engine is written in C language.
0.065728 - Moreover, the inference engine is coded using on the SPMD model (Wilkinson & Allen, 2005) for easy maintenance.
0.048611 - At runtime, each inference engine will be executed by an MPI process, and each inference engine will read a CLIPS file when building its own knowledge base.
0.101254 - To assign courses in a one-by-one manner and schedule one course in parallel, the proposed programming model is used (Fig 8).
0.075117 - A CLIPS file contains only rules and all processes read a CLIPS file when making an inference.
0.141828 - The facts are listed in a C file that is linked with the inference engine.
0.035714 - Therefore, the facts must be converted into the C-format data.
0.072562 - At run time, the data are distributed to multiple processes to reduce execution time when making an inference.
0.085989 - Additionally, these C-format data must be converted into the CLIPS format, and then inserted into the fact list in the inference engine.
0.082575 - Similarly, inference results must be extracted from the inference engine and sent back to the master process in the C format.
0.068536 - The programming model of parallel CLIPS program execution Fig 8.
0.075601 - The programming model of parallel CLIPS program execution.
0.127646 - The rules of the parallel expert system are divided into four rule clusters using the proposed partition guidelines.
0.074766 - Each rule cluster is saved as an independent CLIPS file.
0.098592 - At run time, four slave MPI processes are created for the inferences of these four rule clusters.
0.092896 - Each slave process is associated with a CLIPS file containing one rule cluster.
0.104313 - The master sends courses in a one-by-one manner to all slaves.
0.106446 - After receiving one course, each slave process schedules the course according to the rules listed in its associated CLIPS file.
0.070423 - As soon as scheduling is complete, each slave sends the inference result back to the master process.
0.071121 - Moreover, the facts in the knowledge base will be sent back to the master process.
0.057018 - The master then determines which scheduling result will be adopted for the current course after receiving all possible solutions.
0.071563 - The scheduling result from the slave that has the highest priority for all salves with a feasible solution is chosen for scheduling the course.
0.053459 - Before the master sends the next course to slaves for further inference, the master broadcasts the facts to all slaves that are returned from the chosen slave for the current course.
0.056497 - After receiving these facts, each slave replaces the knowledge base by these facts, assuring a consistent knowledge base exists before scheduling the next course.
0.062992 - The whole timetabling process is complete when no other courses need to be scheduled.
0.097951 - A course timetabling problem in the Department of Computer Science and Information Engineering at the National Changhua University of Education (NCUE) is used as an illustrative example to demonstrate our approach.
0.022792 - The department has 15 faculties, 6 classes, and more than 240 students.
0.050955 - The model was tested with real data comprising 45–50 subjects, a schedule of 40 time slots, and 8 classrooms.
0.063260 - Based on the requirements, several constraints can be identified that the course scheduling system must satisfy.
0.000000 - X1.
0.045351 - Instructors usually offer more than one course and these courses should not be scheduled at the same time.
0.000000 - X2.
0.068358 - A course should not be scheduled at the same time as another required course for the same class.
0.000000 - X3.
0.049180 - Only one course should be assigned to a classroom at any one time.
0.000000 - X4.
0.053571 - Only the available time slots for a classroom should be scheduled.
0.000000 - X5.
0.070778 - The number of students registered for a course should not exceed the seating capacity of the classroom.
0.000000 - X6.
0.056075 - The assignment of classrooms should meet the requirements of courses.
0.000000 - X7.
0.068376 - The scheduled times of courses should not fall within the exclusion sets.
0.000000 - X8.
0.070707 - The scheduled times of courses should fall within the preference sets as much as possible.
0.000000 - X9.
0.092841 - The lectures for a course should not be scheduled in consecutive time slots during the week.
0.000000 - X10.
0.043716 - The time slots assigned to an instructor should not exceed four per day.
0.000000 - X11.
0.068358 - A course should not be scheduled at the same time as another optional course for the same class.
0.078616 - Constraints can be further classified as hard or soft: the former have to be satisfied, while the latter are desirable but can be relaxed in order to achieve a feasible solution.
0.055556 - In our example, constraints X1–X7 are hard constraints and constraints X8–X11 are soft.
0.086499 - This work constructed a cluster consisting of four Intel PCs to evaluate the parallel course timetabling expert system.
0.058824 - Table 1 shows the configuration of the cluster system.
0.045752 - The MPICH2 library is utilized for inter-process communication.
0.000000 - Table 1.
0.043290 - The cluster system configuration.
0.043411 - Intel Pentium III PC × 6 CPU Intel Pentium III, Coppermine 1000 Mhz Memory 256 MB + 128 MB Swap 779,144 KB HD IDE 10 GB OS RedHat 9.0 Fig 9 compares the execution times of the sequential and parallel course timetabling expert systems.
0.057601 - The sequential version is executed in one PC in the cluster system, while the parallel version is executed on five PCs in the cluster system; one for the master process and four for slave processes.
0.050725 - The parallel version reduces execution time significantly.
0.067736 - The performance can be improved by a factor of 12.47, derived by dividing execution time of the sequential version by that of the parallel version.
0.089387 - The speedup is superlinear, i.e., the speedup is more than five when only five PCs are used to execute the parallel version.
0.074074 - The reason why one can obtain a superlinear speedup is as follows.
0.038251 - Total memory space of the cluster system exceeds than that of one PC.
0.083333 - Because CLIPS-based applications are memory-intensive programs, the parallel version can take advantage of this larger memory space.
0.024922 - Execution time comparison between sequential and parallel versions Fig 9.
0.027491 - Execution time comparison between sequential and parallel versions.
0.081639 - This work utilizes a novel parallel course timetabling expert system.
0.094285 - The course timetabling system is designed using the artificial intelligence approach, which integrates expert systems and constraint programming for implementation.
0.068358 - Expert systems are utilized to incorporate knowledge into the timetabling system and provide reasoning capability for knowledge deduction.
0.061033 - Separating the knowledge base, facts, and inference engine in expert systems achieves increased flexibility in supporting changes.
0.049911 - The constraint hierarchy and constraint network are utilized to capture hard and soft constraints and to reason about constraints using the constraint satisfaction and relaxation techniques.
0.189485 - The inference for course timetabling is implemented in CLIPS language.
0.151722 - To address the problem in that achieving a feasible timetable by CLIPS inference is time-consuming, this work proposes to parallelize the process of assigning one course in a cluster system.
0.076103 - To achieve this objective, one must overcome the significant challenge in that the inference on course timetabling has the inherent serialization nature.
0.093750 - This work parallelizes the inference process by using the feature in that the process of scheduling one course is similar to the nested if–then–else structure.
0.137714 - The courses are schedule in a one-by-one manner.
0.100104 - The rules of scheduling one course are divided into multiple rule clusters according to their individual salience values.
0.084967 - Each rule cluster is executed by a slave process.
0.057613 - The master process decides which returned solution to adopt for the current course after different solutions are returned from all slaves.
0.062484 - The adopted solution is the solution returned from the rule cluster that has the largest salience value among all rule clusters that have feasible solutions.
0.086961 - To divide rules into rule clusters, this work points out several possible problems that may occur when rules are divided improperly.
0.170794 - The three partitioning guidelines are proposed to address these problems.
0.093384 - The first partitioning guideline sorts and divides rules according to their salience values.
0.087824 - The salience values in one rule cluster are either all larger or all smaller than any salience value in another rule cluster.
0.084438 - The second partitioning guideline ensures that every rule cluster satisfies the self-containment property.
0.084512 - Furthermore, with the exception for rules consisting of only leaf actions, no rule can be replicated in multiple rule clusters, where a leaf action is an action that does not require other rules for further inference.
0.100259 - The third partitioning guideline is that the rule with the lowest priority in an inference loop should be in an independent rule cluster, and the other rules in the loop can be divided arbitrarily.
0.065728 - Finally, this work separates facts and rules into two types of files using a novel programming model.
0.167366 - Facts are processed and transmitted in the C language, and rules are inferred in CLIPS language.
0.137509 - Inter-process communication in a cluster system is achieved by incorporating the MPICH library into the CLIPS inference engine.
0.095900 - Experimental results demonstrate that the proposed parallel timetabling system achieves superlinear speedup when running in a cluster system.
0.091732 - Implementation experience and the proposed parallelization method are very useful when designing parallel CLIPS-based expert systems that have the execution feature similar to the course timetabling system.
0.103151 - That is, the inference process performs in a similar manner as the nested if–then–else structure in conventional algorithmic languages.
0.083990 - By parallel inference, CLIPS-based expert systems can provide a timely response for users.

[Frase 14] To ensure that a correct timetable is obtained, two possible problems caused by improper rule division are identified.
[Frase 15] Three partitioning guidelines are then used to cope with these problems.
[Frase 301] Therefore, this work modified the CLIPS inference engine to execute the CLIPS file in parallel because the inference engine is written in C language.
[Frase 2] This work integrates expert systems and constraint programming to generate a novel artificial intelligence approach for a course timetabling system.
[Frase 5] However, achieving a feasible timetable is very time consuming because the inference engine is CLIPS-based.
