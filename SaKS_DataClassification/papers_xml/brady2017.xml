<article>
  <title>An evolutionary algorithmic approach to determine the Nash equilibrium in a duopoly with nonlinearities and constraints</title>
  <abstract>
    <sentence>This paper presents an algorithmic approach to obtain the Nash equilibrium in a duopoly.</sentence>
    <sentence>Analytical solutions to duopolistic competition draw on principles of game theory and require simplifying assumptions such as symmetrical payoff functions, linear demand and linear cost.</sentence>
    <sentence>Such assumptions can reduce the practical use of duopolistic models.</sentence>
    <sentence>In contrast, we use an evolutionary algorithmic approach (EAA) to determine the Nash equilibrium values.</sentence>
    <sentence>This approach has the advantage that it can deal with and find optimum values for duopolistic competition modelled using non-linear functions.</sentence>
    <sentence>In the paper we gradually build up the competitive situation by considering non-linear demand functions, non-linear cost functions, production and environmental constraints, and production in discrete bands.</sentence>
    <sentence>We employ particle swarm optimization with composite particles (PSOCP), a variant of particle swarm optimization, as the evolutionary algorithm.</sentence>
    <sentence>Through the paper we explicitly demonstrate how EAA can solve games with constrained payoff functions that cannot be dealt with by traditional analytical methods.</sentence>
    <sentence>We solve several benchmark problems from the literature and compare the results obtained from EAA with those obtained analytically, demonstrating the resilience and rigor of our EAA solution approach.</sentence>
  </abstract>
  <keywords>
    <keyword>Nash equilibrium</keyword>
    <keyword>Evolutionary algorithm</keyword>
    <keyword>Swarm intelligence</keyword>
    <keyword>Constrained games</keyword>
    <keyword>Non-linear payoff functions</keyword>
    <keyword>Abbreviations</keyword>
    <keyword>NENash Equilibrium</keyword>
    <keyword>EAAEvolutionary Algorithmic Approach</keyword>
    <keyword>BRFBest Response Function</keyword>
    <keyword>PRPromising region</keyword>
    <keyword>PSOParticle Swarm Optimization</keyword>
    <keyword>PSOCPParticle Swarm Optimization with Composite Particles</keyword>
    <keyword>GBPGlobal Best Position</keyword>
    <keyword>LBPLocal Best Position</keyword>
  </keywords>
  <section name="Introduction">
    <sentence>The concept of Nash equilibrium (Nash, 1951) is central to the analysis of strategic interactions between different firms involved in non-cooperative games.</sentence>
    <sentence>Nash equilibrium (NE) is the stable state of a system involving competitive firms who try to optimize their personal pay off functions by employing a wide range of strategies.</sentence>
    <sentence>In other words, given the actions of other firms, no firm can improve its position by adopting a different strategy.</sentence>
    <sentence>In general, individual profit functions are considered as pay off functions.</sentence>
    <sentence>However, it can also be minimizing loss function, maximizing sales etc.</sentence>
    <sentence>For the purpose of better illustration of our approach we restrict ourselves to a duopoly case where two firms will be involved in the game and pay off functions are their individual profit functions.</sentence>
    <sentence>Each firm responds in the best possible way, given the strategies of their competitors.</sentence>
    <sentence>This yields a best response function (BRF) for each firm that is employed to determine its decision, taking into account the decisions made by rival firms.</sentence>
    <sentence>Analytically, the point of intersection of all the BRFs, each one corresponding to a firm competing in the market, is known as the Nash equilibrium (Nash, 1950).</sentence>
    <sentence>The traditional analytical approach of attaining Nash equilibrium involves two stages.</sentence>
    <sentence>The first stage is to determine mathematical expressions for BRF of each firm involved in the game by maximizing its corresponding pay off function using calculus principles.</sentence>
    <sentence>The second stage involves solving the system of best responses of all firms to attain NE.</sentence>
    <sentence>Hence in the analytical approach, we must differentiate up to second order in order to find out the BRF of each firm and solve the resulting cumbersome equations.</sentence>
    <sentence>This involves a mathematical obligation to check the continuity and differentiability of each pay off function up to its second order.</sentence>
    <sentence>Games that involve complicated pay off functions with sophisticated demand and cost functions require extensive mathematical skills to solve the differential equations which arise analytically (Agiza &amp; Elsadany, 2004; Daskalkis &amp; Goldberg, 2009; Fabrikant, Papadimitriou, &amp; Berkeley, 2004; Grant Schoenebeck, 2006;Maskin, 1986).</sentence>
    <sentence>This leads to the adoption of simplifying assumptions such as linearizing the non-linear functions or adopting symmetrical functions (Cheng, Reeves, Vorobeychik, &amp; Wellman, 2004) In addition, games are often solved with little consideration of constraints such as production capacity of each firm, production costs, and environmental obligations.</sentence>
    <sentence>A number of authors have used numerical or algorithmic approaches to solve for the Nash equilibrium (Konak, Kulturel-Konak, &amp; Snyder, 2015; Razi, Shahri, &amp; Kian, 2007; Wang, 2013).</sentence>
    <sentence>Zhang and Zhou (2012) have built supply chain network equilibrium models as non-linear problem formulations (Zhao &amp; Nagurney, 2008); they employed smooth Newton algorithm (Ma, 2011) for solving the non-linear games but struggled to prove the existence and uniqueness of the equilibrium.</sentence>
    <sentence>A three stage game theoretic linear and un-constrained supply chain model is built by Xiao, Jin, Chen, Shi, and Xie (2010); they employed a traditional analytical approach and carried out complex calculations to examine existence of Nash equilibrium.</sentence>
    <sentence>Chern, Chan, Teng, and Goyal (2014) have proposed a non-cooperative Nash equilibrium solution in a vendor buyer supply chain model that could capture delay in payments; though they presented an unconstrained mathematical model, they had to solve a system of partial differential equations to prove the existence of an equilibrium.</sentence>
    <sentence>In this paper we put forward an evolutionary algorithmic approach (EAA) to obtain the Nash equilibrium.</sentence>
    <sentence>An evolutionary algorithm is used to find the optimal value of a payoff function subject to a given set of constraints.</sentence>
    <sentence>Evolutionary algorithms work on the principle of random search technique in finding out the optimal value of the payoff function.</sentence>
    <sentence>Those random search techniques are iterative in nature and are not concerned with the nature and complexity of payoff function that is being maximized.</sentence>
    <sentence>Particle swarm optimization (PSO) provides a heuristic to determine the optimal value of a non-linear function (Kennedy &amp; Eberhart, 1995).</sentence>
    <sentence>It is a population-based heuristic drawing on swarm intelligence with origins in the study of bird flocking, fish schooling and other swarm-type behaviours found in the biological world.</sentence>
    <sentence>Several variants have been developed to tackle complex situations with improved speed of convergence and quality of solutions, avoiding local entrapment and premature convergence (Nezami, Bahrampour, &amp; Jamshidlou, 2013).</sentence>
    <sentence>These include a hybridized PSO back propagation algorithm (Zhang, Zhang, Lok, &amp; Lyu, 2007) and a modified PSO for adaptive equalization (Al-Awami, Zerguine, Cheded, Zidouri, &amp; Saif, 2011).</sentence>
    <sentence>Particle Swarm Optimization with Composite Particles (PSOCP) is the particular evolutionary algorithm employed in this paper (Liu, Yang, &amp; Wang, 2010).</sentence>
    <sentence>Its qualities are described in the algorithm description in Section 4.</sentence>
    <sentence>Use of PSO as an optimization heuristic is still relatively novel in the field of production economics (Nearchou, 2011) but has been applied to assembly line (Nearchou, 2011), inventory classification (Tsai &amp; Yeh, 2008) and combinatorial optimization problems (Kemmoé Tchomté &amp; Gourgand, 2009).</sentence>
    <sentence>We use our evolutionary algorithmic approach to solve a variety of duopoly problems.</sentence>
    <sentence>EAA can deal with nonlinearities, discreteness and constraints that would be intractable using analytical approaches.</sentence>
    <sentence>As we are using a meta heuristic in the solution procedure we initially arrive at very near optimal solutions and hence the approximate Nash equilibrium (Daskalkis &amp; Goldberg, 2009).</sentence>
    <sentence>We then improve this approximate solution to obtain a solution very close to the exact Nash equilibrium.</sentence>
    <sentence>The results from the PSOCP model are benchmarked against analytically derived solutions.</sentence>
    <sentence>The solutions for the Nash equilibria obtained from the EAA computational experiments deviate negligibly from the analytically derived solutions (less than 0.1 per cent).</sentence>
    <sentence>The paper is novel in that, to our knowledge, this is the first time that evolutionary algorithms have been used to solve for the Nash equilibrium in constrained nonlinear duopoly models.</sentence>
  </section>
  <section name="Model and problem description">
    <sentence>Let us consider that a homogenous commodity is being produced by n firms where the cost incurred to ith firm for producing qi units of good is Ci(qi), where Ci is an increasing function of qi.</sentence>
    <sentence>The price of the product being sold is determined by the demand for that good in the market and the total output of the market (Q).</sentence>
    <sentence>As we presume that quantity of production is equal to the demand, specifically if the total output of the market is Q then the market price is determined through the function P(Q) where P is called the “inverse demand function”.</sentence>
    <sentence>If each firm produces and sells qi units, total market output is given by (1) (1) The market price of that product is determined by the function P(Q).</sentence>
    <sentence>Then revenue of ith firm (Ri) is calculated from Eq (2) (2) We consider the profit function of each firm as its payoff function.</sentence>
    <sentence>So the profit function (πi) of ith firm is computed by deducting the total cost of production from the revenue it earns for qi units in (3) (3) The nature and complexity of the payoff function of each firm will be determined based on the level of complexity involved with the inverse demand function and cost function.</sentence>
    <sentence>So, we expand our formulation to more complex scenarios by adopting a tier wise increase in complexity from the all linear case to a more sophisticated duopoly game in subsequent Sections 2.1–2.4.</sentence>
    <sentence>Linear demand and linear cost function We start with a simple scenario by considering a Cournot model of a duopoly game with linear cost and payoff functions.</sentence>
    <sentence>Suppose we consider the linear inverse demand function as in (4) (4) where Q is as given in Eq (1) and r represents the market response.</sentence>
    <sentence>The cost function of each firm is given in (5) (5) where λ and ci are positive constants and Fi is a fixed cost incurred to the ith firm, and ci represents unit price of the commodity of the ith firm.</sentence>
    <sentence>So, based on these assumptions, payoff function of ith firm becomes (6) In case of duopoly, the payoff functions of the individual firms become (7) (7) 2.2.</sentence>
    <sentence>Non-linear demand function It is useful to consider non-linear market demand functions as these may better depict certain market situations.</sentence>
    <sentence>We adopt two standard scenarios from Martin (2002).</sentence>
    <sentence>They include exponential and hyperbolic demand functions.</sentence>
    <sentence>The generalized forms of both models are as shown in Eqs.</sentence>
    <sentence>(8) and (9) respectively (8) where αi, βi and γ are positive constants.</sentence>
    <sentence>The above function delineates the demand function as an exponentially decreasing function which may be more representative of certain markets.</sentence>
    <sentence>The other scenario represents demand as hyperbolic in (9) (9) where Ai, ki are positive constants.</sentence>
    <sentence>It is quite possible for markets to have sinusoidal payoff functions as presented in Razi et al.</sentence>
    <sentence>(2007).</sentence>
    <sentence>The nonlinearity in the payoff function may lead to multiple Nash equilibria.</sentence>
    <sentence>The payoff functions are defined as follows (10) (11) Thus through the above examples, we have considered a diversified range of scenarios with non-linear demand functions.</sentence>
    <sentence>However, it is also useful to consider non-linearity in the cost function.</sentence>
    <sentence>This we do in the next section.</sentence>
    <sentence>Non-linear cost function Though there exists different kinds of non-linearity in the cost function, we have adopted a standard form of non-linear cost function from Martin (2002) defined below, so that it takes care of both economies and diseconomies of scale of production (12) where ci, j ≥ 0,∀i and j.</sentence>
    <sentence>The payoff function with linear demand and non-linear cost is shown in Eq (13) below (13) Eqs.</sentence>
    <sentence>(14) and (15) represent the scenario having non-linearity in both demand and cost functions (14) (15) It is easy to observe that the non-linear cost function mentioned in (15) can also take care of cost function of linear nature by making all the coefficient terms except the first order term equal to zero.</sentence>
    <sentence>Constrained functions In this section we consider capacity limitations on the production quantities of each firm.</sentence>
    <sentence>It is quite possible to have a discrete natured cost function with respect to quantity of production because the unit cost of a product can be lesser for bulk production.</sentence>
    <sentence>Hence the cost function can also take the forms of linear, nonlinear and simultaneously both.</sentence>
    <sentence>This discrete natured cost function can be taken care of mathematically by subjecting our payoff function to the set of constraints derived from putting limits on the production quantity and discrete cost of production of a commodity.</sentence>
    <sentence>Suppose if the discrete cost function is split into k intervals as shown in Eq (18) and capacity of each firm is set as expressed in inequality (17), the generalized form of the model will be as given below (16) Subject to: (17) (18) (19) (20) where is production capacity of ith firm and inequality (17) ensures that the production quantity of each firm will be within its capacity.</sentence>
    <sentence>Eq (16) represents the fact that each individual firm tries to maximize its pay off within its feasible zone within the existing constraints frontier.</sentence>
    <sentence>Eq (18) allocates different costs for different ranges of production whose range is split into k intervals.</sentence>
    <sentence>The expression fk(qi) in Eq (19) can be regarded as an activating binary constant which enables the contribution of kth interval of the cost function if qi falls in the kth interval range.</sentence>
    <sentence>The expression is the cost function corresponding to kth interval of the split which can be both linear and non-linear.</sentence>
    <sentence>Though the cost of production depends on the quantity that the firm produces, Eq (20) allocates that particular cost corresponding to the production quantity.</sentence>
    <sentence>Another constraint that we introduce into the model is that of pollution limits.</sentence>
    <sentence>In fact, it is quite likely that different regulatory constraints exist to control the pollution level to ensure environmental protection from pollution prone commodities.</sentence>
    <sentence>Here we follow the concept of river basin pollution game (Haurie &amp; Krawczyk, 1997) with a numerical example given by Mathiesen (2008), where ith producer emits pollution api and maximum capacity bp that is allowed on aggregate pollution.</sentence>
    <sentence>That restriction can be mathematically represented as in Eqs.</sentence>
    <sentence>(21) and (22).</sentence>
    <sentence>Suppose there is a scenario in which the firms are located along a river and pollutants may be expelled into to the river, where they disperse.</sentence>
    <sentence>Emission ei is assumed to be proportional to production level.</sentence>
    <sentence>A regulatory authority monitors concentration of pollution at two downstream stations.</sentence>
    <sentence>If the decay and transportation coefficient of pollution from ith firm to control pollutant pth is denoted by upi, then the regulator's constraints can be portrayed as in (21) and (22) (21) (22) where bp, ei, upi, api are assumed to be positive.</sentence>
    <sentence>This constrained model can approximate a variety of situations by adjusting the values of parameters as required.</sentence>
    <sentence>Though all our constraints are linear in nature in fact, they can be of any forms like linear, non-linear or a combination of both.</sentence>
    <sentence>Now it is quite challenging to solve these kinds of scenarios.</sentence>
    <sentence>This brings us the usefulness of an EAA in solving these complex models efficiently.</sentence>
  </section>
  <section name="Solution methodology">
    <sentence>In this section, we proceed by giving a brief description about traditional analytical approach and EAA to determine the Nash equilibrium.</sentence>
    <sentence>The following illustrates the solution procedure: Definition 1 Given the strategy of other competing players in the game, optimal strategy or a best response of a particular firm is the strategy that maximizes its payoff function subject to existing constraints; Definition 2 The Best Response Function (BRF) can be defined as a function that takes the given strategies of competing players as an input and gives as an output the optimal strategy to be followed by it in order to maximize its payoff.</sentence>
    <sentence>Analytically, BRF of ith firm is an extrapolation of the optimal strategies for all firms across the range of strategies available in the game.</sentence>
    <sentence>Analytical approach The analytical approach is a two stage process.</sentence>
    <sentence>The first stage involves finding out the BRF of each firm by differentiating its payoff function with respect to its strategy and solving that first order derivative to get the zeroes of derivative function of each firm.</sentence>
    <sentence>Those zero functions have to be validated as its best response by checking the sign of double derivative.</sentence>
    <sentence>Second stage proceeds with solving the system of BRFs of the game to arrive at Nash equilibrium.</sentence>
    <sentence>The advantages of this approach are that it is simple to understand and gives the exact Nash equilibrium.</sentence>
    <sentence>However, the analytical approach cannot be employed if any part of the payoff function is either discontinuous or non-differentiable up to second order.</sentence>
    <sentence>With regard to constrained games, ensuring the existence of Nash equilibrium is a major concern.</sentence>
    <sentence>To do that, the convexity or concavity of the payoff function of each firm has to be figured out before we find the Nash equilibrium.</sentence>
    <sentence>Based on the nature of the solution space, there exist techniques to find out the solution in limited cases but these are complex and mathematically rigorous.</sentence>
    <sentence>Evolutionary algorithmic approach Unlike the analytical approach, EAA does not literally find the mathematical expressions of BRFs of each firm to find out Nash equilibrium; rather it uses a graphical approach to do the same.</sentence>
    <sentence>Broadly the technical framework of EAA consists of two stages.</sentence>
    <sentence>The first stage involves drawing the plots of BRFs of each firm using the evolutionary algorithm.</sentence>
    <sentence>The second stage involves the finding of intersection points of the system of BRF plots to give the Nash equilibrium.</sentence>
    <sentence>Based on the beforehand approximate strategies of different players involved in the game, a wide range is defined that could cover all the strategy sets of every firm.</sentence>
    <sentence>To draw the BRF of a particular firm, the strategies of the remaining competing firms are fixed at Np number of different strategic points across the defined wide range.</sentence>
    <sentence>Then the best response of that particular firm at each point of the Np points is determined using the evolutionary algorithm.</sentence>
    <sentence>The EAA takes the strategies of competing firms at each point as input and gives the best response of corresponding firm finding maximum of its payoff function.</sentence>
    <sentence>The set of all the best responses with respect to its competing firms are plotted at the Np different points across the wide range.</sentence>
    <sentence>By extrapolating all the optimal points we get the BRF of that particular firm.</sentence>
    <sentence>We repeat this procedure to determine the best reaction functions of the remaining firms.</sentence>
    <sentence>The intersection point of all the BRFs will turn out to be our required NE of the game.</sentence>
    <sentence>As the concept of extrapolation is used in the process of finding out Nash equilibrium, it is important to have a sufficient number of points for drawing out the plot of BRF of each firm.</sentence>
    <sentence>However, to reduce the time of computation in the whole search for Nash equilibrium in the strategy space, a two tier search is employed.</sentence>
    <sentence>The first tier involves finding out the approximate vicinity of Nash equilibrium in a wide range with a smaller number (Np&lt; 10) of points for extrapolation.</sentence>
    <sentence>Once the promising vicinity is established from this wide range search, a more detailed search is carried out in the promising region around Nash equilibrium.</sentence>
    <sentence>To determine the promising space for exclusive search, the Self-Adaptive Range (SAR) technique is employed.</sentence>
    <sentence>Though the SAR technique is empirical in nature, experimental results show that SAR enables us to move very close to the exact equilibrium with less time and complexity of computation.</sentence>
    <sentence>The overall design of EAA is represented in the form of pseudo code in Table 1.</sentence>
    <sentence>Table 1.</sentence>
    <sentence>Pseudo code for proposed EAA.</sentence>
    <sentence>Step 1: Define parameters of the algorithm and pay off functions of each firm and respective constraints.</sentence>
    <sentence>Step 2: Define the wide range and the number of points (Np) (usually around 5 to 10) for plotting each BRF.</sentence>
    <sentence>Step 3: Compute the incremental step accordingly based on step 2 Step 4: for i = 1: all firms • Initialize the strategies all firms (generally all set to zeroes) for j = 1: (Np) o Optimize the payoff of ith firm using evolutionary algorithm and find its optimal strategy o Plot the optimal strategy versus current strategy of other firms o Increase the strategy of other firms by amount equal to incremental step (IS) end for • Extrapolate Np optimal points of ith firm to get its BRF.</sentence>
    <sentence>end for Step 5: Determine the approximate Nash equilibrium (NElr) by finding intersection of all the BRFs.</sentence>
    <sentence>Step 6: Compute the Promising Range using SAR technique Step 7: Update Np to larger value (more than 20) based on required accuracy in NE Step 8: With Promising Range and updated Np repeat steps 3, 4 and 5 to arrive close to accurate Nash equilibrium *BRF → Best response function A number of other authors have used evolutionary algorithms in finding the Nash equilibrium (Rajabioun &amp; Lucas, 2008; Razi et al., 2007).</sentence>
    <sentence>Both of these papers adopted very similar approaches: they initialize a random population of solutions and update the solutions iteratively to see if payoff function of any player in the game improves.</sentence>
    <sentence>This iterative procedure continues until they find no change in the payoff function of all the players.</sentence>
    <sentence>However, there always exists a threat here that the algorithm does not converge if Nash equilibrium does not exist.</sentence>
    <sentence>Also, it is quite difficult to find multiple Nash equilibria.</sentence>
    <sentence>And, in the case of constrained games convergence becomes doubtful.</sentence>
    <sentence>The EAA proposed in this paper can address those issues in an easy manner as we actually find the geometrical best response functions of each player that can be used to see the trend and existence of Nash equilibria.</sentence>
    <sentence>Self adapting range (SAR) technique Based on the equilibrium that we get in the first wide range search, we estimate an upper boundary (UB) of the promising range of equilibrium using Eq (23) and carry out a rigorous search by plotting BRFs with a larger number of points in the promising region to arrive at a point very close to the true Nash equilibrium (23) where NEwr is the set of Nash equilibria obtained during initial wide range search i.e.</sentence>
    <sentence>and η is the least positive integer that satisfies the inequalities mentioned in Eq (24) (24) and where μ is a positive rational number less than one.</sentence>
    <sentence>The constant μ can be termed as the tolerance random number that regulates the extra precision around the true Nash equilibrium in which we conduct the detailed search.</sentence>
    <sentence>Through rigorous simulation, it was ascertained that μ should be set at values between 0.4 and 0.7 to obtain good results.</sentence>
    <sentence>If multiple Nash equilibria are found to exist during the wide range search, the upper bound of the promising region is set at the maximum value of strategies involved in the multiple Nash equilibria with extra precision around it using Eqs.</sentence>
    <sentence>(23) and (24).</sentence>
    <sentence>In general, most of the production firms will have non-negative amounts of production units so the lower bound of the promising region is assumed to be equal to zero.</sentence>
    <sentence>To relax this assumption and model games with negative values one can build equations similar to Eqs.</sentence>
    <sentence>(23) and (24) and solve.</sentence>
    <sentence>Once the promising range is determined, incremental steps are used to split the promising range and construct Np different strategic points.</sentence>
    <sentence>Exploring the promising range with incremental steps ensures uniformity in the search, which facilitates in building up a reliable BRF of each firm (25) During exhaustive search in the promising region, the number of points (Np) considered to plot a BRF is to be defined based on the complexity and sensitivity involved in the problem.</sentence>
    <sentence>In general, results show that keeping Np more than 20 gives us acceptable solutions.</sentence>
    <sentence>To illustrate the computational experiments presented in Section 5, we kept Np = 20.</sentence>
    <sentence>If the game is sensitive to the precision involved in the values of Nash equilibrium, we can increase Np and compress the promising range near the Nash equilibrium to conduct the search exhaustively around the true Nash equilibrium.</sentence>
    <sentence>The same applies even if there exist multiple Nash equilibria.</sentence>
  </section>
  <section name="Technical description of PSOCP algorithm">
    <sentence>This section provides the fundamental technical blocks that build up the PSOCP algorithm that is used as evolutionary algorithm for finding the Np number of best response points of each firm across the range of strategies available for the other competing firms.</sentence>
    <sentence>Those best response points are joined to get the BRF of corresponding firm.</sentence>
    <sentence>The best response is the strategy that maximizes the payoff function of the firm given the strategies of competing firms.</sentence>
    <sentence>Evolutionary algorithms find the optima of a payoff function using random search techniques in an iterative manner.</sentence>
    <sentence>Particle swarm optimization is one such algorithm.</sentence>
    <sentence>PSO tracks the optimal value with randomly generated solution vectors known as particles.</sentence>
    <sentence>The number of swarm particles that participate in the search is called the swarm size (m).</sentence>
    <sentence>The dimension (d) or length of each particle in the swarm is generally equal to the number of variables involved in the payoff function.</sentence>
    <sentence>In Cournot games, payoff function of a firm is just a function of its production quantity or strategy.</sentence>
    <sentence>So the dimension (d) of each particle is one.</sentence>
    <sentence>Each particle will be passed into the payoff function to get the value of payoff known as fitness value in artificial intelligence literature.</sentence>
    <sentence>So, the swarm is simply a m × d matrix.</sentence>
    <sentence>The mechanism of tracking the optima of payoff function involves mathematical operations on the swarm.</sentence>
    <sentence>The swarm particles reach the vicinity of optimal value of a payoff function by effective exchange of information.</sentence>
    <sentence>To begin the search a set of m swarm particles are randomly generated to cover the whole search space.</sentence>
    <sentence>Then mutual exchange of information takes place among the particles participating in the search regarding which particle has the best fitness value.</sentence>
    <sentence>The particle with the best fitness value out of the total swarm is called the global best position (GBP).</sentence>
    <sentence>Suppose that the kth particle out of m particles has got the best fitness position; then the remaining particles try to move towards the kth particle in an iterative manner.</sentence>
    <sentence>Exchange of information takes place among the swarm: during the movement some other particle may come across better fitness position than the kth particle; this information is again exchanged and search goes on.</sentence>
    <sentence>The value of the global best position found among the swarm either improves by iteration or remains same but does not degrade.</sentence>
    <sentence>After several iterations all the particles converge to a near optimal region of the fitness function after which there will be no significant improvement in the best fitness value of the function.</sentence>
    <sentence>The GBP of the converged swarm is taken as the true optimal value of the payoff function.</sentence>
    <sentence>Another key concept involved in this exploring mechanism is recollecting of information.</sentence>
    <sentence>Each particle will have the ability to remember the best fitness position that it has come across up until the current iteration; this is called the local best position (LBP).</sentence>
    <sentence>The LBP is different for different particles during movement.</sentence>
    <sentence>If a particle moving towards GBP encounters a worse position than its LBP, it stays at its LBP rather than make a move.</sentence>
    <sentence>This ability of remembering and exchanging of information eventually brings all the swarm particles close to the existing true global optima of a given payoff function.</sentence>
    <sentence>The efficiency of the algorithm both in terms of quality and quickness of arriving at global optima depends on how the particles exchange information and how quickly they move towards the promising region.</sentence>
    <sentence>There is however scope for improving the efficiency of the algorithm giving birth to different variants of evolutionary algorithm.</sentence>
    <sentence>This paper uses one such variant of swarm intelligence called particle swarm optimization with composite particles (PSOCP) by Liu et al.</sentence>
    <sentence>(2010).</sentence>
    <sentence>PSOCP has desirable advancements in the technical framework of the algorithm allowing efficient exploration of optimal values of payoff functions to take place.</sentence>
    <sentence>Particle swarm optimization with composite particles (PSOCP) PSOCP is a variant of the evolutionary algorithm known as PSO (Kennedy &amp; Eberhart, 1995) which works on swarm intelligence while tracking out global optima.</sentence>
    <sentence>It was initially developed by Liu et al.</sentence>
    <sentence>(2010) in order to tackle dynamic environments.</sentence>
    <sentence>The concept was inspired by the phenomenon of interaction of elementary members in each composite particle through a velocity-anisotropic reflection scheme (VAR) derived from the physics discipline.</sentence>
    <sentence>Compared to basic PSO, it uses the “concerted action” principle explained in Liu et al.</sentence>
    <sentence>(2010) while updating the elementary particles for next iteration but maintaining a similar procedure to that used for updating the pioneer particles of composite particles.</sentence>
    <sentence>This feature of integral movement of particles facilitates the swarm to share the beneficial information in a constructive manner which ensures that elementary particles move under correct guidance in accordance with the fittest particles.</sentence>
    <sentence>This enables the swarm to make an easy decision support system in the space to explore the promising region around exact optima while avoiding collision and velocity-slackening of elementary particles.</sentence>
    <sentence>A scattering operation is also adopted to ameliorate the fittest elementary particle available to a more desirable direction.</sentence>
    <sentence>When a composite particle generally converges, the scattering operation is triggered which enables the swarm avoid local entrapment.</sentence>
    <sentence>The VAR scheme helps the elementary particles to look for more extensive solution space.</sentence>
    <sentence>Position modulation function This function ensures that all variables should lie within their corresponding boundaries.</sentence>
    <sentence>The function basically takes the swarm to be modulated as its input and modifies that swarm according to the predefined limits and gives the modified swarm as the output.</sentence>
    <sentence>The approach is briefly depicted with the help of pseudo code in Table 2.</sentence>
    <sentence>Table 2.</sentence>
    <sentence>Pseudo code for position modulation function in Section 4.2.</sentence>
    <sentence>Step-1: Define lower and upper bounds of each variable Step-2: for i = 1: all variables end for *UB= Upper Bound *LB= Lower Bound 4.3.</sentence>
    <sentence>Composite particles As per the procedure mentioned in Liu et al.</sentence>
    <sentence>(2010), we adopted the same method to construct the composite particles in this paper.</sentence>
    <sentence>A composite particle is defined as a three particle group with similar features.</sentence>
    <sentence>We consider the Euclidean distance between one particle and another so that each group forms a near equilateral triangle.</sentence>
    <sentence>A “worst is first” criterion is utilized in constructing the composite particles.</sentence>
    <sentence>The procedure starts by arranging all the particles in ascending order of their fitness and the worst particle is selected as a first particle in the composite particle being constructed and the remaining two particles are selected based on Euclidean distance which are close to the weakest particle in that composite particle.</sentence>
    <sentence>This procedure iterates until all possible composite particles are constructed.</sentence>
    <sentence>The particles that remain unconstructed in the end are named as independent particles.</sentence>
    <sentence>These will ultimately turn out to be best fit particles.</sentence>
    <sentence>Composite particles usually handle two major concerns.</sentence>
    <sentence>The primary concern is to develop a method which would increase the interaction among elementary particles in such a way that more promising search space would be explored.</sentence>
    <sentence>A secondary concern is that it facilitates VAR and scattering operations on the composite particles being constructed from which we can improve the performance of the algorithm.</sentence>
    <sentence>The pseudo code shown in Table 3 depicts the procedure adopted for construction of composite particles.</sentence>
    <sentence>Table 3.</sentence>
    <sentence>Pseudo code for creation of composite particles in Section 4.3.</sentence>
    <sentence>Step-1: Sort all the particles in the increasing order of their fitness Step-2: Compute the number of composite particles using .</sentence>
    <sentence>Step-3: Initialize the set of composite particles as null set.</sentence>
    <sentence>i.e., Step-4: for i = 1:Nc Select worst particle (xworst) from swarm S Select two nearest particles to xworst end Step-5: Particles that don't belong to any composite particle remain as independent particles.</sentence>
    <sentence>* * 4.4.</sentence>
    <sentence>Scattering and VAR operations To ensure local diversity within each composite particle, we adopted scattering and VAR operations which facilitates in avoiding local entrapment of our heuristic, a major drawback of meta heuristics in computational intelligence literature.</sentence>
    <sentence>The procedure proceeds by utilising the concept of convergence.</sentence>
    <sentence>A composite particle is said to be converged when the Euclidean distance between the worst particle and the other particles inside it becomes less than the threshold ϴ.</sentence>
    <sentence>A scattering operation is performed whenever the convergence criteria are met within the composite particle.</sentence>
    <sentence>If the position of the elementary particle having the best fitness value in the composite particle is represented by F and other two non-pioneer particles denoted by E1 and E2, then the particle with best fitness F scatters along the direction and in order to replace E1 and E2.</sentence>
    <sentence>Now the new composite particle contributes to the points F, S1 and S2 as shown in Fig 1.</sentence>
    <sentence>Fig 1.</sentence>
    <sentence>Generation of new composite particle using scattering operation.</sentence>
    <sentence>A velocity anisotropic reflective (VAR) operation is proposed along with a scattering operation to make sure that the worst particles move in an improved direction towards a promising region in the search space.</sentence>
    <sentence>This enhances the exploration and better tracking of global optima in the search space.</sentence>
    <sentence>The procedure involves two sub steps with an adoptive step size and pioneer particle selection as defined in Liu et al.</sentence>
    <sentence>(2010).</sentence>
    <sentence>Both of these operations are proposed for better tracking of optima in dynamic environments.</sentence>
    <sentence>The pseudo code given in Table 4 depicts the schema for carrying out scattering and VAR operations.</sentence>
    <sentence>Table 4.</sentence>
    <sentence>Pseudo code for carrying out scattering and VAR Operation.</sentence>
    <sentence>Step-1: for i = 1: Nc // Scattering Operation Step-2: Calculate Euclidean distance between its worst particle and the two remaining particles as respectively Step-3: if end if // VAR Operation Step-4: for each j ∈ particles other than worst particle in that CP Step-5: if is better than then end if end for-(step −4) Step-6: Update pioneer and worst particle in ith CP end for-(step-1) *CP-Composite Particle * is jth particle in ith CP; is reflected (updated) position obtained after the VAR operation.</sentence>
    <sentence>*θ is minimum threshold distance *Rstep is Reflection Step Size during VAR operation *φ is random number *γ is also a random number * → Particle with best fitness in ith CP 4.5.</sentence>
    <sentence>Overview of PSOCP for optimizing payoff functions The innovative qualities of the algorithm - construction of composite particles, scattering and VAR - have been adopted to design a variant of PSOCP to tackle complex game theoretic scenarios smoothly.</sentence>
    <sentence>The algorithm begins with random initialization of the swarm and its initial velocity and runs in an iterative manner until the termination criterion is met.</sentence>
    <sentence>Each iteration involves tracking of the personal best for each pioneer particle, the global best particle, construction of composite particles, scattering operation, VAR scheme operation and updating the swarm for next iteration.</sentence>
    <sentence>At the end of each iteration the position of each updated particle is checked to ensure that it lies within its predefined boundaries using the function position modulation discussed in Section 4.2.</sentence>
    <sentence>Eventually the algorithm arrives at a near optimal solution of the fitness function which we are trying to optimize.</sentence>
    <sentence>Hence this algorithm can be used to predict the optimal decisions or best responses of all the firms corresponding to their pay off functions.</sentence>
    <sentence>An overview of the algorithm is presented in the form of pseudo code given in Table 5.</sentence>
    <sentence>Table 5.</sentence>
    <sentence>Pseudo code for overall procedure for PSOCP algorithm.</sentence>
    <sentence>Step-1: Define all the parameters like swarm size (m), inertia weight (w), accelerating coefficients (k1, k2), reflection step size (Rstep), maximum and minimum values of stretching step size and termination criteria (E) as maximum number of iterations.</sentence>
    <sentence>Step-2: Randomly initialize the swarm, initial velocity and respective fitness and evaluate lbp and gbp of swarm.</sentence>
    <sentence>Step-3: Modulate the randomly initialized swarm using position modulation function Step-4: While (Termination criteria is not met) Initialize iteration counter • for each particle evaluate current fitness if (current fitness is better than local best fitness) then update local best fitness of current particle end if end for Step-5: Construct all the possible composite particles and independent particles using procedure laid down in creation of composite particles function Step-6: Apply scattering and VAR operation on each composite particle Step-7: for each composite particle calculate the pioneer particle • Identify pioneer particle and the remaining as elementary particles • Update velocity and position of the pioneer particle of each composite particle and independent particles using two formulae below • Calculate the distance moved by pioneer particle after update and move the two elementary particles by the same amount in each dimension.</sentence>
    <sentence>• Modulate the updated positions of particles using modulation function.</sentence>
    <sentence>end for in step-7 Step-8: Update lbp and gbp Update iteration counter end while (in step-4) *lbp(t) is local best position of each particle in the swarm up to tth iteration *gbp(t) is the global best position whole swarm up to tth iteration *cposition(t) is current position of a swarm particle in tth iteration *r1 , r2 are random numbers 4.6.</sentence>
    <sentence>Handling constrained games Though there are many ways to address constrained scenarios, we have adopted a penalty function method to overcome these problems in EAA.</sentence>
    <sentence>The first reason is to do with the randomness involved in generating and updating the solutions in our evolutionary algorithm, which may not facilitate us in giving a feasible swarm in every iteration.</sentence>
    <sentence>The second reason has to do with the ease with which the penalty function approach handles complex constraints.</sentence>
    <sentence>A penalty function is constructed by penalizing each constraint with an appropriately large number in proportion to its violation and annexing all those penalty values as one function.</sentence>
    <sentence>Then this penalty function will be appended to the original objective function as a negative effect.</sentence>
    <sentence>As our algorithm tries to rehabilitate and improve the payoff function in every iteration this consolidated objective function ensures reduction in violation of all the constraints in later iterations, as violation of any constraint shows a negative effect in the payoff function.</sentence>
    <sentence>This enables us to end up with a feasible solution after substantial number of iterations whose penalty function value falls to zero due to continuous reduction in violation.</sentence>
    <sentence>To reduce the search space and ensure faster convergence the bound constraints for individual variables are handled using the position modulation function rather than the penalty function.</sentence>
    <sentence>So, ultimately this makes a clear path for our model to return the best response strategy of each firm at every stage by contemplating all the constraints directly without any further attention.</sentence>
    <sentence>Several approaches in constructing penalty functions are defined in Yeniay (2005).</sentence>
    <sentence>Through this technique we curtail the difficulty concealed with handling all kinds of constraints that exist in the problem.</sentence>
    <sentence>Hence in EAA, we directly plot the points that are feasible with respect to all the constraints that frontiers the space and plot the required BRF.</sentence>
    <sentence>Hence penalty function approach is adopted to overcome constrained scenarios, which is a conventional behaviour of general competitive market.</sentence>
    <sentence>Sensitivity analysis and optimal parameter setting As we are using an evolutionary heuristic, it is necessary to look for the appropriate settings of the prime parameters that amend the efficiency of the algorithm in finding the better optimal solutions with less complexity in computation.</sentence>
    <sentence>The crucial parameters involved in our algorithm that may affect the dominant properties of the algorithm are inertia weight (w), accelerating coefficients (k1 , k2), diversification parameter used in VAR operation (Rstep), stretching parameters (Sstepmin ,Sstepmax ), and the threshold Euclidean distance limit (ϴ) involved in the scattering operation.</sentence>
    <sentence>It is imperative to fix optimal settings of the parameters, which vary from situation to situation.</sentence>
    <sentence>As we deal with diversified scenarios, these parameter settings cannot be stated as being invariably the best.</sentence>
    <sentence>Hence in particular with solving the game theory models, we present the optimal data set of the above mentioned parameters obtained by conducting 30 repeated runs for each numerical example that is considered to represent the scenarios modelled above.</sentence>
    <sentence>Few parameter settings are adopted from the conclusions drawn with the numerous experiments presented in Liu et al.</sentence>
    <sentence>(2010).</sentence>
    <sentence>We make an observation that we are getting k2&gt;&gt;k1 at the optimal parameter setting representing the fact that it facilitates the PSO variants to undergo a biased search towards global optima than local optima.</sentence>
    <sentence>This may also endanger the fact that search may miss a better optimal solution which is encountered by the diversification operations adopted in our heuristic.</sentence>
    <sentence>The important parameter that determines the efficiency of the algorithm in different scenarios is the stopping criteria to be employed while figuring out the optimal points for tracing out each BRF.</sentence>
    <sentence>This is exercised in two ways, first one being limiting the number of iterations that algorithm runs and the other is by predefining a threshold converging distance beyond which the algorithm does not search.</sentence>
    <sentence>That threshold distance depends on the accuracy in the quality of solutions needed and also on the range of fitness values.</sentence>
    <sentence>Here we employed the first one by defining the constraining maximum number of iterations (E) as 100 which is verified from the 30 repeated experiments on each scenario.</sentence>
    <sentence>In fact attention should be paid here when we come across a complex situation if it requires more iterations than in the case of constrained optimization.</sentence>
    <sentence>Table 6 shows suitable range of parameters at which our test instances have been solved.</sentence>
    <sentence>Table 6.</sentence>
    <sentence>Optimal parameter settings of PSOCP to solve the test instances.</sentence>
    <sentence>Parameter W k1 k2 Rstep ϕ m E Setting 0.9 0.1 0.98 6 2 3 0.05 50 100 *m is number of swarm particles employed for search each time.</sentence>
    <sentence>*Remaining parameters are as defined in Section 4.7.</sentence>
    <sentence>Table 7.</sentence>
    <sentence>Nash equilibrium found using EAA in test scenario defined in Section 5.1 (Linear demand and cost).</sentence>
    <sentence>NEwr = (68.74, 17.98) max (NEwr) η μ Promising Range (PR) Incremental Step (IS) 68.74 2 0.7 (0, 138.74) 6.937 Nash equilibrium S. No Firm-1 Firm-2</sentence>
  </section>
  <section name="67.90406&#9;18.33709"/>
  <section name="Computational experiments">
    <sentence>In this section we present several, increasingly complex, numerical examples corresponding to the models presented in Sections 2.1–2.4.</sentence>
    <sentence>The solutions obtained through EAA are compared with those gained from an analytical approach to show the robustness, ease and efficiency of EAA in attaining the Nash equilibrium, even in games with high levels of complexity.</sentence>
    <sentence>Linear demand and cost If we consider a duopoly case in which linear inverse demand function of each firm as and cost function as defined in Section 2.1 with the parameters as then the payoff functions of both firms become The above data are extracted from the data referred to in (Mathiesen, 2008).</sentence>
    <sentence>Results for Mathiesen's problem 5.2 are presented in Table 7 and the BRFs of both firms and NE is shown in Fig 2.</sentence>
    <sentence>The units for best strategy of all the firms presented in all the subsequent tables presented throughout Section 5 are the number of units of production quantities to be produced by the corresponding firm.</sentence>
    <sentence>NEwr in all tables presented throughout Section 5 indicates initial Nash equilibrium found in wide range search in EAA.</sentence>
    <sentence>Fig 2.</sentence>
    <sentence>Best response functions and corresponding NE for problem defined in Section 5.1 (linear demand and cost).</sentence>
    <sentence>Hence from the above results we can observe that the relative error that we get through EAA is negligible at less than 0.05 per cent.</sentence>
    <sentence>Non-linear demand In this section, we present numerical examples corresponding to each scenario discussed in Section 2.2.</sentence>
    <sentence>The first scenario refers to exponential inverse demand function (Martin, 2002).</sentence>
    <sentence>It considers a duopoly situation whose payoff functions are of the forms shown in Eq (8) with the parameters .</sentence>
    <sentence>The payoff function of each firm becomes The solution for this situation is presented in Table 8 and Fig 3.</sentence>
    <sentence>Table 8.</sentence>
    <sentence>Nash equilibrium found using EAA in the test scenario defined in Section 5.2 (Non-linear demand: exponential).</sentence>
    <sentence>NEwr = (798.01,798.26) max (NEwr) η μ Promising Range (PR) Incremental Step (IS) 798.26 3 0.4 (0, 1198.26) 59.913 Nash equilibrium S. No Firm-1 Firm-2</sentence>
  </section>
  <section name="799.7452&#9;799.4053">
    <sentence>Fig 3.</sentence>
    <sentence>Best response functions and corresponding NE for problem defined in Section 5.2 (non-linear demand: exponential).</sentence>
    <sentence>Non-linear demand and non-linear cost functions In this case, a situation has been taken up in which both inverse demand function and cost functions having non-linear natures.</sentence>
    <sentence>In this sense we provide a numerical replica for the model that is being described in Section 2.3 in which the demand functions takes a hyperbolic nature with respect to quantity.</sentence>
    <sentence>This following example is adopted from (Martin, 2002), Payoff function of corresponding firm as shown below Table 9 and Fig 4 show the computational results for the above scenario.</sentence>
    <sentence>We have presented more elaborate results than Martin (2002) comprising the different optimal responses found by PSOCP in EAA which are used in plotting BRFs of each firm in Table 9.</sentence>
    <sentence>Table 9.</sentence>
    <sentence>Nash equilibrium found using EAA along with best responses used in plotting BRFs of firms in test scenario defined in Section 5.3 (Non-linear cost and non-linear demand: hyperbolic).</sentence>
    <sentence>NEwr= {(5.012, 7.587), (6.782, 6.894), (7.639, 4.983)} max (NEwr) η μ Promising range (PR) Incremental step (IS) 7.6398 1 0.7 (0, 14.6398) 0.7319 Enhanced search in the Promising Region Point number BRF of firm-1 BRF of firm-2 Best Strategy of Firm-1 Strategy of Firm-2 Strategy of Firm-1 Best Strategy of Firm-2 1 4.804483 0 0 4.813329 2 5.078549 0.73199 0.73199 5.086385 3 5.271097 1.46398 1.46398 5.28613 4 5.441065 2.19597 2.19597 5.453821 5 7.803638 2.92796 2.92796 7.804731 6 7.92935 3.65995 3.65995 7.900556 7 7.958159 4.39194 4.39194 7.991157 8 8.017722 5.12393 5.12393 8.003906 9 8.068147 5.85592 5.85592 8.002797 10 8.007099 6.58791 6.58791 7.996652 11 5.09209 7.3199 7.3199 5.095586 12 4.991875 8.05189 8.05189 4.983557 13 4.908023 8.78388 8.78388 4.897695 14 4.824552 9.51587 9.51587 4.819763 15 4.745976 10.24786 10.24786 4.746341 16 4.709813 10.97985 10.97985 4.680799 17 4.628033 11.71184 11.71184 4.634293 18 4.559394 12.44383 12.44383 4.575247 19 4.516522 13.17582 13.17582 4.527633 20 4.472001 13.90781 13.90781 4.468988 Nash equilibrium S. No Firm-1 Firm-2</sentence>
  </section>
  <section name="4.998743&#9;8.001726">
    <sentence>2 6.871403 6.873095 3 8.00686 4.990449 Fig 4.</sentence>
    <sentence>Best response functions and corresponding NE for problem defined in Section 5.3 (non-linear cost and non-linear demand: hyperbolic).</sentence>
    <sentence>Another non-linear benchmark scenario having multiple Nash equilibria involving sinusoidal payoff functions (Razi et al., 2007) is presented.</sentence>
    <sentence>The respective payoff functions for that duopoly scenario are as shown below Fig 5 and Table 10 show the results of that benchmark scenario depicting all the possible multiple equilibria.</sentence>
    <sentence>This example reflects the resilience of the EAA algorithm and its ability to achieve solutions to complex games smoothly.</sentence>
    <sentence>Table 10.</sentence>
    <sentence>Nash equilibria in case of benchmark problem defined in Section 5.3 (In Wide Range Search).</sentence>
    <sentence>Multiple Nash equilibrium in case of sinusoidal profit functions S No.</sentence>
    <sentence>Firm-1 Strategy ( × 1040) Firm-2 Strategy ( × 1040) 1 0.14 1.329991 2 0.14 1.190009 3 0.14 0.42 4 0.14 0.28 5 0.14 0.14 6 0.14 3.99 7 0.28 8 0.28 0.14 9 0.28 0.28 10 0.28 0.42 11 0.28 1.190019 12 0.28 1.329981 13 0.42 14 0.42 0.14 15 0.42 0.28 16 0.42 0.42 17 0.42 1.190028 18 0.42 1.329972 19 1.19 20 1.190001 0.14 21 1.190001 0.28 22 1.190002 0.42 23 1.190006 1.190079 24 1.190007 1.329921 25 1.329993 1.329912 26 1.329994 1.190088 27 1.329998 0.42 28 1.329999 0.28 29 1.329999 0.14 30 1.33 5.4.</sentence>
    <sentence>Constrained functions: production and environmental In this case, a constrained scenario has been considered with linear payoff functions subject to constraints that regulate the quantity of production by each firm and environmental pollution levels.</sentence>
    <sentence>The constraints pertain to the production capacities of firms and environmental regulations that regulate emission of pollutants by both firms.</sentence>
    <sentence>The environmental pollution constraints are as described in Section 2.4.</sentence>
    <sentence>Pay off functions of individual firm: Subject to: Results for the above have been presented in three stages with respect to constraints.</sentence>
    <sentence>The first stage deals with the effect of production capacity constraints, the second stage deals with effect of pollution constraints and the last stage deals with the combined effect on NE.</sentence>
    <sentence>Figures 6, 7 and 8 and Tables 11, 12 and 13 show the results in sequence of stages.</sentence>
    <sentence>Fig 5.</sentence>
    <sentence>Nash equilibria in case of benchmark problem defined in Section 5.3 (Multiple equilibria).</sentence>
    <sentence>Fig 6.</sentence>
    <sentence>Best response functions and corresponding NE for problem defined in Section 5.4 (Production constraints).</sentence>
    <sentence>Fig 7.</sentence>
    <sentence>Best response functions and corresponding NE for problem defined in Section 5.4 (Pollution constraints).</sentence>
    <sentence>Fig 8.</sentence>
    <sentence>Best response functions and corresponding NE for problem defined in Section 5.4 (Production and pollution constraints).</sentence>
    <sentence>Table 11.</sentence>
    <sentence>Nash equilibrium found using EAA in test scenario defined in Section 5.4 (Production constraints).</sentence>
    <sentence>NEwr = (19.986,10.034) max (NEwr) η μ Promising range (PR) Incremental step (IS) 19.986 2 0.6 (0, 79.986) 3.9993 Nash equilibrium S. No Firm-1 Firm-2</sentence>
  </section>
  <section name="19.99759&#9;&#9;9.968141">
    <sentence>Table 12.</sentence>
    <sentence>Nash equilibrium found using EAA in test scenario defined in Section 5.4 (Pollution constraints).</sentence>
    <sentence>NEwr = (24.442,19.010) max (NEwr) η μ Promising range (PR) Incremental step (IS) 24.442 2 0.4 (0, 67.442) 3.3721 Nash equilibrium S. No Firm-1 Firm-2</sentence>
  </section>
  <section name="23.51379&#9;&#9;18.71475">
    <sentence>Table 13.</sentence>
    <sentence>Nash equilibrium found using EAA in constrained test scenario defined in Section 5.4 (Production and pollution constraints).</sentence>
    <sentence>NEwr = (19.987,9.826) max (NEwr) η μ Promising range (PR) Incremental step (IS) 19.987 2 0.5 (0, 69.987) 3.49935 Nash equilibrium S. No Firm-1 Firm-2</sentence>
  </section>
  <section name="19.94788&#9;&#9;9.976549">
    <sentence>Another constrained scenario can be built by considering the nonlinear payoff functions for each firm subject to the set of constraints given above.</sentence>
    <sentence>Consider the payoff functions with hyperbolic demand function and the polynomial cost function presented in Section 2.3 subject to the constraints presented above.</sentence>
    <sentence>Fig 9 shows the results of this constrained non-linear scenario.</sentence>
    <sentence>We can observe that there is a leftward shift in the Nash equilibrium when we move from the unconstrained scenario discussed in Section 5.3 to the current constrained scenario.</sentence>
    <sentence>Multiple equilibria do not exist in the constrained scenario compared to the unconstrained scenario.</sentence>
    <sentence>In Fig 9, BRF-1 and BRF-2 represent the best response functions in the constrained scenario and BRF-1UC and BRF-2UC represent the best response curves for the unconstrained scenario.</sentence>
    <sentence>NE-UC indicates the Nash equilibrium in the unconstrained scenario; NE-C indicates the Nash equilibrium in the constrained scenario.</sentence>
    <sentence>Fig 9.</sentence>
    <sentence>Change in Nash equilibrium from unconstrained nonlinear game to constrained nonlinear game as presented in Section 5.4.</sentence>
    <sentence>A comparison of the above tests has been made with exact solutions obtained through traditional analytical approach and these are presented in Table 14.</sentence>
    <sentence>Except for scenarios 1 and 2, it is difficult to find analytical solutions for the remaining scenarios.</sentence>
    <sentence>Hence no comparison could be done for those scenarios.</sentence>
    <sentence>In fact this shows the value of the proposed EAA as it can handle without difficulty complicated scenarios that cannot be solved using an analytical approach.</sentence>
    <sentence>Table 14.</sentence>
    <sentence>Compilation of results of all computational experiments solved using EAA and traditional analytical approach.</sentence>
    <sentence>Scenario Defined in Section Nash equilibrium (averaged over 30 trials) % Deviation Average Time of computation (over 30 trials in minutes) Using EAA Using analytical approach Firm 1 Firm2 Firm1 Firm2 Firm1 Frim2 1 5.2 67.942 18.030 68 18 0.0845 0.167 0.158 2 5.3 800.010 799.405 800 800 0.0432 0.074 0.162 3 5.4 5.0087 8.001 – – 0.198 6.8715 6.877 8.006 5.002 4 5.5 19.997 9.968 – – 0.293 5 5.5 23.508 18.720 – – 0.302 6 5.5 19.992 9.987 – – 0.324 7 5.5 3.150 3.148 – – 0.410 Note: the symbol “-” indicates that a solution cannot be found using traditional analytical approach.</sentence>
  </section>
  <section name="Conclusion">
    <sentence>This paper used an evolutionary algorithmic approach to determine the Nash equilibrium for situations of duopolistic competition involving nonlinearities, constraints and discrete functions.</sentence>
    <sentence>This is a novel way of determining the Nash equilibrium and a novel application of particle swarm optimization.</sentence>
    <sentence>The model was validated by comparing the results found using the composite particle swarm approach to results determined analytically for a variety of different cases.</sentence>
    <sentence>Closed form analytical solutions however can be found only for industrial competition problems specified for relatively simple, usually linear, formats.</sentence>
    <sentence>The power of the composite particle swarm approach is that solutions for the Nash equilibrium can be found for complex non-linear situations.</sentence>
    <sentence>Examples of non-linear competitive situations abound in the real world, for example where inverse demand functions are concave rather than linear, where firm costs demonstrate economies or diseconomies of scale, or where production capacity is constrained or formulated in discrete bands.</sentence>
    <sentence>A limitation of this research is that EAA has been tested using a limited number of cases and Nash equilibria determined only for pure strategies.</sentence>
    <sentence>Further research work may be carried out to extend the variety of cases examined, to consider more realistic competitive situations, and to determine Nash equilibrium in mixed strategies.</sentence>
  </section>
</article>
