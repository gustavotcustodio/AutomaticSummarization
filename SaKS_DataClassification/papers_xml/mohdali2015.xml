<article>
  <title>Artificial Intelligence techniques applied as estimator in chemical process systems – A literature survey</title>
  <abstract>
    <sentence>The versatility of Artificial Intelligence (AI) in process systems is not restricted to modelling and control only, but also as estimators to estimate the unmeasured parameters as an alternative to the conventional observers and hardware sensors.</sentence>
    <sentence>These estimators, also known as software sensors have been successfully applied in many chemical process systems such as reactors, distillation columns, and heat exchanger due to their robustness, simple formulation, adaptation capabilities and minimum modelling requirements for the design.</sentence>
    <sentence>However, the various types of AI methods available make it difficult to decide on the most suitable algorithm to be applied for any particular system.</sentence>
    <sentence>Hence, in this paper, we provide a broad literature survey of several AI algorithms implemented as estimators in chemical systems together with their advantages, limitations, practical implications and comparisons between one another to guide researchers in selecting and designing the AI-based estimators.</sentence>
    <sentence>Future research suggestions and directions in improvising and extending the usage of these estimators in various chemical operating units are also presented.</sentence>
  </abstract>
  <keywords>
    <keyword>Artificial Intelligence</keyword>
    <keyword>Estimator</keyword>
    <keyword>Soft-sensor</keyword>
    <keyword>Chemical process systems</keyword>
  </keywords>
  <section name="Introduction">
    <sentence>Artificial Intelligence (AI), by definition is the ability of computers or other machines in performing activities that require human intelligence.</sentence>
    <sentence>It has attracted researchers on its theories and principles since the 1956 Dartmouth conference (Negnevitsky, 2005).</sentence>
    <sentence>Today, this method has been widely used in various applications including games, automation, medical and process control.</sentence>
    <sentence>In process control, its application has recently expanded not only being used in modelling and control but also as tools to estimate difficult-to-measure parameters, known as estimators.</sentence>
    <sentence>Those AI-based estimators are computational algorithms designed to predict the unmeasured parameters that are significant in developing the state feedback control law of a system.</sentence>
    <sentence>They are also addressed as software or virtual sensors and encompass several algorithms including artificial neural network (ANN), fuzzy logic, genetic algorithm (GA) and expert system (ES).</sentence>
    <sentence>They can be developed using software such as MATLAB and LabView and implemented on the specific process unit to predict unmeasured states such as concentration, temperature, heat flux, molecular weight and impurities.</sentence>
    <sentence>Other practical simulation software used for estimating states are PROCESS (Simulation Sciences code) (Himmelblau, 2008), SIAMOD (Siemens adaptive modelling of dynamic system) (Horn, 2001), NeuralWorks Professional II/(PLUS) (Yeh, Huang, &amp; Huang, 2003) and dynamic simulator (Dynafrag) (Du, del Villar, &amp; Thibault, 1997).</sentence>
    <sentence>Before AI-based estimators were introduced, researchers have been using the conventional observers in chemical process systems, for example the Luenberger observer, Extended Kalman Filter (EKF), sliding mode observer and observers.</sentence>
    <sentence>These observers also offer good estimation performances and have their relative advantages when applied in chemical unit operations, as quoted in several literatures (Aguilar-López, 2003; Damour, Benne, Boillereaux, Grondin-Perez, &amp; Chabriat, 2010; Dochain, 2000; Dochain, Couenne, &amp; Jallut, 2009; Gonzalez, Fernandez, Aguilar, Barron, &amp; Alvarez-Ramirez, 2001; Kam &amp; Tadé, 1999; Mesbah, Huesman, Kramer, &amp; Van den Hof, 2011; Tronci, Bezzo, Barolo, &amp; Baratti, 2005; Velardi, Hammouri, &amp; Barresi, 2009; Wang, Peng, &amp; Huang, 1997; Zarei &amp; Poshtan, 2010).</sentence>
    <sentence>However, AI-based estimators are generally easier to retune whenever there are changes in the parameters and are able to avoid time delays compared to the conventional observers.</sentence>
    <sentence>Besides that, these AI-based soft-sensors are able to work in parallel with hardware sensors for providing information especially to detect faults in the systems (Fortuna, Graziani, &amp; Xibilia, 2005).</sentence>
    <sentence>However in certain applications, AI elements have been combined with conventional observers known as hybrid estimators, which include fuzzy Kalman filter (FKF) (Prakash &amp; Senthil, 2008; Senthil, Janarthanan, &amp; Prakash, 2006) and differential neural network observer (DNNO) (Chairez, Poznyak, &amp; Poznyak, 2007; Porru, Aragonese, Baratti, &amp; Alberto, 2000) mainly to increase their performances.</sentence>
    <sentence>Based on the increasing popularity of applying AI as estimators in chemical process systems, several review papers are available in literature but they are not comprehensive and involve only certain AI algorithms.</sentence>
    <sentence>For example, de Assis and Filho (2000) have provided a short review of ANN only and compared it with EKF and adaptive observers.</sentence>
    <sentence>Himmelblau (2008) has explained several applications of ANN in chemical engineering including its usage as estimators while Kamimura and co-workers have (Kamimura, Konstantinov, &amp; Stephanopoulos, 1996) provided a review on ANN and knowledge-based systems in biotechnology.</sentence>
    <sentence>Katare and coworkers also compared various parameter estimation using hybrid GA in several kinetic models (Katare, Bhan, Caruthers, Delgass, &amp; Venkatasubramanian, 2004) and several applications of intelligence systems in process engineering have also been reviewed by Stephanopoulos and Han (Stephanopoulos &amp; Han, 1996).</sentence>
    <sentence>Another review has been done by Kadlec and coworkers whereby they explained several soft sensors in process industries (Kadlec, Gabrys, &amp; Strandt, 2009) and the adaptation mechanisms of the techniques (Kadlec, Grbić, &amp; Gabrys, 2011).</sentence>
    <sentence>Besides that, Kalogirou (2003) and Shioya, Shimizu, and Yoshida (1999) have compiled all AI applications in the combustion and bioprocess respectively.</sentence>
    <sentence>In addition, Porter and co-workers have discussed on GA as estimators in general linear and nonlinear systems (Porter Ii &amp; Passino, 1995).</sentence>
    <sentence>Therefore, in this paper, we have reviewed and provided a comprehensive list of AI algorithms that have been applied as estimators in chemical process systems by highlighting their advantages, limitations and practical implications since it is not available in any literature at present.</sentence>
    <sentence>Guidelines in selecting the possible algorithm for a specific system are also given, to help researchers in choosing the most appropriate algorithm that suits their system if they are to apply AI algorithms as estimators.</sentence>
    <sentence>Examples are also given to show how to develop these AI-based estimators, all of which are novel and important contributions of this paper.</sentence>
    <sentence>After the introduction section, AI applied as estimators in chemical process systems are discussed in Section 2.</sentence>
    <sentence>Section 3 discusses the guideline and examples of the applications while the advantages, limitations and future directions are given in Sections 4.</sentence>
    <sentence>Section 5 concludes the review.</sentence>
  </section>
  <section name="AI applied as estimators in chemical process systems">
    <sentence>The usage of AI algorithms as estimators in chemical process systems is becoming popular due to their robustness, simple formulation, easy-to-design and flexible adaptation capabilities.</sentence>
    <sentence>They also do not require full knowledge of process kinetics, which are at times difficult to be obtained from the highly nonlinear behaviour of chemical processes themselves.</sentence>
    <sentence>The AI algorithms that have been applied include the artificial neural network (ANN), fuzzy logic, genetic algorithm (GA), expert systems (ES) and hybrid systems.</sentence>
    <sentence>However, the variety and unique features of these algorithms make it difficult to decide on the suitable method to be used in any particular system.</sentence>
    <sentence>Therefore a survey of each algorithm applied as estimators in chemical process systems, as presented in this paper, is important to highlight the significance of each algorithm and guide researchers towards the design of the AI-based estimators for any particular chemical process system.</sentence>
    <sentence>ANN is the most popular algorithms applied since its capability is promising and can be trained to learn the process based on historical data (Devogelaere, Rijckaert, Leon, &amp; Lemus, 2002).</sentence>
    <sentence>Besides that, it provides high accuracy and consistent estimations even when changes occur in the process (Sharma, Singh, Singhal, &amp; Ghosh, 2004).</sentence>
    <sentence>In general, ANN relates to the function of the human brain, consists of a number of simple processors or neurons, which are arranged into layers as illustrated in Fig 2.1.</sentence>
    <sentence>In the figure, part A represents the neuron in human while part B shows neuron in the ANN (Maltarollo, Honório, &amp; Silva, 2013).</sentence>
    <sentence>Neurons in adjacent layers of ANN are connected by weighted links passing signals from one layer to the next adjacent layer.</sentence>
    <sentence>Those links have numerical weights that are applied to the inputs of a neuron.</sentence>
    <sentence>ANN learns through the repeated adjustment of the weights to obtain the desired output signal.</sentence>
    <sentence>The feed forward structure of ANN consists of a multilayer structure whereby there are hidden nodes in between the input and output layers.</sentence>
    <sentence>However, there is no specific method to obtain the number of the hidden nodes and it is commonly based on trial and error basis to find the appropriate number of nodes that will provide the best results (Lashkarbolooki, Vaferi, &amp; Mowla, 2012).</sentence>
    <sentence>Human and ANN neuron concept Fig 2.1.</sentence>
    <sentence>Human and ANN neuron concept.</sentence>
    <sentence>Picture taken from Maltarollo et al.</sentence>
    <sentence>(2013): Applications of artificial neural networks in chemical problems.</sentence>
    <sentence>Details and issues regarding the implementation of ANN such as the improvement of neural network generalisation, regularisation, cross validation, learning methods, local minima problem and curse of dimensionality can be found in various references (Buntine &amp; Weigend, 1991; Caruana, Lawrence, &amp; Giles, 2001; Crucianu, Boné, &amp; Asselin de Beauville, 2001; Guyon &amp; Yao, 1999; Hagiwara &amp; Kuno, 2000; Himmelblau, 2008; Lampinen &amp; Vehtari, 2001; MacKay, 1992; Mc Loone &amp; Irwin, 2001; Morgan &amp; Bourlard, 1989; Neal, 1995; Priddy &amp; Keller, 2005; Touretzky, 1990; Wang, Zhang, &amp; Okazaki, 2007; Ytlcetiirk, Herdagdelenz, Uyanikzet, &amp; Lisesi, 1999; Zhang &amp; Friedrich, 2003; Zhang &amp; Morris, 1998; Zhang, 2001; (Zhang, 1999a, 1999b); Zhang, Martin, Morris, &amp; Kiparissides, 1997).</sentence>
    <sentence>We have also highlighted some of these details in Appendix A.</sentence>
    <sentence>Furthermore, the computational cost and time for implementing the neural networks can be minimized if proper steps of training as highlighted in the appendix can be followed closely.</sentence>
    <sentence>For estimating parameters in chemical process systems, several types of ANN can be used such as the feed forward neural networks (FFN), internally recurrent net (IRN), externally recurrent net (ERN), radial basis function networks (RBFN), and the shape-tuneable neural network (MNN) (Chen &amp; Chang, 1996).</sentence>
    <sentence>Each structure has their own features and the comparisons are listed out in Table 2.1.</sentence>
    <sentence>In addition, Table 2.2(a) provides the details of the applications of ANN in chemical process systems, which include the objective of the estimations, their positive highlights, unit operations involved and relevant references related to each of the applications.</sentence>
    <sentence>Table 2.1.</sentence>
    <sentence>Comparison of several ANN structures.</sentence>
    <sentence>No.</sentence>
    <sentence>Types of ANN Key features Advantages Limitations 1 Feed forward neural networks (FFN) • Fixed function and require large amount of training data • Accurately approximate continuous functions • Easy to implement • Slow convergence • Lack dynamics • Mainly used for static function approximation 2 Internally recurrent net (IRN) • Characterised by time-delayed feedback connections from output of hidden nodes back to inputs of hidden nodes • Capable of estimating process with changing variable dynamics • No limit for the number of states • Difficult to initialize • Training can be time consuming 3 Externally recurrent net (ERN) • Contain time-delayed feedback connections from output layer to a hidden layer • Easy to initialize • Simple design and can use current values to initialize states • Number of states must be the same as model outputs • Training can be time consuming 4 Radial basis function neural networks (RBFNN) • Basis function used can be Gaussian or wavelets • Do not apply back-propagation for training • Less sensitive to sensor noise • Faster training • Most suitable for classification problem • Large number of hidden nodes needed 5 Recurrent trainable neural network (RTNN) • Hidden layer is the recurrent layer and the other two layer is based on back propagation • Faster convergence • Less complexity in the design • Not versatile • Slow training due to sequential structure 6 Shape-tuneable neural network (MNN) • Allow tuning of weight between neurons and saturation function of each neurons simultaneously • Sensitive to plant changes but still provide good estimation even with varied parameters • Greatly depends on sampling time and initial parameters Table 2.2.</sentence>
    <sentence>Various applications of AI-based estimators in chemical process systems.</sentence>
    <sentence>Types Objective/estimate(s) Systems applied Positive highlights References (a) ANN as estimators in chemical process systems FFN Conductivity Evaporator Small validation error (7%) (Devogelaere et al., 2002) ANN Gasoline and butane concentration Debutanizer Able to overcome delay (Fortuna et al., 2005) ANN Distillate composition Distillation column Good for binary distillation without multi-component (Singh, Gupta, &amp; Gupta, 2005) ANN Distillate composition Distillation column Handle many inputs with accurate results (Singh, Gupta, &amp; Gupta, 2007) Adaptive neural network Product composition Binary distillation column High accuracy with faster response (de Canete et al., 2012) ANN Mole fraction of distillate product Binary distillation column Satisfactory estimation performance, help to enhance overall control (González, Aguilar, Alvarez-Ramírez, Fernández, &amp; Barrón, 1999) ANN Product composition Reactive distillation column Allow error refinement (Bahar &amp; Özgen, 2010) ANN Top, bottom composition, reflux ratio Batch distillation Able to speed up training for better prediction (Frattini Fileti, Cruz, &amp; Pereira, 2000) RANN Product compositions Batch distillation Good agreement with actual value (Zamprogna, Barolo, &amp; Seborg, 2001) ANN Faults Packed distillation column Consistent results even with disturbances (Sharma et al., 2004) IRN Polymer product quality Polymerization reactor Excellent prediction especially in grade transition region (Himmelblau, 2008) IRN Outlet reactor concentration CSTR Good prediction compare with Extended Kalman Filter (EKF) (Himmelblau, 2008) MNN Heat of reaction, heat coefficient CSTR Handle system with noise (Chen &amp; Peng, 1999) ANN Kinetic parameters Bioreactor Good estimation for on-line application (de Assis &amp; Filho, 2000) RANN Biomass concentration Bioreactor Stable estimation based on corrective action during training (Acuña, Latrille, Béal, &amp; Corrieu, 1998) MLPFF Cellular concentration Bioreactor Accurate estimation at all three phases (lag, exponential, stationary) (Silva et al., 2008) FFN Oxygen uptake rate, carbon dioxide evolution rate Bioreactor High accuracy even the training data is reduced and save cost due to the reduction (Komives &amp; Parker, 2003) ANN Oxygen mass transfer coefficient STR Good prediction even with noise (García-Ochoa &amp; Castro, 2001) ANN Overall reaction rates of anhydrite Stirred cell reactor Good estimation even without initial assumption (Molga &amp; Cherbański, 2003) ANN Substrate, ethanol concentration Fed-batch reactor (Experimental) Estimation can be done outside domain (Gadkar, Mehra, &amp; Gomes, 2005) ANN Heat-released Batch reactor Accurate and fast estimation (Aziz, Hussain, &amp; Mujtaba, 2000) FFN Reactive impurities, polymer product quality Polymerization reactor Effective estimation if based only on the initial batch condition of reactive impurities (Zhang, Morris, Martin, &amp; Kiparissides, 1998) Stacked NN Reactive impurities, fouling Polymerization reactor Good prediction with impurities (Zhang, Morris, Martin, &amp; Kiparissides, 1999) ANN Initiator concentration, heat of reaction Polymerization reactor Only need measurement of one variable for training (Horn, 2001) ANN Monomer, Initiator concentration Polymerization reactor Satisfactory estimation performance (Yang, Chung, &amp; Brooks, 1999) MLRN Chain length Polymerization reactor Good estimation that allow variety of measured variables during training (Meert &amp; Rijckaert, 1998) ANN Reactor temperature Polymerization reactor Small estimation error (Kuroda &amp; Kim, 2002) Bootstrap NN Weight and number of average MW Polymerization reactor Reduce estimation error (Zhang, 1999a, 1999b) IRN Polymer product quality Polymerization reactor (Experimental) Accurate prediction over wide range of transition period (Barton &amp; Himmelblau, 1997) ANN Ethanol concentration Flash fermentor Optimum performances (Rivera, Atala, Filho, Carvalho da Costa, &amp; Filho, 2010) ANN Sugar concentration, chemical potency Fermentation process Good agreement with the value from production process (Dai, Wang, Ding, &amp; Sun, 2006) ANN Glucose and Galactose concentration, residual carbon concentration Fermentor (Experimental) Error of estimation is almost zero (0.06%) (Jin, Ye, Shimizu, &amp; Nikawa, 1996) ANN Consumed sugar concentration, optical cell density Fermentor (Experimental) Satisfactory despite variation in substrate (Yet-Pole, Wen-Tengu, &amp; Yung-Chuan, 1996) FFN, RBFNN Biomass concentration Fermentor Good estimation even with variation in yield coefficient (James, Legge, &amp; Budman, 2002) ANN Fluid and particle temperature, Biot number (Bi) Fluid-particle system Able to reduce the error of estimation (Sablani, 2001) RNNM Process kinetics Fermentor (Experimental) Reliable estimates and able to avoid over-fitting of NN during learning (Valdez-Castro, Baruch, &amp; Barrera-Cortes, 2003) ANN Density, viscosity, refractive index Binary system (water–methanol–acetonitrile–tetrahydrofuran mixtures) Small estimation error (Mehlman, Wentzell, &amp; McGuffin, 1998) ANN Heat transfer rate Heat exchanger Consistent prediction value compared with actual value (Islamoglu, 2003) ANN Heat flux Heat exchanger Prediction is based on known experimental data (Su et al., 2002) ANN Pressure drop Rotating fed bed Accurate estimation compare with actual values in wet bed (Lashkarbolooki et al., 2012) ANN Activated carbon Absorber Satisfactory prediction performance (Faur-Brasquet &amp; Le Cloirec, 2003) ANN Iron oxide conversion rate Iron oxide reduction process High convergence (Wiltowski et al., 2005) ANN Thermal conductivity response factor Gas chromatography Good agreement with actual value (Jalali-Heravi &amp; Fatemi, 2000) ANN Particle size Cyclone (grinding process) Simple formulation (Du et al., 1997) FFN Coal combustion rate Coal combustion process High accuracy and robust compared with actual value (Zhu, Jones, Williams, &amp; Thomas, 1999) BPNN Hydrogen content of coal Coal combustion process Prediction is based on proximate analysis (Yao, Vuthaluru, Tadé, &amp; Djukanovic, 2005) ANN Slurry velocity, solid concentration Pipeline for conveying bulk material Suitable for difficult model development process (Lahiri &amp; Ghanta, 2008) FFN Dynamic compositions Tennessee Eastman plant Reliable estimates upon calibration of the estimator (Yeh et al., 2003) ANN Lipase, biomass concentration Enzyme process (Experimental) Good estimation based only one online measured parameters (Linko, Zhu, &amp; Linko, 1999) RBFNN Permeate and residue hydrogen concentration, permeate gas flux Gas membrane separator Predict by omitting many boundary values (Wang et al., 2006) FFN Moisture content of bananas Fruit dehydration process Superior ability in predicting moisture content (Mohebbi et al., 2011) ANN Critical odour release Waste water treatment plant (refinery) Good prediction even when number of nodes are reduced (Kordon et al., 1996) (b) Fuzzy Logic as estimators in chemical process systems Fuzzy Takagi–Sugeno (FTS) Fouling parameters Heat exchanger Accurate estimate without any additional sensors (Delrot et al., 2012) Fuzzy Takagi–Sugeno (FTS) Specific CO2 evolution rate, specific O2 uptake rate Fermentor Eliminate defuzzification part since output can be directly obtained from rule part (Hisbullah et al., 2003) Fuzzy Energy efficiencies of ethylene Furnace High efficiencies, able to reduce more than 50% of the cost (Geng, Han, Gu, &amp; Zhu, 2012) Fuzzy Size of Algae population Wastewater treatment plant High accuracy that able to improve the runtime (Shen &amp; Chouchoulas, 2001) Intelligent Fuzzy Weighted Heat flux Thermal fluid hollow cylinder pipeline Fast convergence (Chen &amp; Lee, 2008) Fuzzy Product concentration Fed-batch reactor Easy design (Patnaik, 1997) Fuzzy matching Cost Chemical plant (Chem.</sentence>
    <sentence>Systems Ltd.) Accurate with minimal estimation effort (Petley &amp; Edwards, 1995) Fuzzy (Mamdani inferences) Biogas, methane production rate Digester Satisfactory performance with small deviation (Turkdogan-Aydınol &amp; Yetilmezsoy, 2010) Fuzzy c-means (FCM) Melt index Fluidized bed reactor Reduce input variables dimension (Liu, 2007) Fuzzy (Mamdani inferences) Fault on pH sensor and sodium hydroxide frequency Digestion reactor (Experimental) Satisfactory even with varied operating condition (Genovesi et al., 1999) (c) ES as estimators in chemical process systems ES Probability of odour Waste water treatment plant Good prediction even when number of nodes are reduced (Kordon et al., 1996) ES Effluent waste colour Wastewater treatment plant Provide early warning for further treatment process (Paraskevas, Pantelakis, &amp; Lekkas, 1999) ES Product flow, temperature Crude oil distillation column Able to minimise the error (Motlaghi et al., 2008) (d) GA as estimators in chemical process systems GA Size of Algae population Wastewater treatment plant High accuracy that able to reduce the cost (Shen &amp; Chouchoulas, 2001) GA Friction factor Helically coiled tubes (Experimental) High accuracy by improving the mean relative error (Beigzadeh &amp; Rahimi, 2012) GA Hydrogen concentration, temperature of coolant and reactant Catalytic reactor High conversion (Rezende et al., 2008) GA Temperature CSTR Minimize error between the estimated and set point temperature (Khairi Abdul Wahab et al., 2007) GA Moisture content of banana Fruit dehydration process Superior ability of on-line estimation (Mohebbi et al., 2011) GA Fuel input parameter Palm oil mill Consistent prediction (Ahmad, Azid, Yusof, &amp; Seetharamu, 2004) (e) Hybrid systems as estimators in chemical process systems FuREAP Size of Algae population Wastewater treatment plant High accuracy that able to improve the runtime (Shen &amp; Chouchoulas, 2001) ANFIS Compositions Multi-component reactive distillation column Reliable and accurate estimation (Khazraee &amp; Jahanmiri, 2010) FNN Fault signal in valve Control valve Good estimation despite model mismatch (Korbicz &amp; Kowal, 2007) FNN Melt index Polymerization reactor (Experimental) Able to settle the online training efficiency problem (Liu &amp; Zhao, 2012) FNN MW average Polymerization reactor Fast estimation (Chitanov, Kiparissides, &amp; Petrov, 2004) FNN Biomass concentration, viscosity Bioreactor Fast convergence (Araúzo-Bravo et al., 2004) ANFIS Emulsion stability Water-in-oil mixtures Satisfactory performance with small deviation (Yetilmezsoy et al., 2011) ANFIS Friction factor Helically coiled tubes High accuracy by improving the mean relative error (Beigzadeh &amp; Rahimi, 2012) HNN Injection time, injection pressure Plastic injection moulding process Small estimation error without the knowledge of injection moulding (Yarlagadda &amp; Teck Khong, 2001) HNN Product yield, gas compositions Fluidized bed gasifier Powerful estimator especially for complex process (Guo, Li, Cheng, Lü, &amp; Shen, 2001) HNN Monomer concentration Polymerization reactor Accurate estimation without the knowledge of model structure (Ng &amp; Hussain, 2004) HNN Monomer concentration, temperature Polymerization reactor Good validation results, fast convergence (Wei et al., 2007) HNN Liquid heads 3-tanks in series Able to handle noise and variation of the stochastic process (Wilson &amp; Zorzetto, 1997) HNN Food porosity Food drying process (Experimental) High accuracy based on increasing number of inputs (Hussain, Shafiur Rahman, &amp; Ng, 2002) SAHNN Reactants rates and concentration Batch reactor Fast convergence rate (Wang et al., 2011) HMNNRFM Reaction rate Fixed bed reactor Good prediction without use of model equation (Shiva Kumar &amp; Venkateswarlu, 2012) ANN-GA (GNN) Critical heat flux Heated tubes Fast convergence, consistent prediction (Wei, Su, Qiu, Ni, &amp; Yang, 2010) FFN-ES Silicon, sulphur compositions Furnace Small estimation error (Radhakrishnan &amp; Mohamed, 2000) Fuzzy-ES Froth density Flotation column (Experimental) Satisfactory despite variation in feed rate (Chuk et al., 2005) Fuzzy-GA Kinetic parameters Sulphuric acid catalyst preparation process Effective convergence, able to avoid premature convergence (Yang &amp; Yan, 2011) Fuzzy-Neural-GA Injection velocity and cooling water temperature Plastic injection moulding Good generalization capabilities (Li et al., 2002) Another AI-based algorithm that has been applied as estimators in chemical processes is the fuzzy logic approach.</sentence>
    <sentence>Fuzzy logic works on fuzzy sets that indicate the maximum limits of an element.</sentence>
    <sentence>By definition, it is a type of logic or multi-valued logic that distinguishes more than just TRUE and FALSE values.</sentence>
    <sentence>It can be represented with degrees of truthfulness and falseness in the range of [0,1] where 0 is absolute FALSE and 1 is absolute TRUE.</sentence>
    <sentence>It was introduced by Zadeh in 1964 through his paper on fuzzy sets and the application has become very popular since 1987 (Negnevitsky, 2005).</sentence>
    <sentence>Fuzzy logic consists of several elements such as the linguistic variable and values, fuzzy rules, membership function, fuzzy inference and defuzzification.</sentence>
    <sentence>These details may be found in several references (Leondes, 1998; Yetilmezsoy, Fingas, &amp; Fieldhouse, 2011).</sentence>
    <sentence>Fuzzy Takagi Sugeno, Fuzzy Mamdani inferences and Fuzzy-C-means are among the fuzzy logic structures that have been used to develop estimators in chemical process units.</sentence>
    <sentence>Fuzzy logic has been applied as estimators due to their simple formulation and ability to accurately describe imprecise values of parameters, for example temperature, speed and height.</sentence>
    <sentence>Nevertheless, one disadvantages of fuzzy logic is that the results sometimes depend on the number of rules, inference systems and the type of membership function applied.</sentence>
    <sentence>Furthermore, there is no guideline to obtain them but with trial and error or based on past experiences similar to ANN (Delrot, Guerra, Dambrine, &amp; Delmotte, 2012; Frank &amp; Köppen-Seliger, 1997; Liu, 2007).</sentence>
    <sentence>Table 2.2(b) lists out all the application of fuzzy logic as estimators in chemical process systems.</sentence>
    <sentence>Apart from ANN and fuzzy logic, expert systems (ES) and genetic algorithms (GA) have also been applied to build estimators in several chemical process systems.</sentence>
    <sentence>ES is an intelligent system that can provide information and expert advice and is also known as Knowledge-Based-Expert-System as it depends on large amount of knowledge to solve problems.</sentence>
    <sentence>There are basically five types of Expert System namely Rule-Based ES, Frame-Based ES, Case-Based ES, Fuzzy ES and Neuro-Fuzzy ES.</sentence>
    <sentence>Rule-Based ES is an expression of knowledge in the form of rules to solve problems.</sentence>
    <sentence>It is divided into two parts which are IF: Antecedent (premise/condition) and THEN: Consequent (conclusion/action).</sentence>
    <sentence>If there are many antecedents, the operator AND as well as OR is used to combined them all.</sentence>
    <sentence>These rules are the most popular type of knowledge representation.</sentence>
    <sentence>ES has been applied as estimators due to its ability in expressing relations, recommendations, directives, strategies and heuristics.</sentence>
    <sentence>It has five basic components namely knowledge base, database, inference engine, explanation facilities and user interface (Rich &amp; Knight, 1991) as depicted in Fig 2.2 (Kishan, Chadha, &amp; Maini, 2012).</sentence>
    <sentence>However, it is seldom applied as estimators since it is limited in its capability to narrow down the problems domain (Krishnamoorthy &amp; Rajeev, 1996) and it also only generates one solution at a time.</sentence>
    <sentence>This can be seen in Table 2.2(c).</sentence>
    <sentence>An alternative solution is the GA, whereby it is able to generate many feasible solutions and allow researchers to choose from several approaches for obtaining best results (Krishnamoorthy &amp; Rajeev, 1996).</sentence>
    <sentence>Components of an expert system Fig 2.2.</sentence>
    <sentence>Components of an expert system.</sentence>
    <sentence>Picture taken from Kishan et al.</sentence>
    <sentence>(2012): A review of development and application of expert systems.</sentence>
    <sentence>The GA concept was first introduced by Holland in the 1970s with the aim to make computers do what nature does (Fernandez, 1996).</sentence>
    <sentence>In natural computation, chromosomes are blindly selected and are able to manipulate data into binary digits string.</sentence>
    <sentence>Each data is the artificial chromosome that consists of a series of binary elements or genes and is represented by digits known as encoding.</sentence>
    <sentence>Similarly, the evaluation process in GA will select the fittest chromosomes for mating and is expected to produce the fittest offspring within the chromosomes.</sentence>
    <sentence>However, since the selection is stochastic, the population will remain stable until a superior chromosome appears and this is one of its limitations, where the fittest genes will dominate the population for a long time.</sentence>
    <sentence>GA has also been applied widely in several areas including process control, transportation and pattern recognitions.</sentence>
    <sentence>Although GA provides good techniques in assisting decision making such as estimating parameters, it also depends on experience and heuristic method in order to obtain better mutations and generations.</sentence>
    <sentence>It may take several trial and errors steps before reaching the ideal new generations when this concept is applied (Mohebbi, Shahidi, Fathi, Ehtiati, &amp; Noshad, 2011; Porter Ii &amp; Passino, 1995).</sentence>
    <sentence>Table 2.2(d) provides examples of applications of GA as estimators for chemical process systems.</sentence>
    <sentence>Recently, researchers have developed algorithms that combined two or more AI methods in what is called hybrid systems.</sentence>
    <sentence>These algorithms are applied as estimators to overcome the limitations of the single algorithm and to further increase the estimator’s performances.</sentence>
    <sentence>For example, ANN will only allow reasoning from input to outputs and this can be overcome by using the adaptive neuro-fuzzy inference systems (ANFIS) (Yetilmezsoy et al., 2011).</sentence>
    <sentence>Normally, the combination utilised the advantages of each of the algorithms such as the hybrid neural network (HNN), ANFIS, fuzzy neural network (FNN) and expert system neural network (ES-NN) (Sivan, Filo, &amp; Siegelmann, 2007).</sentence>
    <sentence>Details of the applications of hybrid systems as estimators in chemical process systems are given in Table 2.2(e) and the types of hybrid systems are given in Table 2.3 with their advantages and limitations.</sentence>
    <sentence>Table 2.3.</sentence>
    <sentence>Comparisons of several hybrid systems structures.</sentence>
    <sentence>No.</sentence>
    <sentence>Types of Hybrid System Key Features Advantages Limitations 1 Adaptive Neuro-Fuzzy Inference System (ANFIS) • Construct input–output mapping based on human knowledge and simulated input–output data pairs • Consist of two parts: antecedent and conclusion • Minimize error by applying two learning algorithms (back propagation and hybrid) • Able to handle complex processes • Short learning time • Fast in reaching optimum results • Optimum structures are based on trial and error 2 Hybrid Neural Network (HNN) • Hybrid combination of neural network and first principle model • Fewer nodes • Less training time • Fast convergence • Bigger mean square error of the estimated parameters 3 Structure Approaching Hybrid Neural Network (SAHNN) • A hybrid type of neural network • Use approximate mechanistic equation for characterising the unmeasured variables • Rapid convergence • Suitable for certain parameters estimation only 4 Fuzzy Neural Network (FNN) • Contain theory of fuzzy logic and ANN • Implementation can be either from input to output or output to input • Accuracy depends on the number of data quality 5 Fuzzy-Rough Set (FuREAP) • Based on rough set and fuzzy logic theories • Reduce measurement and data set for reducing cost • Pre-processor is difficult to be optimised 6 Fuzzy-Expert Systems (Fuzzy-ES) • Combination of IF-THEN rules with expert systems • Able to solve problems involving variations in parameters • Reduce quantity of rules • Expression of fuzzy inference depends on the behaviour of the systems Most applications with AI-based estimators are designed using the MATLAB (Araúzo-Bravo et al., 2004; Bahar &amp; Özgen, 2010; Devogelaere et al., 2002; Ng &amp; Hussain, 2004; Patnaik, 1997; Silva, Pinotti, Cruz, Giordano, &amp; Giordano, 2008; Wang, Shao, Wang, &amp; Wu, 2006; Yarlagadda &amp; Teck Khong, 2001) and LabView software (de Canete, del Saz-Orozco, Gonzalez, &amp; Garcia-Moral, 2012) while others utilised their own software such as Simulation Sciences code (PROCESS) (Himmelblau, 2008), Siemens Adaptive Modelling of Dynamic System (SIAMOD) (Horn, 2001), GENSYM G2 (Kordon, Dhurjati, &amp; Bockrath, 1996), DataFit (Turkdogan-Aydınol &amp; Yetilmezsoy, 2010) (Yetilmezsoy et al., 2011), ANSYS Fluent CFD (Delrot et al., 2012) and DAMADICS (Korbicz &amp; Kowal, 2007) to develop the estimators for their systems.</sentence>
  </section>
  <section name="Guidelines with examples of application">
    <sentence>In this section, we provide the general guidelines on how to select the appropriate AI algorithm to be applied as estimators with example of some typical applications in order to clearly show how to develop AI-based estimators for chemical process systems.</sentence>
    <sentence>Although, the AI-based estimators can be designed without full knowledge of the process kinetics, we will still use the process model to highlight the nonlinearity of the process.</sentence>
    <sentence>Determining the process model and understanding the behaviour of the process is the first step in designing the AI-based estimators.</sentence>
    <sentence>This is followed by defining the estimated parameters for the specific system such as concentration, temperature, melt index and pressure.</sentence>
    <sentence>Once both the behaviour and the estimated parameters have been identified, researcher may proceed to choose the appropriate algorithm to be used.</sentence>
    <sentence>The variety of those algorithms makes it difficult to decide the most suitable algorithm, thus a guideline as depicted in Fig 3.1 is helpful in assisting researchers in selecting the algorithm.</sentence>
    <sentence>In this paper, we consider five major algorithms that have been applied as estimators in chemical process systems namely ANN, fuzzy logic, GA, ES and the hybrid systems.</sentence>
    <sentence>Each algorithm differs in terms of formulations and has their own advantages as well as limitations.</sentence>
    <sentence>The comparisons regarding advantages, limitations and practical implications of all the algorithms are given in Table 3.1, which will also help in deciding the combination of the hybrid systems, which is developed based on the advantages of individual algorithms.</sentence>
    <sentence>Guideline for choosing AI-based estimators Fig 3.1.</sentence>
    <sentence>Guideline for choosing AI-based estimators.</sentence>
    <sentence>Table 3.1.</sentence>
    <sentence>Comparisons of AI algorithms applied as estimators in chemical process systems.</sentence>
    <sentence>AI algorithm Advantages Limitations Practical implications ANN Able to learn based on historical data, high accuracy and consistent estimations when changes occur No specific numbers of the hidden neurons and it is always based on trial and error Increase in the accuracy for measurement of parameters in highly nonlinear systems Fuzzy logic Simple formulation, easy to design and able to accurately describe imprecise values of parameters Depends on the number of rules, inference systems and the type of membership function applied Applicable for imprecise definition of parameters in difficult-to-model systems GA Generate many feasible solutions and allow researchers to choose from several approaches for obtaining best results Several trial and errors before reaching the ideal new generations when this concept is applied Able to choose best estimation results from several generated solution for complex systems ES Ability in expressing relations, recommendations, directives, strategies and heuristics Generates one solution at a time and expert knowledge must be available Able to estimate parameters using one accurate solution for nonlinear systems Hybrid systems Overcome the limitations of the single algorithms and to increase the estimation performances, faster estimation with more error reduction The formulation is not simple and require more time to be developed Improve in the estimation performances, thus allow better estimation especially in dealing with disturbances in processes In order to apply ANN, the data to be used for training and validation must be sufficient to obtain the best results (Lashkarbolooki et al., 2012) while fuzzy logic is normally applied since it can clearly describe the imprecision in the parameters and its ability in avoiding vagueness in the estimation results (Genovesi, Harmand, &amp; Steyer, 1999; Liu, 2007).</sentence>
    <sentence>GA on the other hand, is applicable for process system which is easy to apply the mutation concept and for generating many feasible solutions to choose from while ES is applied for estimation cases in less nonlinear systems where only one solution is sufficient to obtain the best performance (Krishnamoorthy &amp; Rajeev, 1996).</sentence>
    <sentence>These are the single AI algorithms applied as estimators in chemical process systems and once they have been chosen, the AI-based estimators will be design and validation test will be conducted to observe the performances and upon achieving satisfactory outcomes, the development of AI-based estimators is complete (Chen &amp; Lee, 2008; Motlaghi, Jalali, &amp; Ahmadabadi, 2008; Rezende, Costa, Costa, Maciel, &amp; Filho, 2008; Sharma et al., 2004).</sentence>
    <sentence>However, if the results are unsatisfactory, hybrid approach including the hybrid algorithms should be considered.</sentence>
    <sentence>Hybrid systems are applied to overcome the limitation of any single algorithm including slow rate of estimation and high estimation error but the combination will strongly depend on the behaviour of the system (Li, Jia, &amp; Yu, 2002).</sentence>
    <sentence>Similarly, these hybrid systems will have to be evaluated to observe their performances.</sentence>
    <sentence>As for the first example, we choose the ANN applied as the estimator since it is the most promising method.</sentence>
    <sentence>We refer the reader to the guideline in Fig 3.1 and the AI-based estimation research by Aziz, Hussain, and Mujtaba (2000).</sentence>
    <sentence>First of all, the estimated parameter is selected, which is the amount of heat released, from a jacketed batch reactor, where the reaction is exothermic.</sentence>
    <sentence>Then, the kinetics information will be defined before choosing the appropriate AI algorithm to be used as the estimator.</sentence>
    <sentence>Based on the information, data available is sufficient for applying ANN and it has been proven to be fast and accurate in estimating unknown parameters (Hussain, 1999).</sentence>
    <sentence>The design will proceed with a three layered feed forward neural network with 18 hidden nodes used and the training is based on the Levenberg–Marquardt methodology (Aziz et al., 2000).</sentence>
    <sentence>The process model is also required to relate the reactor temperature, , jacket temperature, and the energy balance with one another as given below.</sentence>
    <sentence>(3.1) (3.2) (3.3) (3.4) (3.5) (3.6) (3.7) Here is the heat input, and are the heat of reactions, and are the rate of reactions, and are the constant reaction rates, is the overall number of moles, , , and are the number of moles for component A, B, C and D respectively.The input layers consist of both present and past values of the reactor and jacket temperature as well as the past heat-release values whereas the output layer will estimate the current heat-release values.</sentence>
    <sentence>Using 6 inputs, the neural network is trained through the forward modelling methodology to obtain the present value of (the output).</sentence>
    <sentence>A constant bias is added to the hidden () and output layer () node where () and () are the weights.</sentence>
    <sentence>The data are moved forward at one discrete-time interval until all are fed into the network in a moving window scheme and are continued repeatedly until it achieves the training error criterion.</sentence>
    <sentence>A cross-validation based early stopping mechanism is implemented and neural network is validated with new set of data, which has not been used during training.</sentence>
    <sentence>The input and output variables are shown in Table 3.2 while the topology of the multi-layered ANN is given in Fig 3.2.</sentence>
    <sentence>The validation result is seen in Fig 3.3, and since the validation shows no discrepancies between actual and estimated values the design of the estimator using ANN can be finalized.</sentence>
    <sentence>Table 3.2.</sentence>
    <sentence>Input–output neural network mapping.</sentence>
    <sentence>Topology of the ANN Fig 3.2.</sentence>
    <sentence>Topology of the ANN.</sentence>
    <sentence>Heat-release estimated using ANN Fig 3.3.</sentence>
    <sentence>Heat-release estimated using ANN.</sentence>
    <sentence>Another example is applying fuzzy logic as estimator to predict the specific CO2 evolution rate, and specific O2 uptake rate, in a fermentor studied by Hisbullah, Hussain, and Ramachandran (2003).</sentence>
    <sentence>Those parameters are estimated to find the differences of both rate to be applied in the fermentor as set point for maintaining the glucose level for obtaining the optimum productivity and yield in the process.</sentence>
    <sentence>The estimator is based on the Takagi–Sugeno inference method which consists of fuzzification and IF-THEN rules.</sentence>
    <sentence>The input variables are the process error, and the change of the error, while output variables are the feed rate, .</sentence>
    <sentence>Those variables are as follows: (3.8) (3.9) (3.10) First, the set point of both rate is considered and the present value (initial estimated value of is assumed and the error is obtained as .</sentence>
    <sentence>Then, the change of error is calculated based on Eq (3.9) and the fuzzy estimator is applied to obtained the present value of based on the desired output value, .</sentence>
    <sentence>The rules for the estimation is given below with linguistic term of = zero, = negative and = positive.</sentence>
    <sentence>(1) (2) (3) (4) (5) (6) The results are shown in Fig 3.4 where the actual values of are in good agreement with the fuzzy estimated values and the advantage of this estimator is being able to achieve good performance, even for a difficult-to-estimate process parameter.</sentence>
    <sentence>Estimation of (Qc-Qo) using fuzzy logic Fig 3.4.</sentence>
    <sentence>Estimation of ( using fuzzy logic.</sentence>
    <sentence>Picture taken from Hisbullah et al.</sentence>
    <sentence>(2003): Design of a fuzzy logic controller for regulating substrate feed to fed-batch fermentation.</sentence>
    <sentence>For GA applied as estimator, we consider an example taken from Khairi Abdul Wahab, Azlan Hussain, &amp; Omar, 2007) that used GA to predict the coolant jacket temperature, in a CSTR in order to minimize the error of the reactor temperature, .</sentence>
    <sentence>The coolant temperature is normally not measured directly.</sentence>
    <sentence>The input used to generate the initial population is the reactor temperature, where the error between and is constantly monitored.</sentence>
    <sentence>If this monitored error is over the specified limit, a binary coolant jacket temperature (initial population) will be created and repeated to achieve the minimum error in the reactor temperature.</sentence>
    <sentence>The procedure involving selection of quasi-genetic, crossover and mutation are illustrated in Fig 3.5.</sentence>
    <sentence>GA procedure in predicting the reactor temperature Fig 3.5.</sentence>
    <sentence>GA procedure in predicting the reactor temperature.</sentence>
    <sentence>The selected operators evaluate the population based on the fitness function and emerge with the best individuals.</sentence>
    <sentence>Next, two individuals are randomly chosen and they reproduced new individuals during the crossover step.</sentence>
    <sentence>After that, mutation ability will enhance the method by injecting a random point for a better search in the entire parameters for estimating the temperature.</sentence>
    <sentence>This mutation step contained random value of elements of the chromosomes.</sentence>
    <sentence>The best fitness chromosomes that gave the smallest error will be chosen as the new estimated coolant jacket temperature.</sentence>
    <sentence>The results are illustrated in Fig 3.6 where the estimated temperature followed the set point or actual temperature.</sentence>
    <sentence>The estimated temperature versus the actual pilot plant temperature Fig 3.6.</sentence>
    <sentence>The estimated temperature versus the actual pilot plant temperature.</sentence>
    <sentence>Finally, HNN will be taken as the example to show how the hybrid systems act as an estimator.</sentence>
    <sentence>It is based on the work done by Hussain et al.</sentence>
    <sentence>(Wei, Hussain, &amp; Wahab, 2007) where HNN is applied for estimating monomer concentration in a polymerization reaction.</sentence>
    <sentence>Consider the mass balance of the monomer as follows: (3.11) Assuming the rate constant, is constant between sampling interval Eq (3.11) can be integrated to become: (3.12) where and is the concentration of monomer at sampling .</sentence>
    <sentence>Eq (3.12) is the simplified model that utilised HNN to estimate the rate constant prior to estimating the monomer concentration.</sentence>
    <sentence>The training of HNN is carried out in serial approach whereby the target data is the concentration and the output is the rate constant.</sentence>
    <sentence>Thus, the sensitivity equation is needed for converting the error of concentration to error of the rate constant and the sensitivity equation is given by Eq (3.13).</sentence>
    <sentence>(3.13) where The configuration of the training is illustrated in Fig 3.7 while network construction is listed in Table 3.3.</sentence>
    <sentence>Apart from that, the work also discussed the estimation of reactor temperature using HNN.</sentence>
    <sentence>A single hidden layer neural network with 8, 7 and 1 nodes at the input, hidden and output layers respectively gave the best model for predicting the concentration which is almost similar to the actual data.</sentence>
    <sentence>Besides that, HNN is faster and easier to be constructed with higher accuracy for the estimation.</sentence>
    <sentence>This is based on the small MSE of training results and validation as well as the validation graph as given in Fig 3.8.</sentence>
    <sentence>The network training configuration Fig 3.7.</sentence>
    <sentence>The network training configuration.</sentence>
    <sentence>Table 3.3.</sentence>
    <sentence>HNN network construction.</sentence>
    <sentence>estimation using HNN Input Target Neural network output Number of nodes (8, 7, 1) MSE for training 1 0.00029 MSE for training 2 0.000066 Validation 0.00013 Validation of Cm Fig 3.8.</sentence>
    <sentence>Validation of .</sentence>
  </section>
  <section name="Discussion and Future directions">
    <sentence>Hardware sensors and conventional observers have been widely applied to estimate the difficult-to-measure parameters in chemical process systems since 1991 before the establishment of the AI-based estimators.</sentence>
    <sentence>Hardware sensors have been applied to detect any disturbances in the process in chemical plants until today, despite the advantages of the software driven sensors.</sentence>
    <sentence>However, they are expensive to instal in most cases and require calibration from time to time.</sentence>
    <sentence>The sensing system in those hardware sensors has also intolerable large delays (Chuk, Ciribeni, &amp; Gutierrez, 2005).</sentence>
    <sentence>On the other hand, conventional observers such as the Extended Kalman Filter (EKF), asymptotic and exponential observers have also been applied as estimators since they offer good estimation with lower cost compared to the hardware sensors (Mohd Ali, Ha Hoang, Hussain, &amp; Dochain, 2015).</sentence>
    <sentence>However, most conventional observers will require accurate dynamic system models which may be difficult to obtain for complex chemical processes.</sentence>
    <sentence>Therefore in order to overcome these limitations, AI-based estimators have been introduced in the last 10 years or so.</sentence>
    <sentence>Another advantage of using AI-based estimators is that the design does not require perfect kinetic knowledge of the system model, which is at times difficult to be obtained based on the highly nonlinear behaviour of chemical process systems themselves.</sentence>
    <sentence>Besides that, these estimators are cheaper and able to reduce the installation and maintenance costs compared to hardware sensors.</sentence>
    <sentence>The computation time of AI-based estimator is fast and they are easy to implement with the wide range of softwares available such as MATLAB and LabView (Bahar &amp; Özgen, 2010; Brudzewski, Kesik, Kołodziejczyk, Zborowska, &amp; Ulaczyk, 2006; de Canete et al., 2012; Jalali-Heravi &amp; Fatemi, 2000; Rezende et al., 2008; Wang, Cao, Wu, Li, &amp; Jin, 2011).</sentence>
    <sentence>In addition, no calibration are needed and these AI-based estimators are easy to be implemented and adapted with little troubleshooting if operated and installed as per its design in a plant.</sentence>
    <sentence>The differences between AI-based estimators, conventional observers and hardware sensors are given in Table 4.1.</sentence>
    <sentence>Table 4.1.</sentence>
    <sentence>Comparisons of AI-based estimators, conventional observers and hardware sensors.</sentence>
    <sentence>AI-based estimators Conventional observers Hardware sensors 1.</sentence>
    <sentence>Does not require perfect model of the system and are mainly data-driven 2.</sentence>
    <sentence>Easy to be adapted for chemical plants 3.</sentence>
    <sentence>Fast computational time 1.</sentence>
    <sentence>Most conventional observers require available accurate dynamic system models 2.</sentence>
    <sentence>Adaptation require the mechanistic model of the system 3.</sentence>
    <sentence>Slow computational time 1.</sentence>
    <sentence>High cost for installation and maintenances 2.</sentence>
    <sentence>Calibration needed from time to time 3.</sentence>
    <sentence>Large time delay in some sensors These AI-based estimators have become popular lately and the trend has changed from single algorithms to hybrid systems including the AI algorithm combined with recent/conventional observers as depicted in Fig 4.1.</sentence>
    <sentence>The figure shows that the hybrid systems have been consistently increasing in its usage due to the availability of many types of AI algorithms that can be easily implemented in the advanced software tools available nowadays.</sentence>
    <sentence>Current and future trend of AI-based estimators Fig 4.1.</sentence>
    <sentence>Current and future trend of AI-based estimators.</sentence>
    <sentence>However, certain designs of these AI-based estimators are more complex in nature especially for the hybrid systems, hence their adaptation in chemical plants will be more tedious and time consuming (Beigzadeh &amp; Rahimi, 2012; Khazraee &amp; Jahanmiri, 2010; Ng &amp; Hussain, 2004; Yarlagadda &amp; Teck Khong, 2001).</sentence>
    <sentence>Besides that, if problems persist after the installation, experts are required to troubleshoot and maintain the estimators since normal operators may not be able to understand the background of the methodology of the program.</sentence>
    <sentence>Hence at present, the online implementations of the AI-based estimators are small (15%) compared to simulation for research and educational purposes (85%) as shown in Fig 4.2, based on the surveys from 1997 to 2010, due to these concerns.</sentence>
    <sentence>However, with the power of hardware and software computing improving tremendously in the last four years, the implementation of the AI-based estimators have become easier and more user friendly.</sentence>
    <sentence>These have led to the increase of its usage from 15% to 20% since 2010 to 2014 onwards as seen in Fig 4.2.</sentence>
    <sentence>AI estimator online and simulation applications (1997–2014) Fig 4.2.</sentence>
    <sentence>AI estimator online and simulation applications (1997–2014).</sentence>
    <sentence>In the future, it is envisioned that more AI-based estimators will be applied in chemical process systems and much easier design formulation of these estimators are developed for improving the current available design methodologies.</sentence>
    <sentence>Secondly, we expect that more pilot plant testing will be carried out using these estimators to convince the industrial community to implement them in their plants based on these real time testings.</sentence>
    <sentence>Furthermore, we suggest that more hybrid AI-based estimators such as ANFIS and HNN be implemented online in chemical plants for benefiting the plants in the long term but with the capability to adapt to changes online.</sentence>
    <sentence>In addition, those hybrid versions are suggested to be combined with the conventional observers such as ANFIS with EKF to further increase the performances in estimation.</sentence>
    <sentence>Besides that, we expect that specific toolbox for estimation is developed in software such as MATLAB and LabView to attract more users and industrial organisations to apply these methods in a more user friendly basis.</sentence>
    <sentence>The adaptive methods of these estimators should also be studied further and incorporated with control strategies such as model predictive control (MPC) to improve the overall estimation and control performances in real time.</sentence>
  </section>
  <section name="Conclusions">
    <sentence>The review has shown that many AI methods including ANN, fuzzy logic and hybrid systems have been extensively applied in developing estimators for predicting the unmeasured parameters in chemical process systems.</sentence>
    <sentence>They offer simple formulation without perfect knowledge of the system model, are easy to implement, adapt and able to overcome long time delays.</sentence>
    <sentence>Furthermore, in terms of costing, it is cheaper to employ this computational algorithm rather than using the expensive hardware sensors that need to be calibrated from time to time.</sentence>
    <sentence>ANN is applied due to its accuracy while fuzzy logic is utilised based on the simple design and easy interpretation.</sentence>
    <sentence>In addition, GA is applied to allow many feasible solutions to be generated and ES is used when one solution is sufficient to obtain the best estimation result.</sentence>
    <sentence>The guideline in choosing the suitable AI algorithm is provided together with the typical examples of application aim to help researchers in developing the AI-based estimators.</sentence>
    <sentence>We have also discussed the advantages, limitations, practical implications and future research suggestion, all of which are the important contributions of this paper.</sentence>
    <sentence>The development of these AI-based estimators for application online is also active research area of the present moment and we foresee more applications in the future with this approach in real systems.</sentence>
    <sentence>Appendix A A.1.</sentence>
    <sentence>Improving neural network generalisation One common problem in neural network modelling is the poor generalisation due to over fitting noise in the data or under fitting of the data.</sentence>
    <sentence>Over-fitting and under fitting are the main problems in developing neural network models.</sentence>
    <sentence>In over-fitting, the error on the training data set is driven to a very small value due to fitting of the noise, but when the network is applied to unseen data, the network error is large leading to poor generalisation capability.</sentence>
    <sentence>While under fitting is due to that the neural network itself cannot cope with or fails to capture the relationship within the complex data (Guyon &amp; Yao, 1999).</sentence>
    <sentence>Many techniques have been introduced to improve the generalisation capability of neural network models like regularisation techniques (Caruana et al., 2001; Hagiwara &amp; Kuno, 2000; Mc Loone &amp; Irwin, 2001), Bayesian Learning e.g.</sentence>
    <sentence>(Crucianu et al., 2001; Neal, 1995) and also by using the parsimonious networks structure (Zhang &amp; Morris, 1998).</sentence>
    <sentence>The most exceptional model for this approach is network pruning techniques and sequential orthogonal training techniques.</sentence>
    <sentence>A sequential orthogonal training technique gradually builds up a neural network model and avoids unnecessarily large networks structure (Zhang, 2002; Zhang &amp; Morris, 1998).</sentence>
    <sentence>Some of the techniques are summarised below.</sentence>
    <sentence>A.2.</sentence>
    <sentence>Regularisation Training with regularisation techniques overcomes the problem of over-fitting by avoiding unnecessarily large network weights.</sentence>
    <sentence>Regularisation is achieved by modifying the network training objective function to include a term to penalise unnecessarily large network weights as follows: (A.1) where N is the number of data point, is the network prediction, y is the target value, W is a vector of network weights, and ρ is the regularisation parameter.</sentence>
    <sentence>The objective of regularised training is to penalise excessively large network weights, which do not contribute significantly to the reduction of model errors, so that the trained neural network has smooth function surface.</sentence>
    <sentence>An intuitive interpretation of this modified training objective function is that a weight that does not influence the first term very much will be kept close to zero by the second term and a weight that is important for model fit will, however, not be affected very much by the second term (Zhang, 2001).</sentence>
    <sentence>Cross validation is the most convincing approach to define the regularisation parameter e.g.</sentence>
    <sentence>(Morgan &amp; Bourlard, 1989; Touretzky, 1990).</sentence>
    <sentence>A.3.</sentence>
    <sentence>Cross validation based “early stopping” Early stopping method is a commonly used technique in overcoming over-fitting.</sentence>
    <sentence>In cross validation techniques neural network building data are divided into testing and training data sets and the sum square error (SSE) for both are monitored during training.</sentence>
    <sentence>When the testing SSE starts to rise, stop the training and use the network weights at the previous training step are taken as the trained network weights.</sentence>
    <sentence>The SSE behaviour on testing and training data sets is shown in Fig A.1.</sentence>
    <sentence>Neural network learning curve Fig A.1.</sentence>
    <sentence>Neural network learning curve.</sentence>
    <sentence>A.4.</sentence>
    <sentence>Bayesian learning method The Bayesian learning framework was first applied to neural networks by Buntine and Weigend (1991), MacKay (1992), Neal (1995).</sentence>
    <sentence>There are several reasons that can explain on how the Bayesian learning rule increases the robustness of neural networks.</sentence>
    <sentence>First, instead of finding an estimate for the mean prediction of the models, it obtains an estimate for the entire distribution of model prediction.</sentence>
    <sentence>This estimate, which is take into account both the noise in the data and the variance of the models, which is valuable to evaluate the confidence for the individual prediction (Lampinen &amp; Vehtari, 2001).</sentence>
    <sentence>A.5.</sentence>
    <sentence>Bootstrap aggregated neural networks A more effective approach for improving neural network generalisation is through combining multiple neural networks (Zhang, 1999a, 1999b; Zhang et al., 1997).</sentence>
    <sentence>Recognising the difficulty in building a perfect neural network model, this technique builds several imperfect neural network models and then combines them in order to improve model robustness and reliability.</sentence>
    <sentence>An intuitive interpretation of this technique is that individual networks can have random prediction errors and, by combining a large number of models, these random prediction errors can be averaged out leading to small prediction errors.</sentence>
    <sentence>A key to the successful implementation of this technique is that the individual models must be different, e.g.</sentence>
    <sentence>developed on different parts of the training data.</sentence>
    <sentence>Zhang (1999a, 1999b) proposes developing a number of neural networks on different bootstrap replications of the training data and then combing the individual neural networks using principal component regression.</sentence>
    <sentence>A.6.</sentence>
    <sentence>Curse of dimensionality Curse of dimensionality normally occurs in the high-dimensional settings during the analysing and organising data.</sentence>
    <sentence>In neural network, the information will increase when there is increment in the number of dimensions, thus more samples are required to avoid memorising the data by the neural network algorithm.</sentence>
    <sentence>This situation is called ‘curse of dimensionality’ and can be prevented by methods proposed in Appendix A.1, Appendix A.2 and Appendix A.3 previously (Priddy &amp; Keller, 2005).</sentence>
    <sentence>A.7.</sentence>
    <sentence>Local minima related problem to ANN Local minima have been identified as the major obstacle to neural network training during practical application of multilayer network in the standard back propagation technique.</sentence>
    <sentence>Network normally failed to train upon reaching the local minimum and many approaches have been made to overcome this, example by using the mutation concept in the neural network algorithm to allow “jump out” from the local minima for continuing training (Ytlcetiirk et al.,1999) and by use of a large quantity of tests set to ensure that the optimization is global in nature (Wang et al., 2007).</sentence>
  </section>
</article>
