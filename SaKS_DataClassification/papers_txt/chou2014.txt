Optimizing parameters of support vector machine using fast messy genetic algorithm for dispute classification

Abstract

Hybrid system is a potential tool to deal with construction engineering and management problems. This study proposes an optimized hybrid artificial intelligence model to integrate a fast messy genetic algorithm (fmGA) with a support vector machine (SVM). The fmGA-based SVM (GASVM) is used for early prediction of dispute propensity in the initial phase of public–private partnership projects. Particularly, the SVM mainly provides learning and curve fitting while the fmGA optimizes SVM parameters. Measures in term of accuracy, precision, sensitivity, specificity, and area under the curve and synthesis index are used for performance evaluation of proposed hybrid intelligence classification model. Experimental comparisons indicate that GASVM achieves better cross-fold prediction accuracy compared to other baseline models (i.e., CART, CHAID, QUEST, and C5.0) and previous works. The forecasting results provide the proactive-warning and decision-support information needed to manage potential disputes.

Keywords
Classification model
Hybrid intelligence
Optimization
Support vector machine
Fast messy genetic algorithm
Dispute prediction
Project management

1. Introduction

Data mining (DM) has attracted great scientific interest and has become an important research area. Major DM methods include predictive modeling (supervised learning in machine learning, i.e., classification and regression problems), clustering and association (unsupervised learning), evolution, pattern matching, data visualization and meta-rule guided mining (Liao, Chu, & Hsiao, 2012). In particular, classification is one of the important missions in data mining (Ngai, Xiu, & Chau, 2009). The DM- and AI-based approaches are related to computer system programs that attempt to resolve problems by emulating human brain processes (Garg, Rani, & Sharma, 2014; Hajdasz, 2014; Irani & Kamal, 2014; Khashei, Zeinal Hamadani, & Bijari, 2012). Therefore, the use of AI-based models is a potential tool to deal with classification problems in construction engineering and management.

Notably, a global trend has become interested for financial public investment via Public Private Partnership (PPP) which is a financial strategy for stimulating private investments in public works. PPP have proved to be a useful and beneficial instrument. However, PPP project involve a variety of organizations and a large number of partnerships as well as exist high risk and uncertainty. Dispute between parties to projects are of great concern to the construction industry (Fenn, Lowe, & Speck, 1997; Tang, Shen, & Cheng, 2010). These problems are also influenced by highly variable and unpredictable factors. Because of these difficulties and the importance of enhancing forecast capability, algorithms with complexity approaching that of integrated models have been developed to improve modeling accuracy, effectiveness and speed (Chou & Lin, 2013; Donis-Díaz, Muro, Bello-Pérez, & Morales, 2014; Pai, Hung, & Lin, 2014; Seera & Lim, 2014; İlhan & Tezel, 2013). However, enhancing the generational capability of advanced DM techniques is still in need for the PPP-related projects.

Taiwan has legally supported PPP projects for more than ten years. The Taiwan Public Construction Commission (TPCC) has actively promoted and encouraged private-sector participation in infrastructure and building construction throughout Taiwan. According to the TPCC, the dispute rate was 23.6% during 2002–2009. The most common processes for handling disputes are mediation or non-mediation (e.g., arbitration, litigation, negotiation, and administrative appeals) procedures. In Taiwan, up to 84% of PPP projects are settled by mediation or negotiation within only 1–9 months after disputes occurs (PCC., 2010). Notably, arbitration or litigation costs all parties considerably more time and money when a mediated agreement cannot be reached. To address these challenges, the proposed classification approaches predict propensity for project claims providing supportive information needed by governmental authority to furnish contact documents in the preparatory and bidding phases of PPPs.

Moreover, the dispute between PPP participantes commonly occur unexpectedly and may involve many issues, including surety bond issue, sub-contractor qualifications, licenses, permits, investment scale, resident rights, government guarantees, excessive profits, operating period, taxation, and default loan commitment (Jones, 2006). Numerous studies show that an efficient, effective, and fair dispute resolution process is essential for PPP project success (Cheung, 1999; Cheung, Suen, & Lam, 2002; Cheung, Yiu, & Chan, 2010; Chou & Lin, 2013; Goetz & Gibson, 2009; Menassa & Peña Mora, 2010). Therefore, development of intelligence models can enable early warming of potential dispute resolutions prior to project initiation to be becoming crucial.

Several studies have attempted to develop the hybrid AI models (Hsiao, Wang, Wang, Wen, & Yu, 2012; Irani & Kamal, 2014; Khashei et al., 2012; Lee, Rajkumar, Lo, Wan, & Isa, 2013; Seera & Lim, 2014) by combining one with other techniques to enhance their performance results, such as combination of genetic algorithm and support vector machine (Fei & Zhang, 2009; Huang & Wang, 2006; Jiao & Liu, 2011; Zhao, Fu, Ji, Tang, & Zhou, 2011; İlhan & Tezel, 2013). Particularly, the mechanism for setting tuning parameters in AI models is an important issue that is widely recognized by scholars in many different disciplines (Donis-Díaz et al., 2014; J. Huang, Bo, & Wang, 2011; Pai et al., 2014; İlhan & Tezel, 2013). In practice, identifying the best set of parameters for a model is an optimization problem. Therefore, integrating AI-based models with nature-inspired algorithms has been proposed as a solution to the above problems.

Advanced AI-based approaches include support vector machine (SVM), which is a machine learning technique with advanced features that enable good generalization and fast computation. The SVM has been demonstrated very powerful in solving classification problems (Lin, 2002). Although the SVM model has proven highly effective for solving classification problems, it has major drawbacks (Jiao & Liu, 2011). The accuracy of the SVM model depends on parameters set in advance. For such need, fast messy genetic algorithms (fmGA)-based method developed by Goldberg, Deb, Kargupta, and Harik (1993) is known for its flexibility in allowing hybridization with other methodologies to obtain enhanced solutions (David E. Goldberg et al., 1993). The primary difference between an fmGA and other genetic algorithms is its ability to manipulate explicit building blocks of genetic material to obtain global optimization (Hettiarachchi, Noman, & Iba, 2013; Wu, 2005). The fmGA can efficiently find the optimal solution of the large-scale permutation problems (Knjazew, 2002). These advantages make fmGA logical candidates for overcoming the disadvantages of SVM.

The aim of this study, thus, is to employ an auxiliary hybrid technique which SVM will call fmGA as subroutine to optimize its structure parameters. The fmGA-based support vector machine (GASVM) enhance their efficacy to early predict PPP dispute likelihood and potential resolutions, thereby alleviating the future adverse effects of disputes on project delivery, operation, and transfer from a governmental prospective. To demonstrate the efficacy of proposed hybrid system, this study used PPP project data collected by TPCC and compared well-known classification and regression-based models (e.g., CART, CHAID, QUEST, and C5.0) using classification performance measure in term of accuracy, precision, sensitivity, specificity, area under the curve and synthesis index. For avoid bias from data (Kohavi, 1995), cross-fold validation was also executed.

The rest of this study is organized as follows. Section 2 thoroughly reviews AI literature and the application of AI to predict construction claims and litigation outcomes. Section 3 characterizes the research methodology, providing a theoretical basic for classification performance models and elaborates on the GASVM model proposed in this study. Section 4 describes and analyzes numerical example and analytical outcomes using classification performance measures. Conclusions are given in Section 5, along with directions for further research.
2. Literature review

The hybrid AI and forecasting techniques are widely used in various engineering and management fields (Hsiao et al., 2012; Huang & Wang, 2006; Kim & Kang, 2012; Kim & Shin, 2007; Moosmayer, Chong, Liu, & Schuppar, 2013), and have been demonstrated to enhance overall performance. Nevertheless, their effectiveness and efficiency are rarely applied in the construction industry, particularly in public–private partnership (PPP) project domain. To support the dispute resolution process, several varieties of tools and systems have been developed (Chong, Mohamad Zin, & Chong, 2012; El-Adaway & Kandil, 2010; Ilter, 2012; Jin & Zhang, 2011; Kassab, Hegazy, & Hipel, 2010; Seifert, 2005). Applying these techniques is useful for both researchers and practitioners to better understand the complex nature of PPP project. Since a dispute always takes in numerous complex and interconnected factors that are difficult to rationalize, using DM techniques is now among the most effective methods for improving prediction accuracy related to some cases such as construction litigation (Chau, 2006; Chau, 2007; Pulket & Arditi, 2009a; Pulket & Arditi, 2009b); construction procurement litigation (Arditi & Pulket, 2010); and change-order-triggered disputes (Chen, 2008; Chen & Hsu, 2007).

Arditi and Tokdemir (1999) have developed several models on the same dataset using AI techniques to enhance prediction result in conventional construction procurement litigation as a prediction accuracy of 83.33% was achieved with a case-based reasoning (Arditi & Tokdemir, 1999), 89.95% was achieved with boosted decision trees (Arditi & Pulket, 2005), and 91.15% was attained with integrated prediction modeling (Arditi & Pulket, 2010). Moreover, their studies have attempted to minimize the number of construction litigation cases by using neural network to predict the likely court rulings and obtained a prediction rate of 67% for litigation outcomes (Arditi, Oksay, & Tokdemir, 1998). They argued that if outcome of construction litigation can be predicted with higher accuracy and reliability by using these approaches, all parties involved in the construction process could save considerable money, time, and aggravation.

Furthermore, Chau (2006) found that excluding the above case studies, AI techniques are rarely applied in the legal field (Chau, 2006). Thus, Chau utilized AI techniques based on particle swarm optimization (PSO) to predict construction litigation outcome, a filed in which relatively new DM techniques are rarely applied. The PSO-based ANN technique developed by Chau obtained the rate of prediction is up to 80%, which is much higher than chance. However, Chau suggested using additional case factors related to cultural, psychological, social, environmental, and political features in the future work.

The other AI techniques were used for construction dispute. In case of changing orders of construction process and design, Chen (2008) developed a K nearest neighbor based knowledge sharing model, which obtained 84.38% accuracy in predicting lawsuits based on a nationwide study of US court records (Chen, 2008). Chen and Hsu (2007) further employed hybrid ANN-CBR model with disputed change order dataset to achieve early-warm information. The ANN classifier demonstrated comparable prediction accuracy (84.61%) (Chen & Hsu, 2007). In case of dispute settlement, Cheng, Tsai, and Chiu (2009) refined and improved the conventional CBR approach by combining fuzzy set theory with a new similarity measurement that integrates Euclidean distance and cosine angle distance (Cheng et al., 2009). Their model successfully extracted the knowledge and experience of experts from 153 historical construction dispute cases collected manually from multiple sources.

Several studies have demonstrated that hybrid AI schemes generate promising results in many industries (Chen & Hsu, 2007; Donis-Díaz et al., 2014; Hettiarachchi et al., 2013; Kim & Shin, 2007; Lee, 2009; İlhan & Tezel, 2013). For instance, Kim, Yoon, An, Cho, and Kang (2004) applied the back-propagation network (BPN) model incorporating GA in optimizing both the neural network size and its parameter (Kim et al., 2004). The combined model showed that was more effective and accurate in estimating construction costs than BPN model using trial and error. Wu, Tzeng, and Lin (2009) developed a hybrid GASVM model to forecast the maximum electrical daily load by using GA to optimize kernel function and kernel parameters of SVM. This model outperformed any other model employed in the European Network on Intelligent Technologies for Smart Adaptive Systems network (Wu et al., 2009).

Similarly, Chen (2007) employed GASVM model to predict engine system reliability. To build an SVM model efficiently, model parameters were optimized as regularization parameter C, bandwidth of the kernel function σ2, and the tube size of ε-insensitive loss function. The experimental results demonstrated that GASVM model forecast more precise than ANN model and traditional autoregressive integrated moving average model (Chen, 2007). Moreover, the model proposed by Hsiao et al. (2012) integrated the component ratios method, fuzzy adaptive learning control network, fmGA, and three-point cost estimation method to solve cost-estimating problems under conditions of limited and uncertain data (Hsiao et al., 2012). In this sense, hybrid approaches are considered a promising research area in the near future (Seera & Lim, 2014).

Additionally, Chau (2006) utilized a split-step PSO algorithm which is employed to train multi-layer perceptions for prediction of the outcome of construction litigation (Chau, 2006), its performance is much better than the benchmark backward propagation algorithm and conventional PSO algorithm. Using the same dataset in this study, Chou and Lin (2013) proposed an ensemble approach by combining best models to predict dispute propensity in PPP projects (Chou & Lin, 2013). Their study demonstrated that the proposed ensemble model (i.e., SVM + ANNs + C5.0) was more accurate than single models with prediction accuracy of 84.33%.

Generally, most of above related works focused on either specific change-order disputes or conventional contracting projects. Management personnel typically is beneficial when the taskforce has a decision-support tool for forecasting dispute propensity and for early planning of how disputes should be resolved before project initiation (Marzouk, El-Mesteckawi, & El-Said, 2011). However, prediction problems are often complex because they involve substantial uncertainty, vagueness, and incomplete or inexact data. Therefore, the inference process must fit environmental conditions (Mareels & Polderman, 1996).

Since humans can process and solve complex problems, even those involving uncertainty, imprecision, and incomplete information, imitating human inference is an effective approach for predicting disputes. Characteristics and environments for construction projects under the PPP strategy differ significantly from the contractor-owner relationships which require effective tools via hybrid AI algorithms. Thus, the proposed model in this study combines fmGA and SVM (GASVM), which is still open to techniques in the PPP domain knowledge, to possibly provide improved dispute classification accuracy. Modeling performance is then compared with several well-known classification models and previous works.
3. Research methodology
3.1. Classification-based models

When response variable is categorical rather than continuous, prediction problems become data classification problems. Classification techniques are based on learning from examples that map input vectors into one of several desired output classes. This work used four classification-based techniques as baseline models (i.e., CART, Exhaustive CHAID, QUEST, and C5.0) for automatically creating and comparing default models of binary numerical outcomes. Moreover, these techniques use different learning mechanisms that are worth of investigating in the case of dispute classification. Default values were set in numerical predictor nodes using the IBM SPSS modeler (IBM., 2010), a powerful and versatile data analytics workbench, to develop the classification and regression-based models in predicting PPP project dispute.
3.1.1. CART and QUEST

Classification and regression tree (CART) technique recursively partitions data into increasingly homogenous subsets (Breiman, Friedman, Olshen, & Stone, 1984). Each of the two subsets is recursively split until the homogeneity criterion or some other stopping criterion is met. Decision tree methods are far superior to other modeling techniques in terms of logic rules. A relatively new binary-split decision tree algorithm used for data classification is QUEST (Quick, Unbiased and Efficient Statistical Tree). The QUEST algorithm resembles CART except that QUEST uses an unbiased variable selection technique by default and uses imputation instead of surrogate splits to compensate for missing values. Therefore, QUEST is suitable for selecting categorical predictor variables with multiple categories (Loh & Shih, 1997).
3.1.1. C5.0

Another classification technique recently developed by Quinlan (2007) is C5.0 (Quinlan, 2007). The decision trees were obtained by the greedy algorithm use boosting technology to improve accuracy in identifying samples. The top-down approach (divide-and-conquer) to decision tree induction starts with a training set of tuples and their associated class labels. The tree is constructed by recursively partitioning the training set into smaller subsets (Tan, Steinbach, & Kumar, 2006). The main difference between CART and C5.0 is that the former performs only binary splits, which gives binary trees, whereas the latter performs a split for each category, which gives a “bushlike” structure. A good alternative to limiting tree growth is pruning the full-grown tree. The CART and CART-like procedures use validation data to prune deliberately overgrown trees by using training data whereas C5.0 uses training data for both growing and pruning the tree (Shmueli, Patel, & Bruce, 2007).
3.1.2. Exhaustive CHAID

Exhaustive Chi-squared Automatic Interaction Detector (Exhaustive CHAID) avoids over-fitting the full-grown tree to the training data by continuously merging predictor categories until only two super categories remain. The algorithm also uses a recursive partitioning method that predates CART technique and is widely applied in diverse domains (Shmueli et al., 2007). It tests for independence by using Chi-square test to assess whether splitting a node obtains significantly improved purity. Particularly, the predictor with the strongest association (according to p-value) with the response variable at each node is used as a split node. If the tested predictor does not show a statistically significant improvement, no split is performed, and the algorithm stops.

This study, however, proposes the use of Exhaustive CHAID, which was developed to address the limitations of the CHAID technique (Biggs, Ville, & Suen, 1991), to classify the target field. Specifically, CHAID may sometimes fail to optimize the split for a predictor variable since it stops merging categories as soon as it finds that all remaining categories significantly differ. Exhaustive CHAID avoids this by continuously merging predictor categories until only two super categories remain. It then identifies the predictor in the series of merges and the set of categories that gives the strongest association with the target variable and computes an adjusted p-value for that association. Thus, Exhaustive CHAID finds the best split for each predictor and chooses which predictor to split by comparing their adjusted p-values (SPSS., 2007).
3.2. GA-based SVM model

This section presents ideas regarding the GASVM in terms of its methodology and flowchart. Fig. 1 shows how the synergistic structure joining the fmGA to the SVM-based classification enables the SVM to identify complex mapping relationships between inputs and outputs. It classifies data using different class labels by generating a support vector set, which contains members of the training input set that outlines a hyperplane in a feature space.
GA-based SVM flowchart



Fig. 1. GA-based SVM flowchart.

It also provides a generic mechanism that uses a kernel function to fit the hyperplane surface to the training data. The user may select a kernel function (e.g., linear, polynomial, radial basis, or sigmoid) for the SVM during the training process, which identifies support vectors along the function surface. Previous study suggested that radial basis function (RBF) is generally a reasonable first choice (Hsu, Chang, & Lin, 2003). Unlike the linear kernel, the RBF maps samples nonlinearly into a higher dimensional space that usually yields more promising results compared to other kernels (Hsu & Lin, 2002; Lin & Lin, 2003). Therefore, the RBF is applied to construct SVM as the kernel function.

Since the SVM requires users to set optimal parameters, SVM parameters must be obtained simultaneously. For optimal SVM prediction accuracy, parameters that should be optimized include penalty parameter C and kernel function parameters such as the γ of the RBF kernel. One proposed alternative to finding the best C and γ when using the RBF kernel function is grid algorithm. However, this method is time consuming and performs poorly. Thus the objective of this proposed hybrid model is to use the fittest shapes of SVM with minimum number of support vectors and optimal SVM parameters to preserve acceptable classification. The optimized classification algorithm is briefly introduced below.
3.2.1. Fast messy generic algorithm

The fmGA is characterized by its relative immunity to high dimensionality and local minima and its potential use in hybrid SVMs. These advantages make fmGA a logical candidate for addressing the disadvantages of SVM. Unlike the well-known simple genetic algorithm, which uses fixed length strings to represent possible solutions, fmGA forms strings of varying length from messy chromosomes. The fmGA can also optimize solutions efficiently in large-scale permutation problems. For example, it can simultaneously optimize SVM parameters C and γ.

FmGA and SVM have proven effective in solving various project management problems. Considering the characteristics and merits of each, the two were combined in the proposed model, i.e., GASVM. In the GASVM, the SVM primarily addresses learning and curve fitting while fmGA addresses parameter optimization. This model was developed to obtain the C and γ parameters with minimal classification error.
3.2.2. Support vector machine-based classification

In classification problems, SVM identifies a separate hyperplane that maximizes the margin between two classes. Maximizing the margin is a quadratic programming problem, which can be solved from its dual problem by introducing Lagrangian multipliers. However, searching for a suitable hyperplane in input space is often overly restrictive for practical use. One solution is mapping the input space into a higher dimension feature space and then searching for the optimal hyperplane. Even without knowledge of mapping, the SVM can still find the optimal hyperplane by using dot product functions in feature space, called kernels. The optimal hyperplane can be expressed as a combination of several input points, called support vectors.

The main purpose of SVM is estimating a classification function by using input–output training data from two classes (x1, y1), ..., (xn, yn) ∈ Rm × {±1}. The goal of classification functions is to establish a hyperplane equation that divides training data and leaves all points of the same class on the same side while maximizing the minimum distances between the hyperplane and each of the two classes (w, b). Where w represents the weight vector realizing a functional margin of 1 on the positive point x+ as well as the negative point x−, and the geometric margin can be computed as follows:
(1)

The optimal hyperplane
is geometrically equivalent to maximizing the margin, i.e., the distance between the two parallel planes and . The Euclidean length of the margin is 2/‖w‖2, where . The maximum margin is also the minimum 2-norm , subject to constraint (2). Therefore, the problem can be formulated as
(2)

Since classes can rarely be separated linearly, generalizing the optimal plane problem is needed. Thus, a set of variables ξ that measures constraint variation is added for each point. The final formulation is
(3)

where C is a penalty parameter (error penalty) chosen by the fmGA.

Eq. (3) can be solved by the classical Lagrange multipliers and Karush–Kuhn–Tucker conditions (Vapnik, 1995). The decision function can be written as
(4)

where αi,b is calculated using training data.

Some kernel functions k(xi,xj) include polynomial, radial basis function (RBF) and sigmoid kernels (Witten & Frank, 2005) (Eqs. (5)–(7), respectively). Kernel parameters in the kernel functions should be optimized for maximum predictive accuracy.

Polynomial kernel:
(5)
Radial basis function kernel:
(6)
Sigmoid kernel:
(7)

Notably, any function k(xi,xj) satisfying Mercer’s condition can be used as the kernel function. Among these functions, the Gaussian function can map the sample set from the input space into a high-dimensional feature space effectively, which is good for representing the complex nonlinear relationship between the input and output samples (Hsu et al., 2003). Furthermore, the linear kernel is a special case of RBF (Keerthi & Lin, 2003) that the linear kernel with a penalty parameter C performs the same RBF kernel with the parameters (C; γ).

The sigmoid kernel also behaves similarly to the RBF for certain parameters. However, the sigmoid kernel is not better than the RBF kernel in general (Lin & Lin, 2003). The second reason is that the number of hyper parameters affects model selection complexity. The polynomial kernel has more hyper parameters compared to the RBF kernel. The RBF kernel presents fewer numerical difficulties. Moreover, the sigmoid kernel is invalid (i.e., not the inner product of two vectors) under certain parameters (Vapnik, 1995). Recent works also suggested the use of RBF kernel function in the SVM model is appropriate and sufficient (Huang & Wang, 2006; Huang et al., 2011; Pai et al., 2014; İlhan & Tezel, 2013). In this regard, the RBF kernel function is used for nonlinear relationships between class labels and attributes in this study.
3.2.3. Integration of fmGA and SVM

Fig. 2 illustrates the adaptation processes (initial/primordial/justapositional phases) of integrating fmGA and SVM.
Adaptation process



Fig. 2. Adaptation process.
3.2.3.1. Initial phase

Probabilistic initialization. The goal of the initialization phase is to create a population of strings containing all possible Building Blocks (BBs) of order k. The fmGA performs the so-called “probabilistically complete initialization” process, which randomly generates n chromosomes of length γc, where k < γc ⩽ l and l represent problem length. The γc value may be chosen arbitrarily, and is usually defined as l − k. The population size n may be approximated using Eq. (8) for the binary-coded problem (Goldberg, Deb, & Horn, 1991).
(8)

where c(α) represents the square of a normal random deviate corresponding to tail-probability α and β represents the signal-to-noise ratio (i.e., the ratio of fitness deviation to the difference between two competing BBs). Variable m represents BB number and k represents BB order. Those parameters may be set arbitrarily in accordance with the problem.

Evaluate individuals. The purpose of evaluation is to assess the fitness of chromosomes. The process describing the GASVM calculates the fitness of each chromosome. In the initial generation, the GASVM evaluates individuals. The aim of the model is to obtain a solution that provides both a high degree of accuracy and the ability to be generalized to a broader problem set. While model accuracy in terms of input patterns can be improved by increasing the number of support vectors, an accurate model that is made to fit input patterns does not necessarily capture overall problem behavior well. In general, such models suffer from input pattern data over-fitting and a deterioration of generalization properties. Thus, the objective of the fusion model is to use the fittest shapes of SVM with a minimum number of support vectors and optimal SVM parameters to preserve an acceptable level of prediction accuracy in posed optimization problems.
3.2.3.2. Primordial phase

Threshold selection. The primordial phase filters out “bad” genes that do not belong to BBs, so that the resultant population encloses a high proportion of “good” genes belonging to BBs. Two operations, building-block filtering and threshold selection, are performed during the primordial phase. A threshold mechanism has been used (Biggs et al., 1991) to restrict competition between building blocks that share little in common, where tournament selection between two strings is only permitted if they share a greater than expected number of genes in common. In random strings of two different lengths,
, , the threshold can be calculated using Eq. (9).
(9)

Building Blocks Filter. In the initialization procedure described in the previous section, the string starts off at a length approximating the problem length. In order to get the fmGA to function properly, this initial length must be reduced until it measures something close to building-block length k (Biggs et al., 1991). The key to getting this to work properly is pumping up sufficient good building block copies so that, even following random deletion, one or more copies remain for subsequent processing.
3.2.3.3. Juxtapositional phase

Cut and Splice. Messy operators, which include cut–splice and mutation operators, are used as genetic operators in the fmGA. The cut–splice operator, similar to the crossover operator in the simple GA, is used to recombine different strings to create new strings. The cut operator breaks a messy string into two parts using a cut probability Pc = Pk(γ − 1), where Pk is a specified bit-wise cut probability and γ represents string length. String length correlates positively with the probability that the string will be cut. The cut point is chosen randomly along the string. The splice operator joins two strings with a specified splice probability (Ps). For example, as shown in Fig. 3, two strings ((2 1)(1 0)(5 0)(3 1)) and ((1 1)(2 0)(6 0)(4 1)) are recombined into ((2 1)(1 0)(4 1)) and ((1 1)(2 0)(5 0)(3 1)) after being cut and spliced. Goldberg et al. (1993) proposed

and a maximum string length, after being cut and spliced, of 2l, where l represents problem length. Ps is typically set to 1 (Goldberg et al., 1993).
Cut–splice operator



Fig. 3. Cut–splice operator.

Mutation. Mutation produces spontaneous random changes in various chromosomes, which protects against premature loss of important notations. In the GASVM, mutation serves to adjust the value of SVM parameters and activation slopes for better performance. It alters one or more genes with a probability (pm). The mutation operator perturbs the allele values of the messy chromosome by switching them from 1 to 0 and vice versa, with a predefined probability pm (see Fig. 4).
Mutation



Fig. 4. Mutation.
4. Numerical example
4.1. Dispute data collection

To demonstrate the applicability and efficiency of the dispute classification schemes, this study used PPP project data collected by the Taiwan Public Construction Commission (TPCC) – the governmental authority overseeing public services and infrastructure construction in Taiwan. The study database contains 584 PPP projects overseen by the TPCC during 2002–2009. Of the 584 surveys issued, 569 were returned completed, for a response rate of 97.4%. This high return rate from various governmental units may be attributable to the TPCC taskforce, the most senior governmental authority, conducting survey activity. The questionnaire included items to collect social demographic data, background information, project characteristics, and project dispute resolution data.

Several projects had more than one dispute (the highest rate was nine disputes for one project) during various project phases. Thus, the overall dataset included data for N = 645 cases (i.e., N2 = 493 non-dispute cases; N1 = 152 dispute cases) when counting one dispute occurrence as a single case. Based on expert feedback and data availability, project attributes and their derivatives that were clearly relevant to the prediction output of interest were identified by survey items.

Table 2 summarizes the statistical profiles of categorical labels and numerical ranges for the resulting study samples. Out of all PPPs analyzed, 59.5% were performed by the central government. Over the past eight years, most public construction has involved cultural and education facilities (25.3%), sanitation and medical facilities (20.8%), transportation facilities (18.1%), and major tour-site facilities (10.5%). In accordance with the economic planning and development policy, 48.5% of projects were located in northern Taiwan. Industrial departments (38.6%) and service departments (50.7%), which were classified according to standard industry definitions, comprised most private sector investment. In most cases (91.0%), the government provided land and facility designs to attract the investors.

Table 1. Confusion matrix.
		Predicted
		Positive	Negative
Actual	Positive	tp	fn
Negative	fp	tn

Table 2. Project attributes and their descriptive statistics.
Attribute	Data range, categorical label or statistical description
Input variables
Type of government agency in charge	Central authority (59.5%); municipality (11.5%); local government (29%)
Type of public construction and facility	

1:

    Transportation facilities (18.1%);
2:

    Common conduit (0%);
3:

    Environmental pollution prevention facilities (2.3%);
4:

    Sewerage (1.1%);
5:

    Water supply facilities (0.5%);
6:

    Water conservancy facilities (2.5%);
7:

    Sanitation and medical facilities (20.8%);
8:

    Social welfare facilities (3.9%);
9:

    Labor welfare facilities (1.2%);
10:

    Cultural and education facilities (25.3%);
11:

    Major tour-site facilities (10.5%);
12:

    Power facilities (0%);
13:

    Public gas and fuel supply facilities (0%);
14:

    Sports facilities (3.3%);
15:

    Parks facilities (2.5%);
16:

    Major industrial facilities (0.5%);
17:

    Major commercial facilities (1.9%);
18:

    Major hi-tech facilities (0.2%);
19:

    New urban development (0%);
20:

    Agricultural facilities (5.6%)

Project location	North (48.5%); center (21.2%); South (24.5%); East (5.3%); isolated island (0.5%)
Executive authority	Central authority (36.0%); municipality (36.1%); local government (27.9%)
Type of invested private sector	Standard industry classification-primary (0.2%); secondary (38.6%); tertiary (50.7%); quaternary (10.5%)
Planning and design unit	Government provides land and plans facility (91.0%); government provides land and private investor designs facility (5.9%); private provides land and designs facility (3.1%)
PPP contracting strategy	BOT (23.7%); OT (52.7%); ROT (23.6%)
Major public infrastructure/facility	Promoted as major public infrastructure/facility in PPP act (80.1%); not major infrastructure/facility (19.9%)
Project scale	Range: 0–60,000,000; Sum: 5.43E8; mean: 841337.1776; standard deviation: 3.52061E6 (thousand NTD; USD:NTD is about 1:30 as of Apr. 2011)
Government capital investment	Range: 0–9,600,000; sum: 40,975,392.41; mean: 63527.7402; standard deviation: 5.11192E5 (thousand NTD)
Private capital investment amount	Range: 0–60,000,000; sum: 5.02E8; mean: 777809.4374; standard deviation: 3.32433E6 (thousand NTD)
Private capital investment ratio (PCIR)	Range: 0–100; mean: 91.4729; standard deviation: 25.42269 (%)
Licensed operations duration	Range: 0–60; mean: 11.9778; standard deviation: 13.39007 (year)

Output variables
Dispute propensity	No dispute occurred (76.4%); dispute occurred (23.6%)

Historically, the three major PPP strategies for delivering public services were BOT (23.7%), OT (52.7%), and ROT (23.6%). The World Bank Group (WBG) (WBG., 2011) defines BOT (Build, operate, and transfer) as a strategy in which a private sponsor builds and operates a new facility before transferring it to the government at the end of the contract period. The government usually provides revenue guarantees through long-term take-or-pay contracts. Another PPP strategy defined by the WBG classifications is rehabilitate, operate, and transfer (ROT), in which a private sponsor rehabilitates an existing facility and then operates and maintains the facility at its own risk for the contract period. Projects involving only management and lease contracts are classified as OT (operate and transfer) projects.

Further, flagship infrastructure projects refer to those that are important and fairly large in scale (i.e., the flagship projects in this study had an average value of approximately 841 million NTD). The collected data indicated that the total amount procured via PPP approximated 543 billion NTD. The mean capital investment by the government and private sectors per project was 63.5 million NTD and 777.8 million NTD, respectively. Notably, average private capital investment ratio was as high as 91.4%. The mean duration of licensed facility operations was about 12.0 years (maximum, 60 years).

To measure the dependencies between the categorized data, contingency table analyses were compared between the distinct predictors and response variable via Chi-square testing to infer the relationships (Table 3). All tests obtained statistically significant results with alpha levels of at least 5% except the variable (i.e., planning and design unit), which was a rejection of the null hypothesis, i.e., no relationship was observed between the row variable (input variable) and the column variable (output variable).

Table 3. Contingency table and chi-square test results for disputed cases.
Project attributes	p-value	Dispute occurred (%)
Agency	.002	
Central authority		67.1
Municipality		15.1
Local government		17.8
Type of public construction	.000	
Transportation facilities		10.5
Water conservancy facilities		9.9
Sanitation and medical facilities		17.1
Cultural and education facilities		13.2
Major tour-site facilities		14.5
Agricultural facilities		11.2
Planning and design unit	.657	
Government provides land and plans facility		92.1
Government provides land and private investor designs facility		5.9
Private investor provides land and designs facility		2.0
PPP strategy	.000	
BOT		49.3
OT		32.2
ROT		18.4
Major public infrastructure	.000	
No		61.2
Yes		38.8
Project scale (thousand NTD)	.000	
<5,000		15.8
5,000–50,000		15.8
>50,000		68.4
PCIR (%)	.057	
<25		3.3
25–50		0.0
50–75		3.9
>75		92.8
LOD (year)	.000	
<5		19.7
5–10		23.0
10–15		5.9
15–20		13.8
>20		37.5

For example, among the disputed cases (N1 = 152), central government agencies had a higher probability of encountering disputes (67.1% probability) compared to municipal (15.1%) and local agencies (17.8%). Particularly, in public construction and facility type Nos. 1, 6, 7, 10, 11, and 20 (Table 2), disputes occurred in 76.4% of projects. The data showed that 85.5% disputes occurred in northern and southern Taiwan.

Interestingly, 92.1% of the disputes occurred when the government provided the land and was responsible for facility design while merely 2% occurred when private investors provided the land and designed the facilities themselves. Among the PPP strategies, the probability of disputes was higher in BOT (49.3%) than in OT (32.2%) and ROT (18.4%). Notably, once the project was legally promoted as major infrastructure, the likelihood of a dispute involving PPP (38.8%) was lower than that in non-major infrastructure (61.2%).

Moreover, once the project value exceeded 50 million NTD, the dispute propensity was 4.33 times higher than that for projects valued between 5 and 50 million NTD or less than 5 million NTD. However, when the private sector investment exceeded 75%, the dispute tendency increased to 92.8%. Notably, dispute patterns were significantly related to the licensed operation period. Table 3 summarizes the statistical results of the cross-analysis.
4.2. Performance measure for classification

Researchers often use k-fold cross-validation algorithm to minimize bias associated with the random sampling of the training and holdout data samples. Kohavi (1995) further confirmed that ten-fold validation testing obtains the optimal computation time and variance (Kohavi, 1995). Thus, a stratified ten-fold cross-validation approach was used to assess model performance in this study.

Classification performance can be evaluated by computing the number of correctly recognized class examples (true positives; tp), the number of correctly recognized examples that do not belong to the class (true negatives; tn), and the number of examples that were either incorrectly assigned to the class (false positives; fp) or that were unrecognized as class examples (false negatives; fn) (Sokolova & Lapalme, 2009). The four counts constitute a confusion matrix (Table 1), which can generate measures commonly used for binary classification such as accuracy, precision, sensitivity, specificity, and area under the ROC curve (AUC) (Ferri, Hernández-Orallo, & Modroiu, 2009; Kim, 2010).

To evaluate the model performance, classification performance measure can be obtained as below
(10)
(11)
(12)
(13)
(14)

Based on the above measures, the following overall average performance score (S) is proposed
(15)

where m represents the number of distinct performance measures and Pi denotes the ith performance measure. The S range is 0–1; the coefficient positively correlates with the effectiveness of the overall evaluation measures.
5. Results and models comparison

The classification analyses were reproduced by cross-fold method. In each fold experiment, GASVM, CART, CHAID, QUEST, and C5.0 were implemented for model training. The testing fold was then used to evaluate the model of each method. The procedure was then rotated to the next fold until all folds were tested. The coincident matrices (rows and columns show actual and predicted results, respectively) for the individual models were used to quantify model performance in terms of five measures: accuracy (Eq. (10)), precision (Eq. (11)), sensitivity (Eq. (12)), specificity (Eq. (13)), and AUC (Eq. (14)). A synthesis index S (Eq. (15)) was also derived for each classification model to represent overall performance.

Table 4 shows the cross-fold modeling performance. Notably, the IBM SPSS modeler, a highly effective and versatile data analytics workbench, was utilized to develop four classification techniques as baseline models. All individual classification models achieved at least 80% accuracy except QUEST. The GASVM was the most accurate in terms of accuracy value (89.30%), the most common single measure of model performance. In terms of overall performance measure S, GASVM (0.871) ranked highest followed by C5.0, CART, CHAID, and QUEST. Interestingly, C5.0 was the best model for classifying non-dispute examples (sensitivity = 95.58%) while GASVM performed best at predicting dispute/no-dispute outcomes (accuracy = 89.30%), measuring classification fidelity for no-dispute examples (precision = 94.67%) and identifying dispute cases (specificity = 93.64%). Moreover, GASVM was also the best classifier in terms of avoiding false classification (AUC = 0.8394).

Table 4. Cross-fold modeling performance.
Classification model	Accuracy (%)	Precision (%)	Sensitivity (%)	Specificity (%)	AUC	S
Proposed model
GASVM	89.30 (1)	94.67 (1)	74.24	93.64 (1)	0.8394 (1)	0.871 (1)

Baseline model
CART	80.00	85.25 (2)	89.30	50.39 (2)	0.6985 (2)	0.750 (2)
CHAID	82.63 (3)	84.47 (3)	94.42 (2)	44.01 (3)	0.6920 (3)	0.749 (3)
QUEST	79.06	81.86	93.36 (3)	33.68	0.6371	0.703
C5.0	83.25 (2)	84.24	95.58 (1)	42.62	0.6910	0.750 (2)

Previous work
Ensemble approach (Chou & Lin, 2013)	84.33	85.60	95.26	48.82	0.7229	0.773
% Improved by GASVM	5.93	10.6	–	91.8	16.2	12.7

(1)–(3) Denotes performance ranking; The bold values represent the best performance measures.

Previously, Chou and Lin (2013) used ensemble approach to estimate dispute classification. (Chou & Lin, 2013). Table 4 shows that the proposed GASVM had improved rates by 5.93% (accuracy), 10.6% (precision), 91.8% (specificity), 16.2% (AUC), and 12.7% (S). For most of the performance measures, the study obtained more satisfactory results than did the previous work.
6. Conclusions

This study proposes several classifiers that can be applied when using CART, QUEST, C5.0, CHAID, and GASVM (a hybrid approach) to predict dispute propensity. In terms of accuracy, GASVM (89.30%) and C5.0 (83.25%) are the two best classification and regression-based models in predicting project disputes. Moreover, GASVM provides the highest overall performance measurement score (0.871) considering accuracy, precision, sensitivity, and AUC. Notably, with the exception of GASVM, which was developed by the authors and implemented within a mathematical tool, all models are easily executed via open-source or commercial software. Compared to the baseline models (i.e., C5.0, CHAID, CART, and QUEST) and previous work, GASVM provides 5.89–12.95% higher classification accuracy.

Practitioners must consider the tradeoffs between commercial artificial intelligence tools and a self-developed hybrid inference model. Specifically, one should decide whether the improvement in quantitative accuracy obtained by GASVM is worth the added effort needed to develop a new model compared to using readily available classification and regression-based models with proven ease of use, convenience and availability. Advanced research can focus on developing GASVM expert systems with window or browser interfaces to facilitate use by project managers.

Accurately forecasting dispute propensity provides the proactive-warning and decision-support information needed to manage potential disputes effectively and to select appropriate resolution strategies before disputes occur. Although the proposed classification techniques have proven effective for early prediction of dispute likelihood in PPP projects involving public infrastructure services, some classification techniques and their variations were not evaluated in this study.

Moreover, although an RBF kernel function was used in the SVM-based classification experiments in this study, other kernel parameters and other SVM types may also be optimized using the same approach. Similar parameter optimization procedures can be used to solve prediction or clustering association problems to decision support system. This study confirmed that the proposed hybrid method can assist government agencies in early warning of dispute propensity, and thereby reducing the time and effort needed to prepare a rule set to proactively prevent disputes among parties.