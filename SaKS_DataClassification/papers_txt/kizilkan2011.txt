Thermodynamic analysis of variable speed refrigeration system using artificial neural networks

Abstract

This study presents thermodynamic performance modeling of an experimental refrigeration system driven by variable speed compressor using artificial neural networks (ANNs) with small data sets. Controlling the rotational speed of compressor with a frequency inverter is one of the best methods to vary the capacity of refrigeration system. For this aim, an experimental refrigeration system was designed with a frequency inverter mounted on compressor electric motor. The experiments were made for different compressor electric motor frequencies. Instead of several experiments, the use of ANNs had been proposed to determine the system performance parameters based on various compressor frequencies and cooling loads using results of experimental analysis. The backpropagation learning algorithm with two different variants was used in the network. In order to train the neural network, limited experimental measurements were used as training and test data. The best fitting training data set was obtained with eight neurons in the hidden layer. The results showed that the statistical error values of training were obviously within acceptable uncertainties. Also the predicted values were very close to actual values.

Keywords
Variable speed
Refrigeration
Neural networks

1. Introduction

Refrigeration systems remove heat from an enclosed space, or from a substance, and move it to a place where it is unobjectionable. The primary purpose of refrigeration systems is lowering the temperature of the enclosed space or substance and then maintaining that lower temperature. These systems work at part-load for much of their life generally regulated by on-off cycles of the compressor, working at the nominal frequency of 50 Hz, imposed by a thermostatic control which determines high energy consumption. Furthermore, the inefficient use of electricity to supply the refrigeration compressors is considered as an indirect contribution to the greenhouse gases emitted in the atmosphere; these emissions can be reduced by improving the energy conversion efficiency of the above mentioned systems (Aprea, Mastrullo, Renno, & Vanoli, 2004a). Because the refrigeration systems are widely used in a wide variety of commercial activities, any efficiency improvement of refrigeration systems would represent a significant energy economy (Buzelin, Amico, Vargas, & Parise, 2005). Theoretically the most efficient method of refrigeration capacity control is the variable speed compressor which continuously matches the compressor refrigeration capacity to the load (Aprea, Mastrullo, & Renno, 2004b). This method of refrigeration capacity control, which consists in varying the compressor speed to continuously match the compressor refrigeration capacity to the load, has been analyzed during the last years (Aprea et al., 2004b; Aprea & Renno, 2004; Aprea, Rossi, Greco, & Renno, 2003; Buzelin et al., 2005; Chaturvedi, Chen, & Kheireddine, 1998; Haberschill, Gay, Aubouin, & Lallemand, 2002; Koury, Machado, & Ismail, 2001; Miller, 1988; Park & Jung, 2007; Park, Kim, & Cho, 2002; Perreira & Parise, 1993; Rasmussen, Ritchie, & Arkkio, 1997; Wicks, 2000).

During the design procedure of refrigeration systems, the engineers seek to find a solution, which gives maximum efficiency with minimum energy consumption and cost. The optimum system is not often easily found and a lot of variations and/or simulations are required in order to decide which combination gives the best financial benefit. The primary objective of this study is to develop a new approach based on artificial neural networks to determine the performance of variable speed experimental refrigeration system in terms of thermodynamics and energy consumption aspects. For this purpose, an experimental plant was built up to investigate the performance of the variable speed refrigeration system and mathematical modeling analysis was carried out by the use of ANNs to determine thermodynamic performance of the system using results of experimental analysis. The advantage of this type of modeling is that, it is easier to make accurate forecasts about the system performance using small data sets instead of making a lot of experiments.
2. Experimental system

The experimental variable speed refrigeration system is made up of a semi hermetic compressor, an evaporator, a condenser and an externally equalized thermostatic expansion valve. Evaporator and condenser are air cooled finned tube type heat exchangers. Evaporator is located in a specially designed cold room which is heated by means of electrical heaters for simulating refrigeration load. Condenser is located in an isolated channel so is not affected by outside conditions. To fix the air temperature constant which is entering the condenser channel, electrical heaters are located at the entrance of the channel. Cold room is 2.1 m in height, 1.2 m in width and 1.35 m in length. It is also isolated with styrofoam. For simulating the refrigeration load, 18 flat electrical heaters are used for homogeny heat distribution. Each heater is 0.045 kW in power and the power of heaters is controlled by means of a variable transformer and the consumed power monitored with the help of a wattmeter. The compressor speed varied with a frequency inverter. The device is 0.75 kW and the efficiency of the device is 95.1% according to the manufacturer’s catalogs. All electrical parts of the refrigeration system are placed into a control panel (Fig. 1).
Experimental system

   

Fig. 1. Experimental system.

To evaluate the system performance by regulating the compressor capacity by means of an inverter, temperature and pressure measurement were made from specified points of the experimental system. Refrigerant mass flow rate is measured using a flow meter that is designed for refrigerant R404a. Also air humidity at the inlet and outlet of the condenser channel were measured using compact humidity measuring instrument. Temperature measurements were collected from 12 points of the system, pressure measurements were collected from 7 points and refrigerant mass flow rate measured after the condenser. All the measurement devices are connected to a data logger which has 20 channels for collecting the data. Also the data logger was connected to a computer.

Experiments were made up as four groups. At each group of experiments, compressor electrical motor frequency adjusted as 35 Hz, 40 Hz, 45 Hz and 50 Hz. Minimum frequency range was selected to be 35 Hz for avoiding problems for the compressor lubricating by splash. Additionally, compressor vibrations increase at lower frequencies. At each adjusted frequency, cold room refrigeration duty simulated by electrical heaters. Experimental setup was operated for each adjusted frequency and cooling loads. All measurements were made for every 5 s and the data was collected to computer by means of data logger.
3. Artificial neural networks (ANNs)

Artificial neural networks (ANNs) consist of large numbers of computational units connected in a massively parallel structure and works similar to a human brain (Chouai, Laugier, & Richon, 2002). Because of their simple and unlimited structure, they have a wide operating area in artificial intelligence applications such as mathematics, engineering applications, energy systems, medicine, economics, etc. Their advantages are not only eliminating, and estimating and also learning. (Kizilkan, Şencan, & Yakut, 2006). Today neural networks can be trained to solve problems that are difficult for conventional computers or human beings. Throughout the toolbox emphasis is placed on neural network paradigms that build up to or are themselves used in engineering, financial and other practical applications.

Neural networks are composed of simple elements operating in parallel. These elements are inspired by biological nervous systems. As in nature, the network function is determined largely by the connections between elements. A neural network can be trained to perform a particular function by adjusting the values of the connections (weights) between elements.

Commonly neural networks are adjusted, or trained, so that a particular input leads to a specific target output. Such a situation is shown in Fig. 2. There, the network is adjusted, based on a comparison of the output and the target, until the network output matches the target. Typically many such input/target pairs are used, in this supervised learning, to train a network (Şencan, 2007).
Schematic diagram of neural networks

   

Fig. 2. Schematic diagram of neural networks.

There are different learning algorithms that can be applied to train a neural network. It is very difficult to know which training algorithm will be the fastest for a given problem, and the best one is usually chosen by trial and error. The most popular of them is the backpropagation algorithm, which has different variants. Backpropagation algorithm was created by generalizing the Widrow–Hoff learning rule to multiple-layer networks and nonlinear differentiable transfer functions. Standard backpropagation is a gradient descent algorithm, in which the network weights are moved along the negative of the gradient of the performance function. The term backpropagation refers to the manner in which the gradient is computed for nonlinear multilayer networks (Şencan & Kalogirou, 2005).

The architecture of neural network unit is shown in Fig. 3. Each artificial neural unit consists of inputs (xn), weights (Wn), summation function (Σ), activation function (α) and outputs (y). The figure illustrates how the information is processed through a single node. The node receives weighted activations of other nodes through its incoming connections. First, these are added up (summation). The result is then passed through an activation function, the outcome being the activation of the node. For each of the outgoing connections, this activation value is multiplied by the specific weight and transferred to the next node (Kalogirou, 2000).
The architecture of neural network unit

   

Fig. 3. The architecture of neural network unit.

The input layer feeds data to the network, therefore it is not a computing layer since it has no weights or activation function. The output layer represents the output response to a given input. Here, x is input vector which can be expressed xT = [x1, x2, … , xn]. W is the vector which is including the weights and represented as WT = [W1, W2, … , Wn]. The node receives weighted activation of other nodes through its coming connections. First, these are added (summation function). The result is then passed through an activation function, the outcome being the activation of the node. For each of the outgoing connections, this activation value is multiplied with the specific weight and transferred to the next node (Kalogirou, 2000).
4. Application of ANNs for the performance analysis

For the main objective of this work, ANNs was used to investigate the performance of the variable speed refrigeration system. There were six inputs and six outputs for the system. The input parameters are compressor frequency, cooling load, condenser and evaporator temperatures and condenser and evaporator pressures. The output parameters were compressor power consumption, refrigerant mass flow rate, experimental and theoretical COP values, exergetic efficiency and irreversibility of the system. The range of input and output values were given in Table 1. In Fig. 4, the selected ANN structure was shown and consisting of an input layer, a hidden layer and an output layer. The number of neurons in hidden layer was selected to be in the range of 4–8 for determining the best approach. The input layer had six neurons for the input parameters and there are six output neurons for the output parameters.

Table 1. Thermodynamic property ranges of system parameters.
	Property	Range
Inputs parameters	Compressor frequency (ƒ), Hz	35–50
Cooling load (QC), kW	0.1–0.7
Condenser temperature (TC), °C	30–35
Evaporator temperature (TE), °C	−15 to −10
Condenser Pressure (PC), kPa	300–400
Evaporator Pressure (PE), kPa	1400–1600

Outputs parameters	Compressor power (WC), kW	0.5–0.8
Refrigerant mass flow rate (
), kg/s	0.006–0.007
COPexperimental	1–1.5
COPtheoretical	1.5–2.5
Exergetic efficiency (ε)	0.5–0.6
Irreversibility (I), kW	0.6–0.8
The ANNs structure for the model

   

Fig. 4. The ANNs structure for the model.

Feed-forward backpropagation learning algorithm was used for learning algorithm with one hidden layer. Inputs and outputs were normalized between the ranges of 0 and 1 by the equation below (Sözen, Arcaklioğlu, & Menlik, 2010).
(1)

The training function variants selected for the algorithm were Levenberg–Marquardt (LM), and Scaled Conjugate Gradient (SCG) algorithms. Adaption learning function was selected to be gradient descent with momentum weight and bias learning function (LEARNGDM) which was standard for the network. Logistic sigmoid (logsig) transfer function has been used in the hidden and output layer. Neurons in input layer have no transfer function. Computer program has been performed under MATLAB environment using neural network toolbox. In the training part of the performance modeling of the experimental system, an increased numbers of neurons were used in single hidden layer (Karatas, Sozen, & Dulek, 2009).

The training of the network was accomplished by adjusting the weights and was carried out through training sets and training cycles (epochs). The goal of the learning procedure was to find the optimal set of weights, which in an ideal case would produce the right output for any input. The output of the network was compared with a desired response to produce an error. The performance of the network was measured in terms of a desired signal and the criterion for convergence. For one sample, the absolute fraction of variance (R2) and the root mean square error (RMSE) were determined with the equations given below (Akdag, Komur, & Ozguc, 2009).
(2)
(3)
In addition mean absolute percentage error (MAPE) and coefficient of variation (cov) are defined as follows, respectively (Akdag et al., 2009; Arcaklioglu, Erisen, & Yilmaz, 2004; Li & Liu, 2009; Sozen, Ozalp, & Arcaklioglu, 2007)
(4)
(5)

In above equations, t is the target value, o is the output value and p is the number of patterns.
5. Results and discussion

For the performance modeling of the variable speed experimental refrigeration system, different algorithms and different number of hidden neurons were used. The data set for the input and output values were consisted of 80 data patterns obtained from experimental system. Eighty percent of these data patterns were used for training and twenty percent were used for testing procedure. In order to determine the output parameters, logistic sigmoid (logsig) transfer function used here is given by;
(6)
where;
(7)

In the above equations for Ei, the first two values are the multiplication of the input parameters (In) with their weights at location, and the last constant value (bn) represents the bias term. The subscript i represents the number of hidden neuron (Karatas et al., 2009; Kizilkan et al., 2006).

The results of the training in terms of statistical error values such as R2, RMSE, MAPE and cov from the variable speed refrigeration system for different algorithms and 4–8 neurons in the hidden layer were presented in Table 2. As seen from the tablet that the best approach which had minimum error was obtained by LM algorithm with eight neurons for all algorithms. Also it must be noted that in both training function case, by increasing the number of hidden neurons, the training accuracy improves, as well as approaching the best algorithm.

Table 2. Statistical error values of training.
Statistical error	Training function – neurons	Output parameters
WC, kW	
, kg/s	COPexperimental	COPtheoretical	ε	I, kW
R2	LM4	0.989691529	0.989946	0.98964	0.98954	0.989527	0.989859
LM5	0.992053575	0.992103	0.991722	0.992155	0.991997	0.992004
LM6	0.995526359	0.995628	0.995531	0.995656	0.995653	0.995586
LM7	0.997989424	0.997987	0.997987	0.99799	0.997983	0.997983
LM8	0.999997522	0.999997	0.999999	0.999999	0.999999	0.999998
SCG4	0.989309592	0.989543	0.989332	0.989427	0.989651	0.98975
SCG5	0.991471445	0.991529	0.991136	0.990917	0.991129	0.991596
SCG6	0.994605154	0.994333	0.994454	0.994281	0.993754	0.994731
SCG7	0.996852395	0.996876	0.996607	0.996793	0.99663	0.996811
SCG8	0.998440289	0.998686	0.99856	0.998631	0.99855	0.998522

RMSE	LM4	0.011354492	0.006775	0.012786	0.013471	0.012725	0.008577
LM5	0.007842882	0.006722	0.013754	0.005398	0.008436	0.008732
LM6	0.006706782	0.004346	0.006974	0.001743	0.001839	0.005043
LM7	0.002789554	0.000938	0.000976	0.000152	0.001421	0.001466
LM8	0.00064616	0.000873	0.000148	0.000102	0.000090	0.000483
SCG4	0.015028239	0.012204	0.01568	0.013803	0.010141	0.009099
SCG5	0.013080453	0.012275	0.017753	0.018942	0.015856	0.011392
SCG6	0.011325284	0.014634	0.014122	0.015425	0.018922	0.009299
SCG7	0.006955776	0.001333	0.011991	0.008283	0.01036	0.007834
SCG8	0.009203962	0.002094	0.007164	0.004759	0.006605	0.00757

MAPE	LM4	0.037882194	0.023785	0.043854	0.047722	0.045461	0.034243
LM5	0.028485818	0.023366	0.047585	0.020346	0.025541	0.034531
LM6	0.020188347	0.013033	0.020765	0.006033	0.007129	0.017426
LM7	0.002161308	0.00296	0.003663	0.000556	0.004092	0.005243
LM8	0.001131733	0.002646	0.000514	0.000313	0.000291	0.001431
SCG4	0.049285373	0.045087	0.054667	0.050761	0.03442	0.035393
SCG5	0.043826203	0.043438	0.075325	0.067984	0.06058	0.044791
SCG6	0.038109656	0.050913	0.049327	0.053983	0.069545	0.034743
SCG7	0.022745647	0.021631	0.037307	0.027624	0.032648	0.024971
SCG8	0.029535975	0.008259	0.026083	0.016305	0.019419	0.025072

cov	LM4	0.022686922	0.013963	0.023022	0.025767	0.026603	0.017278
LM5	0.015687369	0.013855	0.024806	0.010353	0.01761	0.017588
LM6	0.013403636	0.007145	0.012553	0.003343	0.003846	0.010142
LM7	0.001291998	0.001936	0.001757	0.00029	0.002972	0.002948
LM8	0.000557876	0.001801	0.000266	0.000196	0.00019	0.000971
SCG4	0.030055683	0.025187	0.028215	0.026463	0.021225	0.018328
SCG5	0.026217632	0.025402	0.031929	0.036221	0.033156	0.022941
SCG6	0.0226691	0.030262	0.02538	0.029532	0.039651	0.018694
SCG7	0.013907167	0.013065	0.02158	0.01588	0.021677	0.015751
SCG8	0.018410038	0.004321	0.012894	0.00913	0.013814	0.015214

The decrease of the mean square error (MSE) during the training process for eight neurons showed the best approach for LM8 algorithm as shown in Fig. 5. The performance of training and test sets of the established ANN model was given in Fig. 6. It was observed in the figure that the model agrees well with the training and test data as it learns the relationship between the input and output variables.
Training performance for LM8 algorithm in terms of MSE

   

Fig. 5. Training performance for LM8 algorithm in terms of MSE.
Comparison of the measured and predicted values for LM algorithm with eight…

   

Fig. 6. Comparison of the measured and predicted values for LM algorithm with eight neurons.

A comparison between the actual data obtained from experiments and predicted values from ANNs were presented in Table 3. From this table, the real performance of the simulation of the system can be comprehended since these were not used for training. As can be seen, the differences between actual and predicted values are very small. It is clear from this table that the established ANNS model gives a very accurate modeling of the experimental data instead of setting up several experiments.

Table 3. Comparison between the actual and predicted values.
Inputs	Outputs
WC, kW	
, kg/s	COPexperimental	COPtheoretical	ε	I, kW
ƒ, Hz	QC, kW	Actual	Test	Actual	Test	Actual	Test	Actual	Test	Actual	Test	Actual	Test
35	0.7	0.583	0.5823	0.0065	0.006493	1.305	1.30377	2.141	2.1398	0.594	0.5934	0.644	0.643
35	0.5	0.581	0.5804	0.0065	0.006493	1.326	1.32511	2.178	2.1762	0.594	0.5936	0.641	0.640
35	0.3	0.571	0.5705	0.0065	0.006493	1.333	1.33198	2.284	2.2825	0.598	0.5982	0.636	0.636
35	0.1	0.576	0.5753	0.0065	0.006493	1.348	1.34667	2.294	2.2921	0.599	0.5992	0.631	0.630
40	0.7	0.635	0.6346	0.0067	0.006691	1.219	1.21867	1.983	1.9809	0.587	0.5867	0.685	0.685
40	0.5	0.632	0.6310	0.0067	0.006694	1.229	1.22812	1.996	1.9941	0.588	0.5875	0.691	0.690
40	0.3	0.635	0.6341	0.0067	0.006694	1.304	1.30348	2.317	2.3149	0.589	0.5892	0.692	0.691
40	0.1	0.63	0.6295	0.0067	0.006692	1.327	1.32664	2.362	2.3595	0.591	0.5911	0.695	0.694
45	0.7	0.684	0.6833	0.0069	0.006893	1.170	1.16971	2.022	2.0202	0.580	0.5795	0.741	0.740
45	0.5	0.683	0.6823	0.0069	0.006893	1.203	1.20276	2.156	2.1544	0.581	0.5813	0.740	0.739
45	0.3	0.674	0.6733	0.0069	0.006893	1.223	1.22180	2.156	2.1545	0.582	0.5815	0.736	0.735
45	0.1	0.68	0.6792	0.0069	0.006893	1.242	1.24105	2.243	2.2408	0.584	0.5838	0.729	0.728
50	0.7	0.745	0.7443	0.00715	0.007142	1.092	1.09161	1.930	1.9280	0.573	0.5727	0.800	0.799
50	0.5	0.742	0.7412	0.00715	0.007142	1.121	1.12058	2.006	2.0041	0.573	0.5732	0.799	0.798
50	0.3	0.739	0.7381	0.00715	0.007142	1.164	1.16342	2.170	2.1678	0.576	0.5755	0.792	0.792
50	0.1	0.738	0.7373	0.00715	0.007142	1.194	1.19299	2.279	2.2773	0.577	0.5768	0.790	0.789
6. Conclusions

In this study, performance analysis of variable speed refrigeration system with artificial neural networks was successfully carried out with small experimental data. Feed-forward backpropagation learning algorithm with two different training functions has been used. Logistic sigmoid (logsig) transfer function has been selected. The results of the training were given in terms of statistical error values such as R2, RMSE, MAPE and cov for 4–8 neurons in the hidden layer. It was found that that the neural network approach showed higher efficiency instead of establishing several experiments. Also from the results, the system performance can be determined for the unmeasured compressor frequencies such as 36 Hz. This study points out that a significant energy saving can be supplied by determining the optimum compressor frequency with neural Networks. This methodology can provide simplicity in the thermodynamic analysis of refrigeration systems.