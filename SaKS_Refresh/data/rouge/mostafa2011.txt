This is the first study to apply neuro-computational models to investigate software piracy. This study remedies previous econometric and methodological shortcomings in studying software piracy. This study shows that software piracy is affected by GDP, expenditure on R&D and judicial efficiency.

0.122018 - Software piracy represents a major damage to the moral fabric associated with the respect of intellectual property.
0.134291 - The rate of software piracy appears to be increasing globally, suggesting that additional research that uses new approaches is necessary to evaluate the problem.
0.278069 - The study remedies previous econometric and methodological shortcomings by applying Bayesian, robust and evolutionary computation robust regression algorithms to formally test empirical literature on software piracy.
0.103370 - To gain further insights into software piracy at the global level, the study also uses five neuro-computational intelligence methodologies: multi-layer perceptron neural network (MLP), probabilistic neural network (PNN), radial basis function neural network (RBF), generalized regression neural network (GRNN) and Kohonen’s self-organizing maps (SOM) to classify, predict and cluster software piracy rates among 102 nations.
0.218128 - At the empirical level, this research shows that software piracy is significantly affected by the wealth of nation as measured by gross domestic product (GDP), the nation’s expenditure on research and development and the nation’s judicial efficiency.
0.173594 - At the methodological level, this research shows that neuro-computational models outperform traditional statistical techniques such as regression analysis, discriminant analysis and cluster analysis in predicting, classifying and clustering software piracy rates due to their robustness and flexibility of modeling algorithms.
0.134610 - Software piracy has been defined as the unauthorized copying, distribution, and downloading of computer programs and applications (Globerman, 1988).
0.115521 - Even though piracy and counterfeiting occur across almost all types of products, software piracy is a unique form of piracy because in most cases the pirate is both producer and consumer of the software (Andres, 2006a).
0.041667 - Unlike brand piracy or patent infringements, “producers usually do not sell the bogus product – they simply share it” (Nill & Shultz, 2009, p. 290).
0.139440 - Software piracy has recently evolved into a truly global problem.
0.064516 - For example, a survey by the Business Software Alliance (BSA) estimated that illegal software duplication cost the worldwide software industry approximately $50 billion in losses (BSA, 2009).
0.099738 - In a study across 16 countries over the period 1998–2002, Peitz and Waelbroeck (2004) concluded that digital piracy would be responsible for a 20% decrease in sales.
0.120058 - Out of the 102 countries BSA studied, countries such as Vietnam and Indonesia maintain some of the highest software piracy rates (around 90%).
0.032258 - Such countries are sometimes called “one disc” countries because a few discs are legitimately purchased and then many copies are illegally made from the original (Correa, 1995).
0.029412 - Advanced countries such as the US and the UK have one of the lowest rates (around 20%), while transition economies such as Romania and Bulgaria are somewhere between the two extremes.
0.109166 - This might suggest that the relationship between software piracy rates and the wealth of a nation may well be nonlinear – a reminiscent of what is known in the literature as the Environmental Kuznets Curve (EKC), which describes the commonly observed inverted-U-shape relationship between environmental degradation and per-capita income.
0.068966 - Fig 1 illustrates this relationship.
0.094340 - However, it should be noted that the size of the pirated software in developing economies is small compared to advanced economies.
0.035320 - For example, Vietnam and Indonesia account for losses of $96 million and 350$ million, respectively, whereas losses in Western Europe and the US are estimated at $10.6 billion and $8.1 billion, respectively (Correa, 1995).
0.159483 - Software piracy EKC-type curve Fig 1.
0.176393 - Software piracy EKC-type curve.
0.113585 - Some authors argue that software industry may benefit from piracy through network effects, which enhance exposure and facilitate adoption (e.g.
0.000000 - Jain, 2008; Jaisingh, 2009).
0.056911 - However, the net effect is believed to be negative (Limayem, Khalifa, & Chin, 2004).
0.188428 - Software piracy is also regarded as a serious social and political problem.
0.074984 - For example studies have shown that pirated and counterfeited products lower consumers’ confidence in legitimate brands and negatively affect companies’ reputation (Wilk and Zaichkowsky, 1999), impact upon consumers’ perception of genuine articles (Chakraborty, Allred, & Bristol, 1996), and pose threat to consumer health and safety (Cordell, Wongtada, & Kieschnick, 1996).
0.075472 - The advent of the Internet has exacerbated the problem because piracy over the Internet is extremely difficult to detect (Hinduja, 2008).
0.074830 - Wall (2005) noted four characteristics of the Internet that have facilitated an increase in digital piracy in recent years: It allows anonymous communication, it is transnational, it has created a shift in thinking from the ownership of physical property to the ownership of ideas, and it is relatively easy to use.
0.123877 - Although software piracy has been studied at various levels, including global (e.g.
0.000000 - Husted, 2000), national (e.g.
0.039801 - Bezmen & Depken, 2006) and individual levels (e.g.
0.183889 - Shore et al., 2001), no previous studies have attempted to use neuro-computational and evolutionary computation (EC) techniques to predict, classify and cluster software piracy across nations.
0.158261 - In this research we aim to fill this research gap by predicting, classifying and clustering software piracy rates across 102 nations through the use of intelligent modeling techniques.
0.164224 - More specifically, the purpose of this research is twofold: • To determine the major factors that affect the software piracy at the global level; and • To benchmark the performance of neuro-computational and evolutionary computation (EC) models against traditional statistical techniques.
0.244344 - Thus, this study makes at least three important contributions to the broader literature on software piracy.
0.170050 - First, most studies involve comparisons of software piracy rates across a relatively small number of countries.
0.078431 - Our study includes 102 nations, which makes it the most comprehensive study so far.
0.213552 - By doing so the study adds depth to the knowledge base on software piracy.
0.151063 - Second, by employing neuro-computational and EC methods such as neural networks and evolutionary robust regression, the study adds breadth to the debate over the causes of software piracy at the global level.
0.150198 - Finally, by focusing solely on software piracy, rather than on other forms of digital piracy, this study enriches the knowledge base of this under-represented issue.
0.109290 - This paper is organized as follows.
0.177694 - The next section summarizes software piracy literature and develops research hypotheses.
0.039801 - The methodology used to conduct the analysis follows.
0.019048 - The subsequent section presents empirical results of the analysis.
0.018265 - Next, the paper sets out some implications of the analysis.
0.094118 - This section also deals with the research limitations and explores avenues for future research.
0.133094 - Drawing on research from North America, Europe and Australasia, there is a wealth of evidence that suggest that a wide variety of factors influence software piracy.
0.060198 - These can be characterized as affluence, level of human capital, level of corruption, level of inventive activity, domestic income inequality, and judicial efficiency.
0.170857 - Previous research found GDP to be a robust predictor of software piracy.
0.162724 - The presumption is that the higher the income level, the lower the rate of software piracy.
0.109006 - For example, using data for 59 nations from 2000 to 2005, Yang, Sonmez, Bosworth, and Fryxell (2009) found that economic well-being as measured by gross national income (GNI) explains between 59% and 74% of the variation in software piracy rates during the study period.
0.151682 - In a study of 39 nations, Husted (2000) found that the higher the level of economic development, the lower the rate of software piracy.
0.121277 - Applying a macro level panel data technique, Andres (2006a) studied factors affecting software piracy rates across 23 European countries.
0.156541 - Results indicate that income and copyright software protection are the most important factors in determining software piracy rates in Europe.
0.160150 - Depken and Simmons (2004) studied software piracy rates across 75 nations.
0.145786 - The authors concluded that GDP per capita was negatively and significantly correlated with software piracy rates at the 5% significance level.
0.158261 - Based on a study of 50 nations, Ronkainen and Guerrero-Cusumano (2001) found that purchasing power parity adjusted GNI accounted for 73% of the variation in software piracy.
0.150807 - Burke (1996) examined software piracy across signatories to Berne, Rome and Phonographic copyright conventions.
0.143868 - The authors concluded that GDP indirectly influences software piracy rates because it allows police and judiciary to actively implement intellectual property protection conventions.
0.144113 - Bezmen and Depken (2006) also found that a 1% increase in per capita income in the US lead to 0.25% decrease in software piracy rate.
0.089568 - Other empirical research that corroborates the negative impact of income on software piracy includes Yang and Sonmez (2007), Robertson, Gilly, Crittenden, and Crittenden (2008), Bagchi, Kirs, and Cerveny (2006), Banerjee, Khalid, and Sturm (2005), Gopal and Sanders (2000) and Marron and Steel (2000).
0.017544 - Country level results were also confirmed at the individual consumer level.
0.075472 - For example, in a multination study including 627 consumers from Honk Kong, New Zealand, Pakistan and the US, Shore et al.
0.033755 - (2001) found that affordability did influence consumers’ decision to buy pirated products.
0.092754 - In a study on 200 US consumers, Bloch, Bush, and Campbell (1993) concluded that pirated product buyers tend to be less “well-off” financially.
0.030303 - Finally, Sims, Cheng, and Teegen (1996) found a negative relationship between household income and softlifting.
0.099174 - Cheng, Sims, and Teegen (1997) found that household income is significantly related to “can’t afford software” as a reason to pirate software among university students.
0.165031 - The theoretical underpinning of the relationship between income and software piracy is best captured by the ‘compensatory consumption’ theory (Hill, 2002).
0.073260 - This theory posits that financially-deficient consumers have the same materialistic goals as well-off consumers.
0.025890 - Thus, low income consumers use a compensatory consumption strategy by purchasing pirated low priced products to achieve their materialistic goals.
0.041667 - The previous discussion suggests the following hypothesis.
0.142964 - H1: The higher the GDP per capita, the lower the rate of software piracy.
0.160754 - There has been little research on the association between education level and software piracy rates.
0.121212 - In general, this research provides evidence that education has a negative effect on piracy rates.
0.110236 - In a study linking the average years of schooling and piracy rates, Marron and Steel (2000) found that education may lead to a tendency toward lower piracy rates.
0.150157 - Yang (2007) studied piracy rates across 91 countries and found partial support for the relationship between expenditure on education and software piracy rates.
0.095996 - However, the author concluded that “one stark contrast between high- and low-piracy countries is that expenditure on education does not determine piracy in low-piracy countries, but it is an important factor in high-piracy countries” (p. 138).
0.113184 - In a sample of 34 nations, Andres (2006b) concluded that although education measured as average years of secondary schooling was not significantly related to software piracy rates, the sign of the estimated coefficient is negative.
0.133181 - Using a stepwise regression analysis based on 76 nations, Yang and Sonmez (2007) found that there is a negative and significant relation between the government expenditure on education as percentage of GNI and software piracy rates.
0.098180 - Other empirical research reporting a significant negative effect of a country’s education level on software piracy rates includes Depken and Simmons (2004) and Shadlen, Schrank, and Kurtz (2005).
0.186331 - Theoretical explanation of the relationship between education and software piracy is found in Ginarte and Park (1997).
0.025890 - The authors postulate that education either accelerates the imitation of intellectual property or intensifies the demand for intellectual property protection.
0.025890 - In case of low level of education, the former dominates, while a higher level of education finds the latter dominates.
0.041667 - The previous discussion suggests the following hypothesis.
0.135120 - H2: The higher the school enrollment rate, the lower the rate of software piracy.
0.100518 - Empirical research suggests that nations with high level corruption are burdened with the major challenge of protecting against intellectual property violations, including software piracy (Logsdon, Thompson, & Reid, 1994).
0.032362 - Husted (2000) concluded that nations with high levels of corruption are likely to minimize the morality of protecting intellectual property.
0.115973 - Using trajectory methodology to investigate piracy rates across 82 countries between 1995 and 2000, Piquero and Piquero (2006) found high levels of corruption to be associated with high levels of software piracy.
0.000000 - Using invisible hand theory, Robertson et al.
0.180787 - (2008) found that corruption mediated the relationship between economic freedom and software piracy.
0.095238 - The authors also found a strong positive correlation between corruption and piracy rates (r = 0.83).
0.026667 - Using a reverse score of the corruption perception index (CPI) in a sample of 53 nations, Banerjee et al.
0.022989 - (2005) corroborates previous research findings.
0.066116 - The authors theorize that high corruption nations are characterized by weak enforcement of the regulatory structure, which leads individuals and firms to violate copyright protection laws.
0.041667 - The previous discussion suggests the following hypothesis.
0.140137 - H3: The higher the corruption level, the higher the rate of software piracy.
0.170943 - There are few studies that theoretically and/or empirically examined the relationship between intensity of the innovative effort and software piracy.
0.066116 - However, this stream of research seems to conclude that nations with a relatively high inventive activity have an incentive to enforce stronger protection for intellectual property.
0.000000 - Bagchi et al.
0.153980 - (2006) found a significant inverse relationship between technology infrastructure and software piracy.
0.077135 - The authors concluded that weak information technology infrastructure as represented by older editions of software attracts people to use pirated software to conduct their daily transactions.
0.000000 - Yang et al.
0.071913 - (2009) used expenditure on information and computer technology (ICT) as a percentage of GNI as a measure to reflect a nation’s scientific and technological advancement.
0.141742 - The authors found that a one percentage increase in ICT/GNI reduces the incidence of software piracy by 1.7 percentage point.
0.084142 - The authors also found that the addition of this variable raises the explanatory power of the model by around 5%.
0.000000 - Shadlen et al.
0.124749 - (2005) also found that scientific infrastructure measured as the number of full-time R&D workers per 1000 people has a strong impact on software piracy rate.
0.128494 - Other empirical research that showed a negative, but insignificant, relationship between innovative effort and software piracy includes Marron and Steel (2000), and Andres (2006a).
0.041667 - The previous discussion suggests the following hypothesis.
0.130451 - H4: The higher the level of inventive activity, the lower the rate of software piracy.
0.180507 - The relationship between income distribution and software piracy is one of the most rigorously tested in previous research.
0.056738 - Income inequality is measured by the Gini coefficient, which is a widely used measure of income skewness.
0.159967 - At the individual consumer level, Banerjee (2003) has shown that there is a negative relationship between the variation in consumers’ willingness to pay and the level of software piracy.
0.020833 - At the county level, Banerjee et al.
0.082528 - (2005) have shown that a higher Gini coefficient means greater inequality, which “implies higher variation in the willingness to pay and hence may affect the affordability of a majority of the population to buy legitimate software thus increasing the demand for pirated software” (p. 2093).
0.014184 - Husted (2000) argues that with a more egalitarian income distribution, a relatively large middle class will exist.
0.196101 - This class is more prone to demand illegal software copies and, as a consequence, result in a higher software piracy rate.
0.116266 - The author reported a negative and significant relationship between the share of income held by the top 10% and software piracy rates in a sample of 39 nations.
0.162443 - This result was also confirmed by Traphagen and Griffith (1998) who find that the size of a country’s middle class population is positively related to the degree of software piracy.
0.105546 - Other empirical research reporting a significant negative effect of a country’s economic inequality level on software piracy rates includes Andres (2006b) and Cheng et al.
0.000000 - (1997).
0.041667 - The previous discussion suggests the following hypothesis.
0.130451 - H5: The higher the level of income inequality, the lower the rate of software piracy.
0.143596 - Finally, empirical research recognizes the importance of the legal system in deterring software piracy and softlifting (Shore et al., 2001).
0.075362 - For example, Marron and Steel (2000) found that countries with strong institutions protecting contracts and intellectual property also tend to have lower piracy rates.
0.052174 - Shultz and Saporito (1996) concluded that the low probability of punishment in emerging economies makes demand for pirated products of all kinds more likely.
0.063063 - In a similar vein Rapp and Rozek (1990) argued that intellectual property violation is perceived as a developing country problem because in these countries protection may not exist due to the lack of appropriate legislation.
0.116565 - Other empirical research reporting a significant negative effect of a country’s efficient judicial system on software piracy rates includes Andres (2006a, 2006b) and Moores (2003).
0.138923 - The theoretical underpinning of the relationship between judicial efficiency and software piracy is best captured by the ‘economic crime and punishment’ theory (Becker, 1968; Ehrlich, 1996) and the deterrence theory (Hollinger and Clark, 2003).
0.116918 - These theories posit that the expected cost of illegal activities is higher in countries that have more efficient institutions to enforce the law, which lead to an increase in the opportunity cost to engage in illegal activities such as software piracy.
0.150068 - For example, Peace, Galletta, and Thong (2003) found that punishment severity was significantly related to software piracy attitudes in organizations.
0.041667 - The previous discussion suggests the following hypothesis.
0.105044 - H6: The higher the degree of enforcement of laws governing the protection of intellectual property, the lower the rate of software piracy.
0.063768 - Bayesian regression approach The classical linear regression model can be written as (1) where ε is a random noise with mean 0 and variance σ2.
0.048110 - It follows that the conditional distribution of y is p(y|x, w, σ2) = G(y; wTx, σ2).
0.033854 - Within the maximum likelihood estimation (MLE), w is treated as a fixed parameter and is estimated as (2) where X = (x1, x2, … , xN)T, and y = (y1, y2, … , yN)T. Using the MLE, the variance may also be estimated as (3) The Bayesian approach introduces a prior probability distribution over the regression model parameters w. A zero-mean Gaussian prior is usually adopted such that p(w|α) = G(w; 0, α−1I).
0.071765 - It has been formally shown that since the prior distribution is conjugate to the likelihood, the posterior distribution is also Gaussian (Bishop, 2006).
0.066116 - Thus, (4) where (5) (6) If a non-informative prior is used (α → 0), the posterior mean in (5) reduces to the MLE result given by (2).
0.040100 - Analogous to (1), the multivariate regression model with K-response variables may be written as (7) where εn is a K-dimensional random noise with Gaussian distribution: G(εn;0, Σ).
0.029258 - Assuming the covariance matrix is diagonal ( , the likelihood of the dataset can be written as (8) Thus, one form of the independent prior distributions assigned for wk’s may be written as (9) Then the posterior distribution can be derived as follows: (10) Analogous to (4) the following result is obtained: (11) where (12) (13) Bayesian regression model using the MCMC approach involves three major steps (Ntzoufras, 2009): (a) formulation of prior probability distributions for targeted parameters; (b) specification of the likelihood function; and (c) MCMC sampling for the posterior probability distributions.
0.030612 - As strongly informed prior specifications contrast sharply with almost all Bayesian work to date (e.g., Bayram and Thorburn, 2007; Hill & Kriesi, 2001; Jackman, 2000; Kalatzis & Azzoni, 2009; Schweinberger & Snijders, 2003), we represent the low degree of belief in the prior distribution using a low precision value taken as 0.0001.
0.082192 - By this choice prior distribution does not dominate the likelihood.
0.041379 - Since we are interested in calculating the posterior distribution of the mean of a response variable which takes values in the set of real numbers, the likelihood function is given by Yi ∼ N(μ, σ2).
0.053585 - A frequently used diffuse prior for the variance parameter σ2 is the inverse-gamma distribution.
0.086667 - Alternatively, any other positive prior, meaning that the density support is positive on this variance component, may be used.
0.134184 - In this study we used the uniform prior bounded between 0 and 100 as a diffuse prior for σ2.
0.030303 - MCMC samples values of the parameters from the posterior distribution without computing the normalizing constant.
0.033898 - The two most popular MCMC algorithms are the Gibbs sampler (Geman & Geman, 1984) and the Metropolis–Hastings algorithm (Hastings, 1970; Metropolis, Rosenbluth, Teller, & Teller, 1953).
0.071625 - Robust regression The aim of robust regression is to reduce or remove the effect of outlying observations and allow the remainder to predominantly determine the results.
0.021505 - When no outliers are present in the data set, the results from the robust regression should be consistent with the corresponding OLS method (Moller, Frese, & Bro, 2005).
0.048387 - Thus, robust regression can be regarded as modification of both OLS and MLE that diminishes the effects of outlying observations on the regression estimates (Booth & Lee, 2003).
0.047059 - Robust regression provides a powerful methodology extending the conventional analysis and elimination of outliers.
0.037370 - In OLS the objective function to be minimized is the sum of the squared residuals (14) The robust regression methods collected under the term M-estimators (maximum likelihood type estimators) replaces the squared residuals in Eq (14) by another function of the residuals (15) The function ρ is symmetric with a unique minimum at zero, ri is the residual of the ith observation and s is a suitable estimate of the scale obtained from the residuals.
0.019048 - M-estimators are analogous to weighted least squares regression.
0.030303 - At each iterative step a new set of weights are determined based on the residuals.
0.036530 - In general, the larger the residuals, the smaller the weights.
0.043956 - The two most widely used weighting schemes are the Huber weighting and Tukey’s bisquare weighting.
0.025890 - In Huber weighting, observations with small residuals get a weight of 1, the larger the residual, the smaller the weight.
0.000000 - With bisquare, all cases with a non-zero residual get down-weighted at least a little.
0.046667 - Such weights make it possible to bound the effect of outliers on the final model (Moller et al., 2005).
0.046948 - Replacing the sum of the squared residuals in Eq (14) with the robust median yields the least median of squares (LMS) method first proposed by Rousseeuw (1984) as an alternative to OLS regression.
0.094748 - This method is defined by (16) On simulated datasets, LMS was able to estimate regression coefficients correctly when other techniques were significantly affected by outliers (Rousseeuw & Leroy, 1987).
0.017544 - Unfortunately, the LMS has a very low convergence rate (Rousseeuw, 1984).
0.067568 - To overcome this problem, Rousseeuw and Hubert (1997) developed a more efficient robust regression method, least trimmed squares (LTS) and a generalized version of the LMS regression algorithm, naming it least quantile of squares (LQS).
0.046901 - Since the robust regression is resistant to outliers, it has been recently applied in many fields including retrieval of aerosol optical thickness (Cheng, Nash, & Kopetz, 1999), examining the impact of service-learning programs on students’ self-concept and political engagement (Morgan & Streb, 2001) and assessing care giving among adults (Eriksen & Gerstel, 2002).
0.041667 - Evolutionary computation robust regression Compared to non-robust methods, a major drawback of robust regression techniques is their computationally intensive nature (Wegner, 2005).
0.058608 - A promising approach to tackling the problems associated with performing robust regression techniques is EC models.
0.056604 - EC techniques are useful when the search space is large and complex, and solutions are ill-defined apriori (Chen & Huang, 2003).
0.036745 - EC techniques are based on the Darwinian evolution principle, which suggests that populations evolve through inheritance where a concept of fitness reflects the population’s ability to survive.
0.045455 - Populations of individuals may be characterized by genetic makeup (genotype) and/or observed qualities (phenotypes).
0.023810 - In optimization problems population of individuals represent candidate solutions, where the fitness represents the objective value or the goodness of the candidate solution.
0.044150 - Because they combine a Darwinian survival-of-the-fittest approach with an effective information exchange system, EC techniques are well established search heuristics in computer science and mathematical optimization and steadily gaining prominence in computational statistics.
0.050000 - Recent applications of EC techniques in computational statistics include evolutionary clustering (Hruschka, Campello, & De Castro, 2006), association studies (Nunkesser, Bernholt, Schwender, Ickstadt, & Wegner, 2007), estimation of densities (Crowe, McClean, & Cresser, 2006) and time series analysis (Baragona et al., 2004).
0.106343 - Following Doganis, Alexandridis, Patrinos, and Sarimveis (2006), the following EC algorithm was used to optimize the evolutionary robust regression parameters predicting software piracy: (a) Generate an initial population of strings in a random manner.
0.041237 - (b) Calculate the total fitness value for each chromosome Xi, i = 1, 2, … , n and for the population.
0.000000 - (17) where n = population size.
0.018265 - (c) Calculate the selection probability pi for each chromosome Xi.
0.062745 - (18) (d) Use genetic operators such as the mutation operator and the crossover operator.
0.033755 - In the mutation operator some members of the population are altered randomly.
0.043956 - In the crossover operator new generations are borne from a random combination of the old ones.
0.058608 - (e) Replace the current population with the new one and, if necessary, go to step (b).
0.073333 - In this context the “fitness” refers to a measure of how closely the regression expression fits the data points.
0.078658 - Selection determines those partial solutions that contribute to the next generation of solutions and genetic operators or reproduction is the method used to combines and transforms partial solutions into new representations.
0.109589 - A flowchart of this algorithm is provided in Fig 2.
0.020833 - Evolutionary computation robust regression flowchart Fig 2.
0.022989 - Evolutionary computation robust regression flowchart.
0.039216 - Multi-layer perceptron MLP consists of sensory units that make up the input layer, one or more hidden layers of processing units (perceptrons), and one output layer of processing units (perceptrons).
0.031373 - The MLP performs a functional mapping from the input space to the output space.
0.037522 - An MLP with a single hidden layer having H hidden units and a single output, y, implements mappings of the form (19) (20) where Zh is the output of the hth hidden unit, Wh is the weight between the hth hidden and the output unit, and W0 is the output bias.
0.000000 - There are n sensory inputs, Xj.
0.078431 - The jth input is weighted by an amount βj in the hth hidden unit.
0.080586 - The output of an MLP is compared to a target output and an error is calculated.
0.143939 - This error is back-propagated to the neural network and used to adjust the weights.
0.080000 - This process aims at minimizing the mean square error between the network’s prediction output and the target output.
0.106615 - One of the first successful applications of MLP is reported by Lapedes and Farber (1988).
0.045113 - Using two deterministic chaotic time series generated by the logistic map and the Glass–Mackey equation, they designed an MLP that can accurately mimic and predict such dynamic nonlinear systems.
0.050633 - There is an extensive literature in financial applications of MLP (e.g.
0.000000 - Harvey, Travers, & Costa, 2000; Kumar & Bhattacharya, 2006).
0.050633 - Another major application of MLP is in electric load consumption (e.g.
0.000000 - Darbellay & Slama, 2000; McMenamin & Monforte, 1998).
0.019900 - Many other problems have been solved by MLP.
0.000000 - A short list includes air pollution forecasting (e.g.
0.010178 - Videnova, Nedialkova, Dimitrova, & Popova, 2006), maritime traffic forecasting (Mostafa, 2004), airline passenger traffic forecasting (Nam and Yi., 1997), railway traffic forecasting (Zhuo, Li-Min, Yong, & Yan-hui, 2007), commodity prices (Kohzadi, Boyd, Kemlanshahi, & Kaastra, 1996), ozone level (Ruiz-Suarez, Mayora-Ibarra, Torres-Jimenez, & Ruiz-Suarez, 1995), student grade point averages (Gorr, Nagin, & Szczypula, 1994), forecasting macroeconomic data (Aminian, Suarez, Aminian, & Walz, 2006), advertising (Poh, Yao, & Jasic, 1998), and market trends (Aiken & Bsat, 1999).
0.078070 - The MLP is the most frequently used neural network technique in pattern recognition (Bishop, 2006) and classification problems (Sharda, 1994).
0.018265 - However, numerous researchers document the disadvantages of the MLP approach.
0.080000 - For example, Calderon and Cheh (2002) argue that the standard MLP network is subject to problems of local minima.
0.055046 - Swicegood and Clark (2001) claim that there is no formal method of deriving a MLP network configuration for a given classification task.
0.062745 - Thus, there is no direct method of finding the ultimate structure for modeling process.
0.048930 - Consequently, the refining process can be lengthy, accomplished by iterative testing of various architectural parameters and keeping only the most successful structures.
0.030303 - Wang (1995) argues that standard MLP provides unpredictable solutions in terms of classifying statistical data.
0.055096 - Probabilistic neural network PNN is used for classification problems where the objective is to assign cases to one of a number of discrete classes (Hunter, 2000).
0.049587 - Theoretically, the PNN can classify an out-of-sample data with the maximum probability of success when enough training data is given (Enke and Thawornwong, 2005).
0.047059 - PNNs feature a feed-forward architecture and supervised training algorithm similar to back propagation.
0.066667 - The training pattern is presented to the input layer.
0.039448 - The main role of the input layer is to map all the external signals into hidden layers by a scaling function through which each input neuron normalizes the range of external signals into a specific range that the neuron network can process.
0.041995 - The neurons in hidden layer aim to add flexibility to the performance of the PNN so as to recording the knowledge of classification extracted from the training pattern.
0.023810 - There must be, at least, as any neurons in the hidden layer as the number of training patterns (Tam, Tong, Lau, & Chan 2005).
0.034783 - The summation layer consists of one neuron for each data class and sums the outputs from all hidden neurons of each respective data class.
0.018265 - The output layer has one neuron for each possible category.
0.063768 - The network produces activation, a value between zero and one in the output layer corresponding to the probability density function estimated from that category.
0.017544 - The output with the highest value represents the most probable category.
0.048780 - The PNN was originally introduced to the neural network literature by Specht (1990).
0.013333 - PNNs require no assumptions about distributions of random variables used to classify; they even can handle multi-modal distributions.
0.033755 - They train quickly and as well as, or better than MLP networks.
0.066667 - They have the ability to provide mathematically sound confidence levels and are relatively insensitive to outliers (Singer & Bliss, 2003).
0.044077 - While the MLP network requires a validation data set (i.e., wasted cases) to search for over-fitting, PNNs use all available data in model building.
0.030336 - The PNN is based on Bayes’ classification method shown in Eq (21), where hi and hj are the prior probabilities, ci and cj are the costs of misclassification, ad fi(x) and fj(x) are the true probability density functions: (21) In his seminal work, Specht (1990) presented the probability density estimates of a two class problem as (22) (23) where x is the random vector of input data, Φn is a kernel density function, TA and TB are the number of samples for classes A and B, respectively, and cAn and cBn are the training data for classes A and B, respectively.
0.255884 - In this study software piracy rates across nations are grouped into four categories.
0.138817 - Following Yang (2007), software piracy interval set of rates < 25% is referred to as ‘very low piracy rate’.
0.157479 - Software piracy interval set of rates between 25% and 50% is referred to as ‘low piracy rate’.
0.157479 - Software piracy interval set of rates between 50% and 80% is referred to as ‘high piracy rate’.
0.153178 - Software piracy interval set of rates > 80% is referred to as ‘very high piracy rate’.
0.063253 - Thus, for the classification of piracy rates, there are four different output classes and the conditional density estimates for each of these four classes can be written as (24) where C is the class number.
0.019048 - The selection process can be justified using Bayes Theorem.
0.098870 - According to this theorem, the probability that the feature, x, belong to class i is (25) where fx(x) is the density of x.
0.106278 - This can be written as (26) (27) Since fx(x), the density of x, is the same for all i and the probability that the occurrence of each software piracy class is the same [i.e., P(C = 1) = P(C = 2) = ⋯ = P(C = 4)], the αis are going to be the same for all these classes.
0.053763 - The PNN has been extensively used in various pattern classification tasks in the literature due to ease of training and sound statistical foundation in Bayesian estimation theory.
0.056604 - For example, Yang and Marjorie (1999) utilized a PNN to predict the financial crisis in oil industry companies in the USA.
0.031373 - Jin and Srinivasan (2001) proposed a new technique for freeway incident detection using PNN.
0.089431 - Hajmeer and Basheer (2002) used PNN to study the classification of bacterial growth.
0.052632 - Chen, Leung, and Daouk (2003) applied PNN to stock index forecasting.
0.056911 - Huang (2004) applied PNN to predict the class of leukaemia and colon cancer.
0.047059 - Gerbec, Gasperic, Smon, and Gubina (2005) used PNN to classify consumers’ electricity load profiles.
0.027491 - Xue, Zhang, Liu, Hu, and Fan (2005) classified 102 active compounds from diverse medicinal plants with anticancer activity.
0.077670 - Jin and Englande (2006) used PNN to classify whether a condition in a lake is safe to swim or not.
0.030303 - Wilson (2006) successfully tested the PNN on 209 seizures obtained from an epilepsy-monitoring unit.
0.063830 - Laskari, Meletiou, Tasoulis, and Vrahatis (2006) evaluated the performance of PNN on approximation problems related to cryptography.
0.036630 - Radial basis function neural network The basic architecture for a RBFNN is a 3-layer network.
0.073171 - The input layer is simply a fan-out layer and does no processing.
0.022039 - The second or hidden layer performs a non-linear mapping from the input space into a higher dimensional space in which the patterns become linearly separable.
0.016260 - The final layer therefore performs a simple weighted sum with a linear output.
0.071184 - The unique feature of the RBFNN is the process performed in the hidden layer.
0.075949 - The idea is that the patterns in the input space form clusters.
0.013746 - If the centers of these clusters are known, then the distance from the cluster centre can be measured.
0.088235 - Furthermore, this distance measure is made non-linear, so that if a pattern is in an area that is close to a cluster centre it gives a value close to 1.
0.083333 - Beyond this area, the value drops dramatically.
0.071625 - The notion is that this area is radially symmetrical around the cluster centre, so that the non-linear function becomes known as the radial-basis function.
0.050847 - Since the RBFNN has only one hidden layer and has fast convergence speed, it is widely used for non-linear mappings between inputs and outputs.
0.016750 - Examples include detecting spam email (Jiang, 2007), financial distress prediction (Cheng, Chen, & Fu, 2006), public transportation (Celikoglu & Cigizoglu, 2007), classification of active components in traditional medicine (Liu, Wen, & Gao, 2009), classification of audio signals (Dhanalakshmi, Palanivel, & Ramalingam, 2009), prediction of athletes performance (Iyer & Sharda, 2009), and face recognition (Balasubramanian, Palanivel, & Rmalingam, 2009).
0.040528 - The RBFNN implements a mapping of input vector X to output vector Y as f: RN → RM according to, (28) where X ϵ RN is the input vector, Gj(·) is the radial basis function from RN to R, ||·|| denotes the Euclidean distance, Wkj (1 ⩽ j ⩽ P and 1 ⩽ k ⩽ M) are the weights connecting the kth output node to the jth radial basis function node, C ϵ RN are known as the RBFNN centers, and P is the number of centers.
0.033898 - Haykin (2001) describes a number of choices for the radial basis function G. The most popular being the multi-dimensional Gaussian shown in Eq (29).
0.059448 - (29) The RBFNN classifier is a further extension to the RBFNN, where we look for the output node having the maximum activation and label the input to be of the class as indexed by the output node index.
0.014652 - As for example, consider the case of classifying M patterns from their N dimensional feature vectors.
0.057143 - The RBFNN outputs are computed according to Eq (28).
0.037652 - The input vector is labeled to be of the pth pattern class if Yp > Yk, ∀k = 1, 2, … , M and k ≠ p. For the feature vector of the pth class we set the desired output vector D as, (30) Now, for initializing the weight matrix W, we compute the hidden layer outputs for all the T training patterns and form the matrix H of size P × T. Similarly we form the matrix Q of size M × T consisting of the desired output vectors arranged in columns.
0.043538 - The initial weight matrix W (M × P) is computed from the relation, (31) For minimizing the training error, we compute the pattern error ζ(t) for the tth training pattern as, (32) (33) where yk is the network output computed by Eq (28).
0.046667 - If the network parameters are optimized with respect to each pattern error, the procedure is called pattern mode training.
0.047956 - However, the parameters can also be adjusted by optimizing the global error over the training data set, which is the batch mode training.
0.058252 - The batch mode training allows a better estimate of the training error and is also faster than the pattern mode.
0.050251 - For training in batch mode, the pattern error is computed as in Eq (34) for each training data and the global error E is simply the average of these pattern errors computed (34) The network-training objective is to minimize E. The parameters are updated till the required error goal is reached.
0.028369 - The parameters of the nth iteration are updated for the (n + 1)th iteration according to Eqs.
0.045235 - (35)–(37) (35) (36) (37) where ηc, ηs and ηw are the respective learning rates for RBFNN center, RBFNN spread and connection weights, respectively and hj is the output of the jth radial basis function.
0.012232 - Generalized regression neural network GRNN was devised by Specht (1991), casting a statistical method of function approximation into a neural network form.
0.075601 - The GRNN, like the MLP, is able to approximate any functional relationship between inputs and outputs (Wasserman, 1993).
0.021858 - Structurally, the GRNN resembles the MLP.
0.022599 - However, unlike the MLP, the GRNN does not require an estimate of the number of hidden units to be made before training can take place.
0.061538 - Furthermore, the GRNN differs from the classical MLP in that every weight is replaced by a distribution of weight which minimizes the chance of ending up in local minima.
0.041026 - Therefore, no test and verification sets are required, and in principle all available data can be used for the training of the network (Parojcic, Ibric, Djuric, Jovanovic, & Corrigan, 2007).
0.021978 - However other researchers have used holdout samples to prevent the risk of over-fitting (e.g.
0.000000 - Ben-Nakhi & Mahmoud, 2004; Raitsos et al., 2008).
0.061162 - The GRNN is a method of estimating the joint probability density function (pdf) of x and y, giving only a training set.
0.036032 - The estimated value is the most probable value of y and is defined by (38) The density function f(x, y) can be estimated from the training set using Parzen’s estimator (Parzen, 1962) (39) The probability estimate f(x, y) assigns a sample probability of width σ for each sample xi and yi, and the probability estimate is the sum of these sample probabilities (Specht, 1991).
0.055096 - Defining the scalar function (40) and assessing the indicated integration yields the following: (41) The resulting regression (41) is directly applicable to problems involving numerical data.
0.053571 - Due to its good performance in noisy environments, the GRNN has been extensively used in various prediction and forecasting tasks in the literature.
0.042553 - For example, Gaetz, Weinberg, Rzempoluck, and Jantzen (1998) analyzed EEG activity of the brain using a GRNN.
0.033755 - Chtioui, Panigrahi, and Francl (1999) used a GRNN for leaf wetness prediction.
0.054983 - Ibric, Jovanovic, Djuric, Parojcic, and Solomun (2002) used a GRNN in the design of extended-release aspirin tablets.
0.033755 - Cigizoglu (2005) employed a GRNN to forecast monthly water flow in Turkey.
0.156141 - In this study, GRNN forecasting performance was found to be superior to the MLP and other statistical and stochastic methods.
0.045455 - Kim and Lee (2005) used a GRNN-based genetic algorithm to predict silicon oxynitride etching.
0.082927 - Hanna, Ural, and Saygili (2007) developed a GRNN model to predict seismic condition in sites susceptible to liquefaction.
0.033058 - Shie (2008) used a hybrid method integrating a GRNN and a sequential quadratic programming method to determine an optimal parameter setting of an injection-molding process.
0.079511 - Self-organizing maps The SOM, also called Kohonen map, is a heuristic model for exploring and visualizing patterns in high dimensional datasets.
0.059072 - It was first introduced to the neural networks community by Kohonen (1982).
0.032258 - SOM can be viewed as a clustering technique that identifies clusters in a dataset without the rigid assumptions of linearity or normality of more traditional statistical techniques.
0.021505 - Indeed, like k-means, it clusters data based on an unsupervised competitive algorithm where each cluster has a fixed coordinate in a topological map (Audrain-Pontevia, 2006).
0.073394 - The SOM is trained based on an unsupervised training algorithm where no target output is provided and the network evolves until convergence.
0.065125 - Based on the Gladyshev’s theorem, it has been shown that SOM models have almost sure convergence (Lo & Bavarian, 1993).
0.050125 - The SOM consists of only two layers: the input layer which classifies data according to their similarity, and the output layer of radial neurons arranged in a two-dimensional map.
0.042553 - Output neurons will self-organize to an ordered map and neurons with similar weights are placed together.
0.032362 - They are connected to adjacent neurons by a neighborhood relation, dictating the topology of the map (Moreno, Marco, & Olmeda, 2006).
0.032520 - The number of neurons can vary from a few dozen to several thousand.
0.032184 - Since the SOM compresses information while preserving the most important topological and metrical relationships of the primary data elements on the display, it can also be used for pattern classification (Silven, Niskanen, & Kauppinen, 2003).
0.050847 - Due to the unsupervised character of their learning algorithm and the excellent visualization ability, SOMs have been recently used in myriad classification and clustering tasks.
0.015094 - Examples include classifying cognitive performance in schizophrenic patients and healthy individuals (Silver & Shmoish, 2008), mutual funds classification (Moreno et al., 2006), speech quality assessment (Mahdi, 2006), vehicle routing (Ghaziri & Osman, 2006), network intrusion detection (Zhong, Khoshgoftaar, & Seliya, 2007), anomalous behavior in communication networks (Frota, Barreto, & Mota, 2007), compounds pattern recognition (Yan, 2006), market segmentation (Kuo et al., 2002), clustering green consumer behavior (Mostafa, 2009) and classifying magnetic resonance brain images (Chaplot, Patnaik, & Jagannathan, 2006).
0.215994 - Preliminary data analysis In this study software piracy data were taken from the BSA global software piracy study (BSA, 2009).
0.248622 - This data set is the latest available data on software piracy.
0.030303 - GDP data were taken from the World Bank’s World Development Indicators (World Bank, 2009).
0.059701 - Consistent with other cross-national studies (e.g.
0.042553 - Andres, 2006b), we use the natural logarithm transformation of the GDP data to correct for excessive skewness.
0.014652 - School enrollment data were taken from the World Bank’s World Development Indicators (World Bank, 2009).
0.015686 - Domestic income inequality data were taken from the World Income Inequality Database (WIID, 2009).
0.000000 - These data are measured as Gini coefficients.
0.000000 - A Gini score of zero means perfect equality while a score of one hundred suggests perfect inequality.
0.055402 - R&D expenditure as a percentage of GDP data were taken from the World Bank’s World Development Indicators (World Bank, 2009).
0.000000 - Corruption Perception Index (CPI) data were taken from Transparency International (TA, 2009).
0.065163 - Since 1995, TA has published an annual CPI ordering the countries of the world according to the degree to which corruption is perceived to exist among public officials and politicians.
0.032520 - The corruption index originally ranged from 0 (high corruption) to 10 (low corruption).
0.048930 - Following Piquero and Piquero (2006), we recoded the measure so that lower values indicated low corruption and higher values indicated high corruption.
0.013333 - Finally, rule of law data were taken from the Kaufmann et al.’s governance indicators (Kaufmann, Kraay, & Mastruzzi, 2009).
0.045455 - The Worldwide Governance Indicators (WGI) dataset has been found valid and reliable (Kaufmann & Kraay, 2008).
0.033755 - Table 1 provides descriptive statistics for all variables used in the analysis.
0.000000 - Table 1.
0.036530 - Descriptive statistics of variables used in the analysis (N = 102).
0.000000 - Variable Mean SD Minimum Maximum PIR 0.616 0.224 0.200 0.930 LnGDP 8.859 1.052 6.522 10.893 ResDev 0.884 0.982 0.018 4.527 CPI 5.308 2.285 0.700 8.700 SchEnr 73.890 17.411 22.000 100.000 Gini 39.625 9.234 22.800 66.600 LAW 0.218 1.025 −1.670 2.000 4.2.
0.143196 - Bayesian regression In this study the Bayesian parameter estimation was conducted using the WinBUGS software (Spiegelhalter, Thomas, Best, & Lunn, 2003).
0.123002 - WinBUGS has a built-in likelihood function for uncensored and censored normal data that was used in this study (WinBUGS code used in this study is shown in Appendix A.1).
0.024465 - For the Bayesian regression model, three chains of 1000,000 observations were generated for each parameter of interest, using posterior conditional distributions.
0.045350 - For each chain, the first 100,000 iterations were burned to filter the effect of starting values, with every 10th observation saved to reduce the autocorrelation of the Gibbs sequence.
0.057971 - The Bayesian estimate is taken as the posterior mean of parameters, and 95% HPD (highest probability density) was obtained from the posterior distribution quantiles.
0.022599 - It should be noted that these credible intervals have the intuitive interpretation as indicating a 95% probability that the true value falls within that range.
0.033898 - In other words, these intervals are interpreted in the way that frequentist-based confidence intervals are sometimes incorrectly interpreted (Billoir, Delignete-Muller, Pery, & Charles, 2008).
0.041667 - The results are given in Table 2.
0.011594 - Three of the six estimates for the effects of explanatory variables are reliable at conventional levels (a 95% HPD interval bounded away from zero).
0.024465 - Fig 3 shows the kernel density plots of the posterior marginal distributions for four parameters (similar results were obtained for other parameters).
0.042781 - While it is enough to observe whether 0 is included or not in the interval, several authors suggest using the posterior density kernels to help researchers to decide whether a parameter is significant or not even in cases in which 0 is included in the interval (e.g.
0.000000 - Martin, Roman, & Voltes-Dorta, 2009, p. 167).
0.056497 - We notice from Table 2 that estimates obtained from the Bayesian regression are quite similar to the estimates obtained from the OLS and robust regression.
0.107692 - In regression models such as this, it is expected that the posterior estimates to be very similar to the maximum likelihood estimators with non-informative priors on the parameters.
0.000000 - Table 2.
0.000000 - Bayesian regression results.
0.000000 - Estimate MCSE Std.
0.000000 - dev.
0.008439 - 95% HPD interval Intercept −0.05885 0.000123 0.00998 [−0.094 : −0.0360] LnGDP −0.01835 0.000084 0.00759 [−0.034 : −0.0196] SchEnr 0.01037 0.000007 0.00080 [−0.004 : 0.0328] CPI −.06122 0.000078 0.00599 [−0.026 : 0.0589] ResDev −0.01363 0.000055 0.00863 [−0.082 : −0.0518] Gini −0.04163 0.000007 0.00128 [−0.002 : 0.0095] LAW −0.00514 0.000078 0.00927 [−0.009 : −0.0019] Kernel density estimation of parameters included in Bayesian regression model Fig 3.
0.036530 - Kernel density estimation of parameters included in Bayesian regression model.
0.052174 - Convergence diagnostics can be used to estimate whether MCMC equilibrium has been reached and the chain does not need to be propagated any further.
0.121563 - In this study the MCMC simulation results were subjected to several diagnostics tests using the CODA (Convergence Diagnostics and Output Analysis) software package (Best, Cowles, & Vines, 1996) and the SAS package version 9.2 (SAS Institute, 2008).
0.049645 - SAS code used to run the Bayesian regression model diagnostics can be found in Appendix A.2.
0.026667 - Diagnostic tests conducted are Geweke (1992), Heidelberger and Welch (1992), Raftery and Lewis (1992) and Gelman and Rubin (1992).
0.052632 - Geweke (1992) diagnostic test is based on standard time series methods.
0.065476 - This diagnostic applies a simple Z-test to check whether the means estimated from two different subsamples of the MCMC output are equal.
0.088729 - Table 3 shows that all Z values are within −2 and 2, indicating no differences in the means for the first and last sets of iterations.
0.000000 - Table 3.
0.000000 - Geweke diagnostics.
0.024922 - Parameter z Pr > |z| beta0 −0.1065 0.9152 beta1 1.1469 0.2514 beta2 −0.9939 0.3203 beta3 −0.5112 0.6092 beta4 −0.0704 0.9439 beta5 0.1359 0.8919 beta6 −0.1860 0.8524 sigma2 0.5733 0.5664 Heidelberger and Welch (1992) diagnostic tests whether stationarity of the MCMC is attained.
0.110480 - If this hypothesis is rejected, then the first 10% of the total iterations is discarded and the test is repeated on the remaining sample (Ntzoufras, 2009).
0.075472 - This procedure is repeated until the test of stationarity is not rejected or more than 50% of the sample is discarded.
0.066667 - If the test is passed, then the number of iterations that have been used to pass the test, the discarded iterations, and the Cramer-von Mises statistic are reported.
0.076190 - Table 4 shows the Heidelberger and Welch diagnostic results.
0.102564 - From this table we see that virtually all parameters have passed the Heidelberger and Welch diagnostic.
0.000000 - Table 4.
0.000000 - Heidelberger–Welch diagnostics.
0.008869 - Parameter Cramer–von-Mises Stat Stationarity test Half-width Relative mean Half-width test p Test outcome Half-width Test outcome beta0 0.1808 0.3081 Passed 0.000165 0.0044 0.0369 Passed beta1 0.2879 0.1463 Passed 0.000144 0.0126 0.0114 Passed beta2 0.2651 0.1701 Passed 0.000014 −0.0007 −0.0182 Passed beta3 0.1504 0.3885 Passed 0.000127 0.0553 0.0022 Passed beta4 0.0616 0.8041 Passed 0.000103 −0.0126 −0.0081 Passed beta5 0.1051 0.5605 Passed 0.000014 0.0068 0.0020 Passed beta6 0.2310 0.2147 Passed 0.000140 −0.0165 −0.0085 Passed sigma2 0.0653 0.7807 Passed 0.000021 0.0144 0.0014 Passed Unlike Geweke and the Heidelberger and Welch diagnostics, Raftery and Lewis (1992) diagnostic focuses on achieving a pre-specified degree of accuracy of specific quantiles rather than the convergence of the mean.
0.073751 - The default measure in both CODA and SAS is the 2.5% percentile estimated with accuracy 0.005 and probability 0.95.
0.063927 - Raftery and Lewis diagnostic results are shown in Table 5.
0.086022 - From this table we conclude that a sample size equal to 27,842 iterations is required to obtain the pre-specified accuracy for the 2.5% quantile.
0.040000 - Since burn-in is generally low (we have already removed 100,000 iterations), no additional burn-ins is needed.
0.062992 - However, the dependence factor for some parameters is high, indicating high autocorrelation for these parameters and that a wider thinning interval may be required to make observations independent.
0.060426 - Autocorrelation plots for the first four parameters are shown in Fig 4 (Similar results were obtained for other parameters).
0.035088 - Table 6 shows parameter autocorrelations against the lag for each parameter.
0.032520 - The autocorrelations appear to be very small after lag 50 for all parameters.
0.000000 - Table 5.
0.000000 - Raftery–Lewis diagnostics.
0.004975 - Dependence parameter Burn-in Number of samples Total Minimum Factor beta0 17 27,842 3746 7.4325 beta1 12 18,131 3746 4.8401 beta2 8 12,761 3746 3.4066 beta3 17 22,760 3746 6.0758 beta4 6 8833 3746 2.3580 beta5 5 8367 3746 2.2336 beta6 7 12,548 3746 3.3497 sigma2 3 4072 3746 1.0870 Quantile = 0.025, accuracy = ±0.005, probability = 0.95, epsilon = 0.001.
0.033755 - Autocorrelation plots of first four parameters included in Bayesian regression… Fig 4.
0.052632 - Autocorrelation plots of first four parameters included in Bayesian regression model.
0.000000 - Table 6.
0.000000 - Posterior autocorrelations.
0.016543 - Parameter Lag 1 Lag 5 Lag 10 Lag 50 beta0 0.7345 0.3598 0.2238 0.0192 beta1 0.7198 0.3325 0.1773 0.0002 beta2 0.5064 0.1796 0.1105 0.0033 beta3 0.6783 0.3587 0.2627 0.0237 beta4 0.5214 0.0838 0.0279 0.0029 beta5 0.4418 0.0538 0.0213 0.0020 beta6 0.4339 0.1427 0.0991 −0.0008 sigma2 0.1844 0.0264 0.0171 0.0048 Gelman–Rubin diagnostic is an ANOVA-based diagnostic, calculating a shrinking factor by which the scale parameter of the marginal posterior distribution of each variable might be reduced if the chain was run to infinity (Huang et al., 2007).
0.019900 - Shrinking factor values close to one indicate convergence.
0.058252 - Both the median and 97.5% quantiles stabilize around the expected value 1.0, indicating that our model have converged.
0.020833 - We also examined the MCMC convergence visually.
0.019048 - The trace plots are very effective convergence diagnostic tools.
0.033755 - Fig 5 provides the trace plots from fitting the Bayesian regression model.
0.117292 - This graph shows that the mean of the Markov chain has stabilized and appears constant over the graph.
0.078658 - The graph also shows that the chains are “dense” in the sense that they quickly traverse the support of the distribution to explore both the tails and the mode areas efficiently.
0.048780 - Thus, we conclude that the chains appear to have reached their stationary distributions.
0.016260 - Trace plots for posterior samples of parameters included in Bayesian regression… Fig 5.
0.033755 - Trace plots for posterior samples of parameters included in Bayesian regression model.
0.051780 - Robust and evolutionary computation robust regression Multivariate OLS and robust regression were run on all of the hypothesized dependent variables.
0.073446 - One problem that may arise with this type of data is multicollinearity, which is a high degree among two or more of the independent variables.
0.052174 - One of the effects of multicollinearity is that the estimates of the coefficients of the independent variables become very sensitive to the data used.
0.046154 - A maximum VIF value in excess of 10 is frequently taken as an indication that multicollinearity may be unduly influencing the least square estimates (Kutner, Nachtsheim, Netter, & Li 2005).
0.079699 - VIF values calculated show that multicollinearity is not a serious problem.
0.192835 - From Table 7 we see that software piracy is likely to be negatively affected by the nation’s wealth as measured by GDP.
0.210755 - This result supports hypothesis 1 and it is also in line with other studies that found GDP is inversely related to software piracy rates (e.g., Husted, 2000).
0.171321 - Expenditure on research and development as a percentage of GDP was also found to be inversely related to software piracy rates.
0.068966 - This result supports hypothesis 4.
0.117706 - It also confirms other research results which found a negative relationship between wealth and software piracy (e.g., Husted, 2000).
0.157479 - As expected, rule of law was found to be negatively and significantly related to software piracy rates.
0.068966 - This result supports hypothesis 6.
0.048780 - It is also in line with other research findings (e.g., Andres, 2006a).
0.150807 - School enrolment rates were also found to be negatively related to software piracy rates.
0.059701 - However, this variable did not reach statistical significance.
0.145689 - Corruption perception index and Gini coefficients were not significantly related to software piracy rates at the global level.
0.059701 - Variance explained by the OLS model was 85%.
0.032520 - Internal validation of the final model’s R2 was performed using bootstrapping techniques.
0.082474 - Following Efron and Tibshirani (1994), several thousand bootstrap estimates for R2 were calculated within the R software environment.
0.076739 - From Fig 6 we see that the variance explained by the OLS model is stable around 0.846 (The R code used to bootstrap R2 can be found in Appendix A.3).
0.000000 - Table 7.
0.000000 - OLS regression results.
0.004762 - Estimate SE t-Value Pr(>|t|) Intercept 1.2190 0.210700 5.786 <0.001⁎⁎ LnGDP −0.062580 0.023120 −2.706 0.00829⁎⁎ SchEnr −0.000324 0.001029 −0.316 0.75319 CPI 0.005619 0.017210 0.327 0.74489 ResDev −0.044140 0.015430 −2.860 0.00539⁎⁎ Gini 0.000003 0.001173 0.002 0.99809 LAW −0.101000 0.037760 −2.676 0.00901⁎⁎ Residual standard error: 0.09131 on 81 degrees of freedom.
0.000000 - Multiple R2: 0.8462, adjusted R2: 0.8348.
0.048780 - F-statistic: 74.27 on 6 and 81 DF, p-value: <0.001.
0.000000 - ⁎⁎ P < 0.001.
0.020833 - Bootstrapping R2 in OLS regression Fig 6.
0.022989 - Bootstrapping R2 in OLS regression.
0.016878 - Table 8 reports the robust regression results using the M-estimators techniques.
0.031373 - These results are generally in line with the results obtained from the OLS regression.
0.105737 - Fig 7 compares the weight functions for the two M-estimators used to conduct the robust regression in this study: the Huber estimator and the Tukey bisquare (or biweight) estimator.
0.036697 - From Fig 7, we see that the weights for the Huber estimator are 1.0 for residuals on a plateau around zero.
0.032520 - As the residuals increase the weights drop off concavely to a lower weight.
0.051282 - The weights for the Tukey’s bisquare estimator peak at the zero residuals and then tail off in a convex curve down to zero weights for extremely large residuals.
0.000000 - Table 8.
0.000000 - Robust regression results.
0.005650 - Estimate SE t-Value Panel A: Huber weight estimates Intercept 1.1950 0.2050 5.8290 LnGDP −0.0581 0.0225 −2.5819 SchEnr −0.0003 0.0010 −0.3327 CPI 0.0048 0.0167 0.2892 ResDev −0.0401 0.0150 −2.6677 Gini −0.0003 0.0011 −0.2618 LAW −0.1157 0.0367 −3.1486 Panel B: Bisquare weight estimates Intercept 1.1997 0.2021 5.9346 LnGDP −0.0587 0.0222 −2.6437 SchEnr −0.0003 0.0010 −0.3499 CPI 0.0051 0.0165 0.3070 ResDev −0.0400 0.0148 −2.7019 Gini −0.0003 0.0011 −0.2587 LAW −0.1143 0.0362 −3.1539 LMS estimate LTS estimate Panel C: Least median squares and least trimmed squares estimates LMS estimate LTS estimate Intercept 1.5818 1.1462 LnGDP −0.0893 −0.0349 SchEnr 0.0012 −0.0005 CPI −0.0444 −0.0253 ResDev −0.0358 −0.0699 Gini 0.0012 0.0014 LAW −0.2216 −0.1717 Huber and bisquare weights for robust regression Fig 7.
0.041667 - Huber and bisquare weights for robust regression.
0.117306 - The Free Evolutionary Algorithm Kit package (Rfreak) developed by Nunkesser (2008) was used to analyze evolutionary algorithms in this study.
0.131868 - Rfreak is an R interface software package written in Java to design and analyze EC models.
0.067092 - A critical parameter of EC models in solving an optimization problem effectively is the number of iterations (i.e.
0.000000 - generations).
0.126682 - In this study number of generations of the size 1,000,000 are employed.
0.032520 - Appendix A.4 provides the codes used to conduct the EC robust regressions.
0.043716 - Results are shown in Table 9.
0.100629 - From this table it is evident that EC robust regression results are generally in line with OLS and robust regression results.
0.000000 - Table 9.
0.022989 - Evolutionary computation robust regression results.
0.000000 - LMS Est.
0.000000 - LTS Est.
0.000000 - LQD Est.
0.000000 - LQS Est.
0.000000 - Intercept 0.6568 1.0300 1.2310 0.5982 LnGDP −0.0254 −0.0091 −0.0303 −0.0225 SchEnr −0.0012 −0.0021 −0.0002 −0.0003 CPI 0.0445 0.0037 −0.0073 0.0614 ResDev 0.0037 −0.2192 −0.0178 0.0176 Gini 0.0014 −0.0002 −0.0073 −0.0031 LAW −0.0598 −0.0615 −0.1987 −0.0721 4.4.
0.073260 - MLP, PNN and RBFNN-based classification There are many software packages available for analyzing MLP models.
0.032520 - We chose both NeuroIntelligence (Alyuda, 2003) and SPSS Neural Networks (SPSS, 2007) packages.
0.153148 - Both software packages apply artificial intelligence techniques to automatically find the efficient MLP architecture (MLP design used in this study is shown in Fig 8).
0.041237 - Typically, the application of MLP requires a training data set and a testing data set (Lek & Guegan, 1999).
0.075362 - The training data set is used to train the MLP and must have enough examples of data to be representative for the overall problem.
0.057971 - The testing data set should be independent of the training set and is used to assess the classification accuracy of the MLP after training.
0.024465 - Following Lim and Kirikoshi (2005), an error back-propagation algorithm with weight updates occurring after each epoch was used for MLP training.
0.019900 - The learning rate was set at 0.1.
0.067511 - Table 10 reports the properties and predictive accuracy of the MLP model.
0.032258 - As can be observed, the MLP classifier predicted training sample with 66.2% accuracy, validation sample with 65.4% accuracy and holdout sample with 81.8% accuracy.
0.099502 - MLP architecture used in the study Fig 8.
0.109290 - MLP architecture used in the study.
0.000000 - Table 10.
0.068966 - MLP properties and model summary.
0.007207 - MLP network information Input layer Covariates 1 LnGDP 2 LAW 3 ResDev 4 CPI 5 SchEnr 6 Gini Number of unitsa 6 Rescaling method for covariates Standardized Hidden layer(s) Number of hidden layers 1 Number of units in hidden layer 1a 7 Activation function Hyperbolic tangent Output layer Dependent variables 1 PIR Number of units 4 Activation function Softmax Error function Cross-entropy Training Cross entropy error 49.336 Percent incorrect predictions 33.8% Stopping rule used 1 consecutive step(s) with no decrease in errorb Testing Cross entropy error 18.201 Percent incorrect predictions 34.6% Holdout Percent incorrect predictions 18.2% a Excluding the bias unit.
0.047619 - b Error computations are based on the testing sample.
0.118250 - The PNN network used in this study was trained with 80% of the data selected randomly.
0.067146 - Network training is a process by which the connection weights and biases of the NN are adapted through a continuous process of simulation by the environment in which the network is embedded.
0.076577 - The primary purpose of training is to minimize an error function by searching for a set of connections strengths and biases that causes the NN to produce outputs that are equal or close to targets.
0.000000 - A number of training algorithms can be used.
0.022599 - In practice, the Levenberg–Marquardt routine often finds better optima for a variety of problems than do the other optimization techniques (Shavlick, Mooney, & Towell, 1991).
0.056497 - After the training phase the NN model is applied to the data set to classify each nation’s EF into one of the four categories.
0.092827 - There are many computer software packages available for building and analyzing PNNs.
0.102697 - Because of its extensive capabilities for building networks based on a variety of training and learning methods, NeuralTools Professional package (Palisade, 2005) was chosen in this study.
0.125000 - This software automatically scales all input data.
0.042553 - Scaling involves mapping each variable to a range with minimum and maximum values of 0 and 1.
0.056604 - NeuralTools Professional software uses a non-linear scaling function known as the ‘tanh’, which scales inputs to a (−1, 1) range.
0.089347 - This function tends to squeeze data together at the low and high ends of the original data range.
0.030303 - It may thus be helpful in reducing the effects of outliers (Tam et al., 2005).
0.041667 - PNN properties are shown in Table 11.
0.000000 - Table 11.
0.068966 - PNN properties and model summary.
0.000000 - Net information Configuration PNN category predictor Independent category variables 0 Independent numeric variables 6 (SchEnr, LnGDP, Gini, LAW, ResDev, CPI) Dependent variable Category var.
0.034783 - (piracy) Training Number of cases 82 Number of trials 94 Reason stopped Auto-stopped % Bad predictions 19.5122% Mean incorrect probability 40.3472% Std.
0.000000 - deviation of incorrect prob.
0.000000 - deviation of incorrect prob.
0.067511 - The basic configuration of the RBFNN used is shown in Table 12.
0.041995 - The learning rates for the RBFNN parameters are varied between 0.001 and 0.1 and that for the weights are varied between 0.1 and 0.7.
0.036697 - The training is stopped if either the error goal reaches 0.001 or if the maximum texture misclassification becomes lower than 1%.
0.017544 - Fig 9 depicts the exponential decay of the sum squared errors.
0.020833 - Table 12 provides the basic RBFNN properties.
0.051282 - From Table 12 we see that the hit ratio for the holdout sample is 81.8%.
0.019900 - Sum squared error of the RBFNN Fig 9.
0.021858 - Sum squared error of the RBFNN.
0.000000 - Table 12.
0.068966 - RBFNN properties and model summary.
0.000000 - RBF network information Input layer Covariates 1 SchEnr 2 LnGDP 3 Gini 4 LAW 5 ResDev 6 CPI Number of units 6 Rescaling method for covariates Standardized Hidden layer Number of units 9a Activation function Softmax Output layer Dependent variables 1 PIR Number of units 4 Activation function Identity Error function Sum of squares Training Sum of squares error 14.672 Percent incorrect predictions 25.7% Testing Sum of squares error 3.865 Percent incorrect predictions 35.3% Holdout Percent incorrect predictions 18.2% Dependent variable: class.
0.062450 - a Determined by the testing data criterion: the “best” number of hidden units is the one that yields the smallest error in the testing data.
0.133032 - To study the effectiveness of MLP, PNN and RBFNN-based classification of software piracy rates, the results of MLP, PNN and PNN were compared with the traditional multiple discriminant analysis (MDA).
0.039801 - MDA is frequently used supervised pattern recognition technique.
0.057971 - A linear function of the variables is sought, which maximizes the ratio of between-class variance and minimizes the ratio of within-class variance.
0.091324 - MDA is an extremely simple and efficient method of classification.
0.037736 - Indeed, it cannot be outperformed if the two distributions are normal and have the same dispersion matrix (i.e., Bayes limit).
0.036530 - Fig 10 shows the canonical discriminant functions’ EF group centroids.
0.057221 - A common measure of predictive models is the percentage of observation correctly classified or the hit ratio.
0.029304 - Table 13 reports the predictive accuracy of the two NN models as compared with the MDA.
0.033573 - As can be observed in Panel (a), the MLP classifier predicted the training sample with 66.2% accuracy, the test sample with 65.4%, and the holdout sample with 81.8% accuracy.
0.044025 - In panel (b), the PNN classifier predicted the training sample with 81.5% accuracy and the test sample with 75% accuracy.
0.038567 - In Panel (c), the RBFNN classifier predicted the training sample with 74.3% the testing sample with 64.7% and the holdout sample with 81.8%.
0.013333 - MDA model had an accuracy rate of 74.7%, with a leave-one-out validation accuracy of 66.7%.
0.000000 - Canonical discriminant functions’ centroids Fig 10.
0.000000 - Canonical discriminant functions’ centroids.
0.000000 - Table 13.
0.022989 - Predictive accuracy of classification models.
0.000000 - HIGH LOW MED VHIGH % CORRECT Panel (a): MLP Class count (training) HIGH 10 0 3 8 47.6 LOW 0 0 5 0 0.0 MED 2 0 13 0 86.7 VHIGH 4 0 0 20 83.3 Class count (testing) HIGH 3 0 0 5 37.5 LOW 0 0 4 0 0.0 MED 0 0 6 0 100 VHIGH 0 0 0 8 100 Class count (holdout) HIGH 1 0 0 1 50 LOW 0 0 1 0 0.0 MED 0 0 2 0 100 VHIGH 0 0 0 6 100 Panel (b): PNN Class count (training) HIGH 22 0 2 5 75.9 LOW 0 7 1 0 87.5 MED 0 0 14 23 74.2 VHIGH Class count (testing) HIGH 2 0 0 0 100 LOW 0 1 1 0 50 MED 3 0 6 0 66.7 VHIGH 1 0 0 6 85.7 Panel (c): RBFNN Class count (training) HIGH 10 0 2 7 52.6 LOW 0 3 4 0 42.9 MED 2 1 12 0 80 VHIGH 3 0 0 30 90.9 Class count (testing) HIGH 5 0 1 3 55.6 LOW 0 0 0 0 0.0 MED 1 0 5 0 83.3 VHIGH 1 0 0 1 50 Class count (holdout) HIGH 3 0 0 0 100 LOW 0 2 1 0 66.7 MED 0 0 2 0 100 VHIGH 1 0 0 2 66.7 Panel (d): LDAa HIGH 19 0 2 10 61.3 LOW 0 6 4 0 60 MED 3 5 15 0 65.2 VHIGH 6 0 0 32 84.2 a 70.6% or original grouped cases correctly classified; 66.7% of cross-validated grouped cases correctly classified.
0.114832 - Despite the satisfactory classification performance of the MLP, PNN and RBFNN in this study, such models are often criticized as black boxes that do not allow decision-makers to make inferences on how the input variables affect the models’ results.
0.101961 - One way to address this issue is to conduct a variable impact analysis (VIA).
0.078014 - The purpose of VIA is to measure the sensitivity of net predictions to changes in independent variables.
0.094239 - Table 14 shows that the most important input variables for the MLP, PNN and RBFNN are expenditure on research and development, GDP and rule of law.
0.043956 - The lower the percent value for a given variable, the less that variable affects the predictions.
0.034783 - The results of the analysis can help in the selection of a new set of independent variables, one that will allow more accurate predictions.
0.013746 - For example, a variable with a low impact value can be eliminated in favor of some new variables.
0.000000 - Table 14.
0.000000 - Variable impact analysis (VIA).
0.000000 - Normalized importance (%) Panel (a) MLP VIA LnGDP 95.3 LAW 53.5 ResDev 100.0 CPI 34.8 SchEnr 28.3 Gini 36.1 Panel (b) PNN VIA LnGDP 100 LAW 85.8 Gini 31.9 ResDev 8.5 CPI 11.1 SchEnr 10.3 Panel (c) RBFNN VIA SchEnr 61.3 LnGDP 72.4 Gini 53.5 LAW 64.0 ResDev 100.0 CPI 18.9 4.5.
0.121534 - GRNN-based prediction NeuralTools Professional package (Palisade, 2005) was chosen to build the GRNN in this study.
0.121951 - This software uses the conjugate gradient descent optimization technique to train the GRNN.
0.057221 - The error measure used during the training to evaluate different smoothing factors is the mean square error.
0.159398 - GRNN properties used in this study are shown in Table 15.
0.039801 - Fig 11 shows the histogram of GRNN residuals.
0.104971 - This figure shows that no pattern is detected in the GRNN residuals, which suggests that the errors are approximately normally distributed with a mean of zero.
0.175969 - The GRNN was then used to predict software piracy rates.
0.070922 - These predicted values were then plotted against the observed piracy rates values as shown in Fig 12.
0.065476 - Here the straight line indicates the ideal trend where the predicted and observed piracy rates values will be the same at different levels.
0.062745 - The trend line of predicted piracy rates values very closely follows the ideal pattern.
0.031373 - The results were satisfactory, as indicated by the relatively high R2 value of 93%.
0.060606 - The fact that the R2 showed such increase in the GRNN model indicates the data are best represented in a model able to detect nonlinear relationships.
0.057743 - Improved performance from the use of NN versus regression was also found in the work by Larrain (2007) who used both methods to predict treasury bills and inventories.
0.045455 - Similar results were reported in Hurrion and Birgil (1999) and in Radhakrishnan and Nandan (2005).
0.000000 - Table 15.
0.068966 - GRNN properties and model summary.
0.000000 - Net information Configuration GRNN numeric predictor Independent category variables 0 Independent numeric variables 6 (SchEnr, LnGDP, Gini, LAW, ResDev, CPI) Dependent variable Numeric var.
0.027027 - (piracy) Training Number of cases 82 R2 0.94 Number of trials 73 Reason stopped Auto-stopped % Bad predictions (30% tolerance) 8.5366% Root mean square error 8.274 Mean absolute error 6.267 Std.
0.000000 - deviation of abs.
0.000000 - error 5.401 Testing Number of cases 20 R2 0.93 % Bad predictions (30% tolerance) 10.0000% Root mean square error 10.37 Mean absolute error 8.288 Std.
0.000000 - deviation of abs.
0.000000 - error 6.232 Histogram of GRNN residuals Fig 11.
0.000000 - Histogram of GRNN residuals.
0.000000 - GRNN predicted vs Fig 12.
0.000000 - GRNN predicted vs. actual plot.
0.056911 - SOM-based clustering There are many software packages available for analyzing SOM models.
0.054795 - We chose SOMine package version 5.0 (Viscovery software, 2008).
0.146341 - This software applies artificial intelligence techniques to automatically find the efficient SOM clusters.
0.021978 - To visualize the cluster structure, some authors use the unified distance matrix (U-matrix) (e.g.
0.000000 - Stavrou, Spiliotis, & Charalambpuw 2010; Vijayakumar, Damayanti, Pant, & Sreedhar 2007).
0.070588 - However, this method does not give crisp boundaries to the clusters (Worner & Gevrey, 2006).
0.113600 - In this study a hierarchical cluster analysis with a Ward linkage method was applied to the SOM to clearly delineate the edges of each cluster.
0.066667 - The number of neurons is chosen to be 2000.
0.038835 - There are two learning algorithms for SOM (Kohonen, 2001): the sequential or stochastic learning algorithm and the batch learning algorithm.
0.051282 - In the former, the reference vectors are updated immediately after a single input vector is presented.
0.061404 - In the latter, the update is done using all input vectors.
0.066116 - While the batch algorithm does not suffer from convergence problems, the sequential algorithm is stochastic in nature and is less likely trapped to a local minimum.
0.060606 - Following Ding and Patra (2007), we choose the sequential learning algorithm to train the SOM.
0.041667 - Fig 13 shows the SOM cluster indicator.
0.106867 - This figure clearly shows that the SOM converges successfully to a three-cluster solution after 50 iterations.
0.000000 - SOM cluster indicator Fig 13.
0.000000 - SOM cluster indicator.
0.057143 - The SOM cluster results are shown in Fig 14.
0.075758 - This two-dimensional hexagonal grid shows clear division of the input pattern into four clusters.
0.020997 - Since the order on the grid reflects the neighborhood within the data, features of the data distribution can be read off from the emerging landscape on the grid.
0.148267 - Fig 14 shows three discernable clusters of software piracy at the global level.
0.063768 - The three-cluster solution also meets Siew, Smith, Churilov, and Ibrahim (2002) qualitative criteria that should be used to select the representative SOM model.
0.038095 - These criteria include representability, explainability and level of sophistication.
0.062893 - representability refers to the fact that the variables in each cluster should be distinct and carry some information of their own.
0.109804 - This means that the resulting profile for each cluster should be unique and meaningful.
0.039801 - Explainability means that the clusters themselves are distinct.
0.023256 - Level of sophistication means that the size of each cluster should be monitored so that there are no either too large clusters that might hide more distinct groups in the cluster, or too small clusters that might be an indication of artificial clusters.
0.155773 - In this study cluster 1 is called “high piracy.” This blue-colored cluster is the largest cluster with a frequency of 54.9%.
0.110480 - This cluster includes countries characterized by low GDP, high income disequilibrium, high corruption, low school enrollment rate, low R&D expenditure and very weak judiciary system.
0.130821 - Cluster 2 is called “average piracy.” This red-colored cluster has a frequency of 21.57%, and includes countries characterized by higher GDP, school enrollment and R&D expenditure compared to the high piracy nations.
0.048780 - Countries here are also characterized by low corruption perception and good judiciary system.
0.092199 - The third cluster is called “low piracy.” This yellow-colored cluster has a frequency of 23.53%.
0.179519 - This cluster includes nations with very low software piracy rates and nations in this cluster are characterized by very high R&D expenditure, GDP, and school enrollment rate.
0.047059 - Countries here are also characterized by very low corruption perception and excellent judiciary system.
0.038095 - Table 16 summarizes the basic information in each cluster.
0.140634 - The SOM results confirm our regression results, and also previous studies’ results, which found software piracy to be correlated with GDP, percentage of GDP spent on research and development and an index of copyright software protection (e.g.
0.000000 - Andres, 2006a; Husted, 2000).
0.000000 - SOM-ward clusters Fig 14.
0.000000 - SOM-ward clusters.
0.000000 - Table 16.
0.000000 - SOM cluster summary.
0.009840 - Cluster Freq SchEnr CPI LnGDP Gini LAW ResDev PIR 1 54.90% 64.8 7.03 8.10 43.27 −0.583 0.346 0.7763 2 21.57% 77.3 4.500 9.40 38.70 0.717 0.642 0.5455 3 2 3.53% 92.1 2.021 10.14 31.97 1.630 2.361 0.3058 Based on the SOM-Ward clusters, feature or component maps can be constructed (Vesanto, 1999).
0.031373 - These maps are also known in the literature as ‘temperature maps.’ (Churilov & Flitman, 2006).
0.054983 - On these maps, the nodes which share similar information are organized in close color proximity to each other.
0.062745 - Fig 15 shows the feature maps for every cluster and for all input attributes.
0.030303 - Feature maps show the distribution of values of the respective input component over the map.
0.020997 - Relationships between variables could be inspected by visually comparing the pattern of shaded pixels for each map; similarity of the patterns indicates strong monotonic relationships between the variables.
0.032520 - The name of the displayed input component appears on top of each map.
0.073751 - The color scale at the bottom of the component window shows that blue is used for low values, green for mid-range values and red for high values.
0.067797 - From the feature maps we note, for example, that the extreme values represented in red in the CPI feature map matches the high piracy cluster.
0.078431 - Interestingly, this cluster includes the highest constellation of red pixels in the Gini index.
0.128494 - Through the use of colors, one can immediately see the absence of red pixels in every software piracy dimension for the CPI and Gini.
0.161725 - This implies that these two variables are negatively related to software piracy – a result that was previously confirmed by other researchers (e.g.
0.000000 - Andres, 2006b).
0.053333 - In essence, these colorful maps reveal the existence of previously theorized assumptions and it can even create new ones.
0.042553 - The maps also make it possible to find subgroups that do not follow the main theoretical assumptions.
0.053571 - For example, when red dots are found in the middle of the yellow or blue area, this signals the presence of deviant subgroups.
0.033058 - When either blue or red nodes are forming two clearly separated areas, this might be considered as a sign of non-linear correlation (Thneberg & Hotulainen, 2006).
0.000000 - SOM feature maps of input attributes Fig 15.
0.000000 - SOM feature maps of input attributes.
0.027027 - When the SOM produces visual images of each cluster, not only the mean of each cluster is calculated but also other aspects such as which variables make the cluster different from others (Vesanto & Alhoniemi, 2000).
0.000000 - Fig 16 presents a variable-wise importance analysis of each attribute within each cluster.
0.155132 - This ranking of software piracy information within the same group is probably more valuable to policy-makers than overall rankings of software piracy across all groups.
0.019900 - SOM variable importance in each cluster Fig 16.
0.021858 - SOM variable importance in each cluster.
0.157705 - We also applied hierarchical clustering to analyze global software piracy.
0.052174 - The result of the algorithm is a tree of clusters, called a dendogram, which shows how the attributes are grouped in a hierarchical tree.
0.145602 - Fig 17 shows the dendogram of software piracy rates across nations using the agglomerative algorithm.
0.071429 - In this algorithm countries are iteratively combined based on similarity until only one country remains or until a specified termination condition is satisfied.
0.000000 - Dendogram using average linkage (between groups) Fig 17.
0.000000 - Dendogram using average linkage (between groups).
0.093924 - Our results confirm the theoretical work by Hecht-Nielson (1989) who has shown that neuro-computational models can learn input-output relationships to the point of making perfect forecasts with the data on which the network is trained.
0.034783 - However, perfect forecasts with the training data do not guarantee optimal forecasts with the testing data due to differences in the two data sets.
0.143868 - The good performance of these models in predicting and classifying software piracy rates across nations can be traced to its inherent non-linearity.
0.085106 - This makes such techniques ideal for dealing with non-linear relations that may exist in the data.
0.186815 - Thus, neuro-computational models are needed to better understand the inner dynamics of the global software piracy.
0.078273 - Our results are also in line with the findings of other researchers who have investigated the performance of neuro-computational models compared to other traditional statistical techniques, such as regression analysis, discriminant analysis, and logistic regression analysis.
0.073563 - For example, in a study of clinical diagnosis of cancers, Shan, Zhao, Xu, Liebich., and Zhang (2002) found a hit ratio of 85% for the PNN model compared to 80% for the MDA model.
0.068627 - In a study of credit-scoring models used in commercial and consumer lending decisions, Bensic, Sarlija, and Zekic-Susac (2005) compared the performance of logistic regression, neural networks and decision trees.
0.062745 - The PNN model produced the highest hit rate and the lowest type I error.
0.061538 - Similar findings have been reported in a study examining the performance of NN in predicting bankruptcy (Anandarajan, Lee, & Anandarajan 2001) and diagnosis of acute appendicitis (Sakai et al., 2007).
0.124178 - From a policy standpoint, our findings imply that economic development may play an important role in lowering software piracy rates.
0.084746 - Thus, improving the standard of living in less developed countries might lead to a decrease in demand for pirated products, including software and digital products.
0.108820 - Although the relationship between software piracy rates and the wealth of a nation may well be nonlinear – a reminiscent of what is known in the literature as the Environmental Kuznets Curve (EKC), future research should empirically test this link.
0.165555 - Our results also imply that more expenditure on R&D activities, less corrupt governments and efficient judiciary systems would directly influence the benefits or cost of piracy and would thus lead to a decrease in software piracy.
0.079000 - Finally, we believe that software producers’ pledge to donate a portion of their profit to charitable causes in less developed countries might decrease illegal copying of software products.
0.107692 - A recent laboratory study found that donation to charitable causes may increase the moral intensity of piracy and consequently may reduce the willingness to pirate (Grolleau, Mzoughi, & Sutan, 2008).
0.118838 - Despite the significant contributions of this study, it suffers from a number of limitations.
0.123235 - First, this study has used a cross-sectional rather than a longitudinal approach.
0.144113 - This implies that much more emphasis has been placed on observing software piracy rates across nations rather than in observing changes in global software piracy rates.
0.131963 - There would seem to be hence a need for much more longitudinal research to focus on observing changes in software piracy over time.
0.133133 - Second, despite the satisfactory performance of the neuro-computational and EC models in this study, future research might improve the performance of the models used in this study by integrating fuzzy discriminant analysis and genetic algorithms (GA) with neuro-computational models.
0.033149 - Mirmirani and Li (2004) pointed out that traditional algorithms search for optimal weight vectors for a neural network with a given architecture, while GA can yield an efficient exploration of the search space when the modeler has little apriori knowledge of the structure of problem domains.
0.146255 - Finally, future research might use other neuro-computational and EC models’ architectures such as gene expression programming (GEP) to classify and predict software piracy rates across nations.
0.056911 - GEP was first introduced to the genetic programming (GP) community by Ferreira (2001).
0.066451 - Thus, it is the most recent development in the field of artificial evolutionary systems (Ferreira, 2004).
0.065476 - Due to the unsupervised character of their learning algorithm and the excellent visualization ability, GEP models have been recently used in myriad fields.
0.020513 - Examples include particle physics data analysis (Teodorescu & Sherwood, 2008), food processing (Kahyaoglu, 2008), real parameter optimization (Xu, Liu, Tang, Zuo, & Tang, 2009), and chaotic maps analysis (Hardy & Steeb, 2002).
0.000000 - Appendix A A.1.
0.012903 - WinBUGS code used to conduct Bayesian regression model{ for (i in 1:n){ PIR[i] ∼ dnorm(y.hat, tau.y) y.hat <- a + b1 ∗ LnGDP[i] + b2 ∗ SchEnr[i] + b3 ∗ CPI[i] + b4 ∗ ResDev[i] + b5 ∗ Gini[i] + b6 ∗ LAW[i] } a ∼ dnorm(0, 0.0001) b1 ∼ dnorm(0, 0.0001) b2 ∼ dnorm(0, 0.0001) b3 ∼ dnorm(0, 0.0001) b4 ∼ dnorm(0, 0.0001) b5 ∼ dnorm(0, 0.0001) b6 ∼ dnorm(0, 0.0001) tau.y <- pow(sigma.y, −2) sigma.y ∼ dunif(0, 100) } A.2.
0.020147 - SAS code used to conduct Bayesian regression diagnostics Data piracy; INFILE “C:⧹⧹ PiracySAS.txt” DELIMITER = ’09’x; INPUT LnGDP SchEnr CPI ResDev Gini LAW PIR; proc print; run; ods graphics on; procmcmc data = piracy outpost = piracyout nmc = 1000000 NBI = 10000 Diagnostics = Heidel[Raferty] thin = 10 seed = 246810; parms beta0 0 beta1 0 beta2 0 beta3 0 beta4 0 beta5 0 beta6 0; parms sigma2 1; prior beta0 beta1 beta2 beta3 beta4 beta5 beta6 ∼ normal(mean = 0, var = 0.0001); prior sigma2 ∼ uniform(0,1); mu = beta0 + beta1 ∗ LnGDP + beta2 ∗ SchEnr + beta3 ∗ CPI + beta4 ∗ ResDev + beta5 ∗ Gini + beta6 ∗ LAW; model PIR ∼ n(mu, var = sigma2); run; ods graphics off; A.3.
0.035961 - R environment code used to bootstrap R2 in OLS regression > library(boot) > rsq <- function(formula, data, indices){ + d <- data[indices,] + fit <- lm(formula, data = d) + return(summary(fit)$r.square)} > results <- boot(data = piracy, statistic = rsq, R = 10000, formula = PIR ∼ LnGDP + SchEnr + CPI + ResDev + Gini + LAW) > results boot(data = piracy, statistic = rsq, R = 10000, formula = PIR∼ LnGDP + SchEnr + CPI + ResDev + Gini + LAW) > plot(results) A.4.
0.028011 - Rfreak code used to conduct evolutionary computation robust regression > library(RFreak) Loading required package: rJava > LTSevol(piracy[,7], piracy[, 1:6], adjust = TRUE, runs = 1, generations = 1000000) > robreg.evol(piracy[, 1:6], piracy[,7], method = ”lts”, generations = 1000000) > lqsreg.evol(piracy[, 1:6], piracy[,7], generations = 1000000) > lqdreg.evol(piracy[, 1:6], piracy[,7], generations = 1000000) > lmsreg.evol(piracy[, 1:6], piracy[,7], generations = 1000000)

[Frase 5] At the empirical level, this research shows that software piracy is significantly affected by the wealth of nation as measured by gross domestic product (GDP), the nation’s expenditure on research and development and the nation’s judicial efficiency.
[Frase 3] The study remedies previous econometric and methodological shortcomings by applying Bayesian, robust and evolutionary computation robust regression algorithms to formally test empirical literature on software piracy.
[Frase 6] At the methodological level, this research shows that neuro-computational models outperform traditional statistical techniques such as regression analysis, discriminant analysis and cluster analysis in predicting, classifying and clustering software piracy rates due to their robustness and flexibility of modeling algorithms.
