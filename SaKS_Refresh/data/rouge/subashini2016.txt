To suggest a non-invasive method for classification of Astrocytoma through rigorous training and testing. To compare and conclude the best medical image segmentation technique. To develop an efficient automatic feature selection technique for grade identification. To analyze and quantify the performance of classifiers constructed for the grade identification of Astrocytoma (tumor).

0.123016 - Brain tumor grade identification is an invasive technique and clinicians rely on biopsy and spinal tap method.
0.219227 - The proposed method takes an effort to develop a non-invasive method for the tumor grade (Low/High) identification using magnetic resonant images.
0.130617 - The process involves preprocessing, image segmentation, tumor isolation, feature extraction, feature selection and classification.
0.135256 - An analysis on the performance of the segmentation techniques, feature extraction methods, automatic feature selection (SFLA) and constructed classifiers (support vector machines, learning vector quantization and Naives Bayes) is done on the basis of accuracy, efficiency and elapsed time.
0.100000 - This analysis motivates towards the accurate determination of tumor grade from MR images instead of depending on magnetic resonant spectroscopy and biopsy.
0.098173 - Fuzzy c-means segmentation outperformed other segmentation techniques, shape and size based textural feature promoted the demarcation of tumor grades, Naive Bayes classifier succeeded in terms of efficiency, error and elapse time when compared with SVM and LVQ.
0.081016 - The study was carried out with 200 images consisting training set (164 images) and testing set (36 images).
0.113997 - The results revealed that the system is robust and accurate (91%), consumed less time in grade identification, an alternative for biopsy and MRS in the brain tumor grade identification diagnosis procedure.
0.056604 - A brain tumor is an abnormal growth of cells in the brain or the spinal canal which can cause uncontrollable cell division in the brain or in the lymphatic tissue or blood vessels that can prove to be life threatening.
0.072222 - However, brain tumors can be cancerous or benign depending on the rapidity of their growth and nature.
0.085859 - Brain tumors are to be detected at the earliest possible stage and treated before it can prove to be fatal.
0.068841 - The proposed method deals with a unique class of brain tumors namely the Astrocytoma which is malignancy of a type of glial cells called Astrocytes found mostly in the cerebrum of the brain.
0.088780 - There are four types (grades) of Astrocytoma based on the grading provided by the World Health Organization (WHO) which is generally followed internationally.
0.115278 - Pilocytic Astrocytoma is the first type (grade) of Astrocytoma common in children that grows gradually and usually are benign.
0.111111 - Low grade astrocytoma is the second type whose borders are not well defined and they spread rarely to the other parts of the central nervous system.
0.075269 - The third type is the Anaplastic Astrocytoma which invade neighboring tissues and they are not uniform in appearance.
0.053333 - They fall under the high grade Glioma category with poor clinical prognosis.
0.095833 - Glioblastoma multiforme is the most malignant fourth type brain tumor which is very common and tends to grow and spread to other parts of the brain quickly.
0.078947 - Grade I and Grade II form the low grade Glioma brain tumors whereas Grade III and Grade IV form the high grade Glioma brain tumors.
0.150702 - The methodology deals with the classification of Astrocytoma into low grade and high grade Gliomas respectively.
0.093444 - Medical Image analysis for brain tumor detection relies on magnetic resonant images and magnetic resonant spectroscopy in the initial diagnosis procedure.
0.135907 - Recent works on brain tumor grade identification entirely depend on MR images and spectroscopy (Arizmendi, Vellido, & Romero, 2012) methods to promote non-invasive techniques.
0.074561 - (Metwally et al., 2014) has demonstrated that magnetic resonant spectroscopy is a complimentary tool which saves a patient from biopsy to identify the type/grade.
0.079563 - (Luts, Heerschap, Suykens & Van Huffel, 2007) combined MRI with MRS data for the construction of multi classifier system in brain tumor classification based on least squares support vector machines.
0.048246 - Grading of astrocytic brain tumors is also based on gene expression microarray data, which utilized simple artificial neural network as classifier (Petalidis, Oulas, & Backlund, 2008).
0.062500 - Machine learning schemes also supports efficient classification in tumor type identification.
0.051282 - In the investigation made by (Yen & Langari, 2004), (Zhao et al., 2010) (Zacharaki et al., 2012), (El-Dahshan, Mohsen, Revett & Salem, 2014) the region of interest (tumor) was isolated from MR brain image which was followed by feature extraction.
0.113095 - The predominant features were selected and support vector machines were employed for texture pattern classification.
0.208700 - An efficient method with improved accuracy has to be implemented for the non-invasive tumor grade identification from MR images.
0.087121 - The existing method (Zacharaki et al., 2009), provide 88% of accuracy with 102 brain images: The procedure involved: ROI definition (software package FSL), feature extraction (Gabor), feature selection (Ranking Selection) and classification (SVM).
0.000000 - Fig 1.
0.250518 - Non-invasive procedure for the grade discrimination of astrocytoma (tumor).
0.093472 - We propose an expert system to improve the accuracy based on ROI definition (FCM & Watershed segmentation), feature extraction (GLCM, PCA and statistical methods), optimized feature selection (Shuffling Frog Leaping Algorithm) and classification (SVM, LVQ and Naive Bayes).
0.229853 - Motivation The proposed non-invasive method involves grade identification of Astrocytoma (tumor) from MR images.
0.090909 - MR images is efficient in the detection of tumor because of its high contrast, high spatial resolution and less radiation.
0.151961 - Magnetic resonant images provide information about the size and location of tumor but unable to classify the type/grade of tumor.
0.059511 - Hence clinicians proceed towards invasive methods in which biopsy and spinal tap methods are painful and time consuming.
0.118280 - This inability motivated us towards the development of an expert system to improve the diagnostic ability of MRI.
0.119565 - Moreover, there is no need to go for a biopsy at the earliest stage as the aim of this method is to classify the tumors with the help of the MR images alone.
0.088889 - The analysis began with the isolation of tumor (region of interest) using segmentation methods (Section 2.3).
0.137214 - The segmented tumor image is now subjected to feature extraction (Section 2.4), automatic feature selection (Section 2.5) and classification (Section 2.6) of features.
0.078431 - The results (Section 3) proved that the method is accurate in grade demarcation since the ROI is considered for evaluation procedure.
0.078125 - The developed automated system, assist premier diagnosis and it is efficient in provision of quick results in clinical outcomes.
0.205610 - The proposed scheme is highlighted in Fig 1 to comprehend the procedure involved in the non-invasive method of grade identification of Astrocytoma.
0.086022 - Image database An MR scan or CT scan can provide a picture of the anatomy of the brain.
0.087647 - MR scanned image is taken for the entire process implemented.
0.000000 - MR scan is more sensitive than CT.
0.116632 - It is non-invasive and has little exposure to radiation.
0.042735 - There are three types of MR image scans, namelyT1 weighted MRI (gray matter (dark gray) and white matter (lighter gray) tissues are efficiently contrasted), T2 weighted MRI (gray matter (lighter gray) and white matter (darker gray)) and PD weighted MRI (The gray (bright) and white (darker gray) matter is differentiated with little contrast between brain and CSF).The proposed method utilized 200, T2 weighted images.
0.089975 - Training set consisted of 164 images (82-low grade & 82-high grade) and testing set consisted of 36 images (18-low grade and 18-high grade).
0.059524 - Pre-processing The medical data used is magnetic resonant head data carrying information on Astrocytoma.
0.091398 - The data is obtained from a diagnostic lab and consists of abnormal MR brain images of human volunteers.
0.101190 - The imaging modalities and artefacts are to be removed and hence subjected to pre-processing.
0.080645 - The conventional methods of resizing and filtering are substituted using pulse coupled neural network and a median filter.
0.066667 - Pulse coupled neural network Removal of noise from the image is an important factor in image processing.
0.063063 - The PCNN network (Subashini & Sahoo, 2014) can be used to achieve this as filtering of noise will always help in getting more accurate result.
0.060976 - The advantage of this network is that it removes only the noisy pixels without disturbing the other pixels and thus the relevant details and the edges are preserved.
0.088542 - The noise is pin pointed and filtered based on the spatial information and time information of the original image.
0.085574 - A median filter is used in conjunction with PCNN to remove common noise occurring in medical images like the Binary or salt and pepper noise (Wen & Wen, 2013).
0.111342 - Tumor segmentation and isolation Image segmentation is the process of dividing a digital image in to multiple segments that have a strong correspondence with original image.
0.067825 - There are numerous types of segmentation techniques are available such as threshold based segmentation, edge based segmentation, region based segmentation and clustering based segmentation.
0.134804 - The segmentation methods applied for tumor isolation in this grade identification process is discussed in Sections 2.3.1 and 2.3.2.
0.048077 - Fuzzy c-means segmentation Fuzzy c-means clustering is the best known unsupervised clustering algorithm.
0.100000 - It is generally used to find the interesting patterns or groups of data from the given set.
0.065657 - This form of clustering is often used to segment images where pixels are partitioned into regions corresponding to different objects.
0.087302 - The fuzzy c-means algorithm allows a point in an image or given set of data to belong to multiple clusters thus producing a soft partition of the dataset.
0.047009 - A set of clusters are well separated when any two points in a cluster are closer than the shortest distance between two clusters in different clusters.
0.076667 - In order to do the partition of clusters, an objective function Jm is used which is shown in Eq (1) (1) where ‘P’ is a fuzzy partition of the dataset X formed by C1, C2,…,Ck clusters.
0.043011 - Parameter ‘m’ is a weight that determines the degree with which the partial clusters affect the clustering result.
0.071429 - ‘vi’ minimizes the objective function to find a good partition where‘’that minimize Jm further.
0.047619 - The FCM theorem states that a constrained fuzzy partition [C1, C2,….Ck] can be a local minimum of the objective function Jm only if the following conditions in Eqs.
0.097826 - (2) and (3)are satisfied: (2) (3) The fuzzy c-means segmentation is carried out to cluster and the pixels are grouped together to get the desired segments of tumor (Yen & Langari, 2004).
0.069892 - Edge-based segmentation method Edge-based segmentation is the segmentation method based on the edge in an image.
0.111111 - The proposed method applies edge detection before segmentation for tumor isolation.
0.047619 - Few edge detection methods are median filter, gradient operators and Hilbert transform (Nixon & Aguado, 2008).
0.023810 - Watershed segmentation algorithm Gray scale digital image is considered as topographic surface in watershed segmentation.
0.074074 - The segmentation is based on the intensity and pixels are grouped with similar intensity.
0.131944 - This is a better way to segment the tumor from image.
0.115385 - Few morphological operations are performed to isolate the tumor region from the image.
0.066092 - If the image is a 3D topographic image, x and y denote the coordinate plane and z, the pixel value, then M1, M2, ...., MR is the regional minima of an image g(x, y), which is the pixel of coordinate (x, y) (Vincent & Soille, 1991).
0.054264 - C(Mi)is the catchment basin coordinate associated with Mi that is flooded at stage n and T[n] is the set of coordinates (s,t) given by Eq (4).
0.107527 - (4) The maximum pixel of g(x,y) is calculated and the minimum pixel is assigned to Mi.
0.030303 - The topography will be flooded from n=min+1.
0.087246 - Eq (5) denotes the catchment basin for the co ordinate (s,t).
0.034483 - If (x, y) ∈ C(Mi)and at location (x,y) Otherwise as shown in Eq (5).
0.039007 - (5) C[n], union of the flooded catchment basin is given in Eq (6) (6) Let n = n+1, the set of connected components Q is calculated from T[n] as per Eq (4).
0.072917 - For everyq ∈ Q[n], there are three conditions which are mentioned below • If is empty, then q is incorporated in to C[n–1] to form C[n] and it shows the calculated new minimum.
0.060284 - • If contains one connected component of C[n–1], then q is incorporated in to C[n–1] to form C[n], which shows q is within the catchment basin of some regional minimum.
0.041667 - • If contains more than one connected component of C[n–1], it shows that a ridge is found which divides the catchment basin.
0.086957 - The points of ridges are calculated and set as dam.
0.000000 - Eqs.
0.065476 - (4) and (5) are repeated to calculate C[n] until n reaches to max+1.
0.051282 - Feature extraction Feature extraction is a unique form of dimensionality reduction i.e.
0.125000 - transforming the input data in to a specific set of features.
0.102151 - Large amount of data is needed to represent a single image which occupies large memory and time consuming.
0.111111 - So, the features are extracted in order to reduce the data, memory and time.
0.141560 - The extraction techniques are different for the textural, intensity and shape based features.
0.093137 - Fig 2 shows shape, texture and intensity based features, which describe the types of features that are extracted from tumor images.
0.000000 - Fig 2.
0.070175 - Shape, texture and intensity based features.
0.040230 - Textural features: gray level co-occurrence matrix The textural features, which represent the surface or structure, are calculated by converting the MR images into Gray Level Co-occurrence Matrices (GLCM) which is based on the repeated recurrence of some gray level configuration in the texture.
0.047619 - This configuration varies with the distance rapidly in fine textures and slowly in coarse textures.
0.055556 - Since the segmented images show a sharp change in textures, the features obtained after the segmentation provide a significant variation among the various parameters calculated from the GLCM values.
0.023810 - GLCM is a way of extracting second order statistical textures defined as Haralick's texture descriptors namely Angular Second Moment (ASM), entropy, autocorrelation, dissimilarity, maximum probability, inverse difference etc.
0.114035 - In a GLCM, the number of rows and columns is equal to the number of gray levels, G in a given image (Sasikala & Kumaravel, 2007).
0.000000 - Table 1.
0.063492 - GLCM based feature extraction on low grade images.
0.000000 - Sl.
0.000000 - no.
0.000000 - Contrast Dissimilarity ASM Entropy Max probability Inverse idm Area 1 0.7 0.1 1.0 0.1 1.0 1.0 1.0 295.0 2 0.1 0.0 1.0 0.1 1.0 1.0 1.0 244.0 3 0.1 0.0 1.0 0.1 1.0 1.0 1.0 374.0 4 0.1 0.0 1.0 0.1 1.0 1.0 1.0 149.0 5 0.1 0.0 1.0 0.1 1.0 1.0 1.0 235.0 6 0.0 0.0 1.0 0.1 1.0 1.0 1.0 242.0 7 0.1 0.0 0.9 0.1 1.0 1.0 1.0 345.0 8 0.1 0.0 1.0 0.1 1.0 1.0 1.0 218.0 9 0.1 0.0 0.9 0.1 1.0 1.0 1.0 328.0 10 0.0 0.0 1.0 0.0 1.0 1.0 1.0 145.0 Table 2.
0.063492 - GLCM based feature extraction on high grade images.
0.000000 - Sl.
0.000000 - no.
0.011111 - Contrast Dissimilarity ASM Entropy Max probability Inverse idm Area 1 0.1 0.0 0.9 0.2 1.0 1.0 1.0 486.0 2 0.1 0.0 0.9 0.2 1.0 1.0 1.0 387.0 3 0.1 0.0 0.9 0.2 1.0 1.0 1.0 640.0 4 0.1 0.0 0.9 0.2 1.0 1.0 1.0 424.0 5 0.7 0.0 0.9 0.2 1.0 1.0 1.0 357.0 6 0.1 0.0 0.9 0.1 1.0 1.0 1.0 303.0 7 0.1 0.0 1.0 0.1 1.0 1.0 1.0 442.0 8 0.0 0.0 1.0 0.5 1.0 1.0 1.0 263.0 9 0.1 0.0 0.9 0.2 0.9 1.0 1.0 395.0 10 0.1 0.0 0.8 0.3 0.9 1.0 1.0 447.0 Manually, seven features were chosen and computed using the GLCM method listed out and are represented in Eqs.
0.000000 - (7–13).
0.089744 - Contrast: it is a measure of the local intensity variation in an image.
0.000000 - (7) 2.
0.079365 - Dissimilarity: the measure of dissimilarity between the pixels.
0.000000 - (8) 3.
0.089744 - Angular Second Moment (ASM): it is the measure of homogeneity of an image.
0.030303 - It usually provides relatively high values in the GLCM.
0.000000 - (9) 4.
0.013333 - Entropy: homogeneous images have higher entropy where as inhomogenities has low entropy.
0.000000 - (10) 5.
0.000000 - Maximum Probability (MP) (11) 6.
0.080000 - Inverse Difference Moment (IDM): it is the local homogeneity of the image.
0.092593 - It has higher values for homogeneous images and lower values for non homogeneous images.
0.000000 - (12) 7.
0.085357 - Inverse: it can be computed from (13) The features computed (Joshi & Rana, 2010) from the matrix showed varying differences with respect to both the Grades are tabulated in Tables 1 and 2.
0.051282 - Non-textural features: area calculation The only other non-textural feature i.e.
0.104762 - the area of tumor was calculated by removing the unwanted portions of the segmented image through morphological operations like erosion and dilation.
0.114035 - The isolated tumor portion was subjected to Sobel's edge detection and then the calculation of area (Tables 1 and 2) in terms of pixels.
0.022222 - Sobels's edge detection is a discreet differentiation operator which plays a vital role in image processing.
0.100000 - It gives an approximation of the gradient of the image intensity function.
0.067901 - It's based on convolution of a 3×3 mask with the original image.
0.014493 - It can detect edges quite efficiently (Sonka, Hlavac, & Boyle, 2008).
0.071429 - Principle component analysis (PCA) Principle Component Analysis is the process of extracting the principle features.
0.000000 - It is based on orthogonal transformation i.e.
0.106667 - converting the set of correlated variables in to set of uncorrelated variable.
0.083333 - Here, the correlated variable is the segmented image and the uncorrelated variable is the features which are principle components.
0.068966 - The lower dimensional feature vectors are estimated from the original data set by means of PCA.
0.066667 - represents the n × N matrix, where each and every ‘x’ is the n dimensional face vector, from a p × q face image.
0.066667 - ‘n’ is the total number of pixels in the given image (p x q) (Rathi & Palani, 2012).
0.058712 - PCA is the linear transformation of image in to a feature vector, shown in Eq (14) (14) Where Y is the m x n feature vector matrix, `m' is the feature vector dimension and W is the `n x m' transformation matrix, and the eigen vectors are the column of W. The `m' largest eigen vector can be calculated from the Eq (15) (15) where ‘ei’ and ‘λ’ are eigenvectors and eigen values of the matrix.
0.070513 - The total scatter matrix ‘S’ and the mean value ‘µ’ are given in Eqs.
0.062500 - (16) and (17).
0.041667 - (16) (17) The transformed feature vector is WTSW after linear transformation.
0.072464 - The projection Wopt is to maximize the determinant of the scatter matrix in Eq (18) (18) where ‘w’ is the set of eigen vector of ‘S’ corresponding to the ‘m’ largest eigen values.
0.090909 - In this the given input image is ‘n’ dimensional that is reduced to ‘m’ dimensional feature vector and the reduced ‘m’ feature vector is less than the original ‘n’ image vector.
0.000000 - Table 3.
0.097222 - Texture, shape and intensity based feature extraction on low grade images.
0.000000 - Sl.
0.000000 - no Entropy Mean Moment Skewness Variance Area Std deviation Histogram Eigen vector 1 4.6 202 55 11.5 55 336 111 106 −100.2 2 4.2 173 69 8.2 69 530 122 104 −100.2 3 4.7 172 90 8.9 90 538 114 121 −72.51 4 4.3 153 141 9.6 1429 630 124 157 −72.5 5 3.6 207 331 11.9 332 681 96 261 −72.15 6 3.6 173 377 12.2 379 685 116 282 −52.69 7 4.2 177 431 11.7 432 882 113 298 −44.75 8 4.6 127 322 8.1 323 954 120 186 −44.02 9 4 188 351 9.5 352 1035 109 248 −31.08 10 4.2 152 529 9.5 530 1075 98 290 −30.88 Table 4.
0.097222 - Texture, shape and intensity based feature extraction on high grade images.
0.000000 - Sl.
0.000000 - no Entropy Mean Moment Skewness Variance Area Std deviation Histogram Eigen Vector 1 4.3 169 4135 12.5 4150 2534 117 177 −105.73 2 4.2 129 10276 9.4 10316 2555 124 1128 −51.694 3 3.7 179 999 11.1 1002 2664 112 444 −44.756 4 3.5 184 3095 11.3 3107 2695 111 947 −0.0475 5 3.9 187 2535 14.4 2544 2801 110 781 −0.0454 6 4 187 38846 13.9 38988 3336 109 3029 −0.0365 7 3.7 160 54074 12.9 54286 3457 120 3461 −0.0318 8 4.2 167 5154 12.2 5173 3505 118 1043 −0.03 9 3.8 175 65750 14 66007 3909 116 784 −0.0298 10 4.5 149 1204 9.2 1208 3923 122 400 −0.0226 2.5.
0.119895 - Feature selection Feature selection is the process of selecting the redundant feature for the classifier that can be tremendously useful in reducing the dimensionality and execution time of the data to be processed.
0.079191 - It is mainly useful in data analysis process, as it shows which feature is more important for grade prediction and how these features are related.
0.073333 - The textural and non-textural features are tabulated in Tables 1–4.
0.080000 - Shuffling Frog Leaping Algorithm is applied for selecting the most predominant feature.
0.066667 - Shuffling frog leaping algorithm (SFLA) The SFLA combines the benefits of both Genetic based memetic algorithms and Social behavior based PSO algorithms.
0.069444 - SFLA generate better results than the Genetic algorithm (Rouhi, Jafari, Kasaei, & Keshavarzian, 2015) in terms of efficiency and effectiveness (Elbeltagi, Hegazy & Grierson, 2005).
0.051724 - In this, the entire populations of frogs are dispersed within a different subset called a Memeplex.
0.034314 - Different memeplexes are considered as a different culture of frogs, each performing local search (Niknam, Rasoul Narimani, Jabbari & Reza Malekpour, 2011).
0.063492 - The extracted features are the initial population set.
0.065476 - (1) Initial population: For an S dimensional problem, initial population of ‘P’ frogs is created.
0.060897 - A frog is represented as in Eq (19) (19) (2) Sorting and distribution: Based on the fitness value, frogs are sorted in descending order, then the whole population is partitioned in to ‘m’ memeplexes, each contains ‘n’ frogs (mxn).
0.063063 - The first frog belongs to the first Memeplex; the second frog belongs to the second Memeplex;‘m’ frog is belongs to the ‘m’ memeplex.
0.079710 - The memeplexes are the various textural and non-textural parameters.
0.043329 - (3) Memeplex evolution: Frogs with the best and the worst fitness are identified as Xb and Xw and the frog with the global fitness is identified as Xg (Yang, Chuang, Ke, & Yang, 2008).Change in frog position is as per Eqs.
0.062500 - (20) and (21).
0.043478 - (20) (21) ‘rand’ is random number between 0 and 1.
0.073836 - The maximum change in position is defined by Dmax and it replaces the worst frog, if this generates the better solution.
0.000000 - If Eqs.
0.058824 - (20) and (21) do not replace the worst frog, then the change in position is given by (22) (22) If Eqs.
0.053571 - (20) and (22) do not provide better solution, then a new solution is randomly generated.
0.080645 - (4) Shuffling: Within each memeplexes, the individual frogs hold ideas and evolve through the process of memetic evolution.
0.033333 - After a defined number of memetic evolution steps, ideas are passed among memeplexes in a shuffling process.
0.061111 - (5) Terminal condition: The local search and the shuffling processes continue until defined convergence criteria are satisfied.
0.138357 - The parameter that shows best demarcation among themselves is chosen for classification/determination of tumor grade.
0.128175 - Classification of tumor The method proposes a linear classification of features into low grade an high grade.
0.126914 - Support Vector Machines (SVM), Learning Vector Quantization (LVQ) and Naives Bayes are efficiently used in the process of grade identification.
0.080460 - Support vector machine (SVM) SVM are linear machines used for pattern classification and non-linear regression.
0.095960 - A hyperplane is constructed which acts as a decision base to create a margin between the positive and negative samples.
0.079365 - The main goal is to maximize this margin.
0.069444 - Various theories of statistical learning are used to achieve this property.
0.068607 - Since SVM implements a method of minimizing structural risk, it provides a good generalization performance of pattern classificationproblemsinspite the fact that problem-domain knowledge is lacking.
0.096774 - This property is very much unique to SVM and thus it has an advantage over other conventional classifiers.
0.080460 - The support vectors have a small set of training data which is obtained by the algorithm.
0.063725 - Learning machines are constructed depending on the inner product kernel and characterized by decision surfaces of their own (Bauer & Nolte, 2011).
0.126096 - A linear classification of data is required for the grade identification (low/high), a linearly separable optimal hyperplane, ‘x’ is built which is expressed in Eq (23).
0.066092 - (23) where, ‘ xp’ is the nominal projection of ‘x’ onto the hyperplane, ‘r’ is the desired algebraic distance and ‘wo’ is the optimum value of the weight vector used to find the separation between the closest data points called the margin of separation denoted by ρ.
0.134409 - The optimal hyperplane is found which lead to the construction of a support vector machine for pattern recognition.
0.028986 - Moreover, the inner product kernel is defined by Eq (24).
0.085366 - (24) where, ϕT(x)ϕ(xi) represents the inner product of the two vectors induced in the feature space by ‘x’ and ‘xi’ corresponding to the ‘i’th sample.
0.101190 - The inner product kernel is used to construct the optimal hyperplane in the feature space.
0.062500 - With the help of the optimal hyperplane, we can construct a support vector machine as given by Eq (25).
0.098958 - (25) where, is the training sample and the Lagrange multipliers are used to maximize the objective function (Haykin, 2003).
0.093137 - Learning vector quantization (LVQ) The LVQ network is a hybrid network which uses supervised and unsupervised learning techniques to form classifications.
0.075000 - It consists of a number of neurons in each layer where each neuron in the first layer is assigned to a single neuron in the second layer.
0.083333 - S1 is the number of neurons in the first layer and S2 is the number of neurons in the second layer.
0.000000 - S2 will usually be larger than S1.
0.094248 - Each neuron in the first layer of the LVQ learns a prototype vector and thus the classification of the region of the input space is done.
0.064815 - Unlike SVM where the input and the weight vector proximity are computed using an inner product, LVQ functions by computing the distance directly.
0.066667 - Thus it prevents the normalization of vectors.
0.076923 - The input of the first layer of LVQ is given by Eq (26).
0.059140 - (26) where, ‘n’ is the net input, ‘w’ is the weight vector and ‘p’ is the vector prototype.
0.061111 - The second layer of the LVQ network concatenates the subclasses into one class with a W2 matrix.
0.111111 - A set of examples of proper network behavior are required for training the network.
0.047619 - This task is achieved by the training matrix.
0.101626 - Each neuron in the first layer is assigned to an output neuron after which the learning occurs and this process helps in the generation of a W2 matrix.
0.055556 - All elements of W2 are made zero except if a hidden neuron I can be assigned to class K, then .
0.088542 - The hidden weights of W1 are trained using the Kohonen rule and the network is shown in Fig 3.
0.067901 - LVQ network showing the neuron layers and the input layer (Hagan, Demuth & Beale, 2002).
0.000000 - Fig 3.
0.057292 - LVQ network showing the neuron layers and the input (Martin T.Hagan, Howard B. Demuth and Mark Beale, 2008).
0.136111 - Naive Bayesian classification The Bayesian classification is a supervised learning method in addition to the statistical method for classification.
0.086667 - It provides a useful outlook for understanding and evaluating many learning algorithms.
0.108696 - It computes precise probabilities for hypothesis and robust to noise.
0.080645 - The main advantage of this method is that, it requires only a small amount of training data set.
0.022222 - A Naive classifier is a simple probabilistic classifier based on Baye's theorem with strong independent assumptions.
0.086667 - The network is trained efficiently by the nature of the probability model.
0.027778 - It is mainly suited when the input dimensionality is too high.
0.066667 - The training data are accompanied by labels indicating the class of the observations and the new data is classified based on the training set (John & Langley, 1995).
0.074074 - The probability model for a classifier is a conditional model shown in Eq (27).
0.078947 - (27) where C is the dependent class variable with a small number of classes, F1 through Fn are features, n is the number of features.
0.076923 - If the number of features is large, then the probability table is infeasible.
0.099732 - The Baye's theorem is given below in Eq (28), (28) The above Eq (28) can be simplified as Eq (29) (29) Since the proposed method is an alternative for invasive methods, a thorough analysis has been done with image segmentation, feature extraction and classification techniques to choose the best technique with improved accuracy.
0.087719 - This section describes in detail, the design of each technique and also gives the algorithms and programming methodologies used in each stage of the work.
0.116846 - The grade identification procedure dealt with the segmentation of MR images using fuzzy c-means based clustering and water shed, followed by extraction of textural and non-textural based features.
0.000000 - Area is calculated after edge detection.
0.109812 - The selected features are used for classification using SVM, LVQ and Naive Bayes algorithms and the process is depicted in Fig 4.
0.130065 - Astrocytoma grade identification procedure.
0.000000 - Fig 4.
0.130065 - Astrocytoma grade identification procedure.
0.065789 - Image pre-processing The following algorithms are used to implement the image pre-processing Step 1: Start Step 2: Convert the image into gray scale image Step 3: Resize the image to 512×512 Step 4: De-noise the image using a PCNN based median filter Step 5: End Fig 5(a and b) depicts the original and preprocessed low grade astrocytoma image.
0.135076 - This process of resizing, enhancing the quality of image is applied for the training and testing images (164- testing set, 36- training set).
0.000000 - Fig 5.
0.074074 - (a) Low grade Astrocytoma original image (b) Low grade pre-processed image 3.2.
0.079386 - Image segmentation Segmentation is a challenging task since the region of interest needs to be fixed ignoring grey matter, white matter, cerebrospinal fluid without losing valuable information.
0.089286 - The results are depicted in Fig 6 conversion of original image to edge detected image.
0.000000 - Fig 6.
0.043478 - (a) Original image (b) Segmented image (c) Edge detected image.
0.095238 - Conversion of original image to edge detected image.
0.043860 - FCM based segmentation A three-class fuzzy segmentation algorithm (Yen & Langari, 2004) is carried out to segment the tumor Step 1: Start Step 2: Define a function F, giving the dataset, the number of clusters and the weight as the input Step 3: Define a variable which represents the termination tolerance and variable I =0, 1, 2… Step 4: Repeat for all I Step 5: Calculate the cluster prototypes using Eq (3) of Section (2.3.1) Step 6: Compute the distances between the dataset elements and the prototype elements Step 7: Update the partition matrix U by computing the membership function using the Eq (2) of Section (2.3.1) if 1 ≤ k ≤ N. Step 8: Otherwise, set the membership function to zero Step 9: Repeat until ||Ul-Ul-1|| is less than the termination tolerance Fig 7.
0.052632 - Graphical representation of features: Top left
0.000000 - Step 10: End 3.2.2.
0.059524 - Water shed segmentation The steps involved in the watershed segmentation are given below: Step 1: The image is loaded and converted in to gray scale image Step 2: The gradient magnitude is calculated which is used as a segmentation function Step 3: The foreground objects are marked and the background markers are computed Step 4: The watershed transform of the gradient magnitude is calculated Step 5: After watershed transform some morphological operations are applied for segregate the tumor from the segmented image 3.2.3.
0.091270 - Tumor isolation The following algorithm describes the use of morphological operators to isolate the tumor by removing the unwanted portions and by enhancing the required portions (Nixon & Aguado, 2008).
0.063131 - Step 1: Start Step 2: Read the segmented image Step 3: Use the command imerode() for eroding the unwanted portions Step 4: Use the command imdilate() for dilating certain parts of the tumor Step 5: Repeat Step 3 and Step 4 until the tumor is isolated completely Step 6: End 3.2.4.
0.045000 - Algorithm for area calculation Step 1: Start Step 2: Compute the number of rows and columns of pixels the image Step 3: initialize a variable area Step 4: Start for (i= 1: no of rows) Step 5: for (j=1: no of columns) Step 6: if, the pixel values come within the edge detected area, increment area by 1 Step 7: else, increment area by 0 Step 8: Display area Step 9: List out the area along with the texture based features Step 10: End 3.3.
0.114583 - Feature extraction Texture based feature, non-textural (shape) features and intensity based features are calculated for training the classifiers.
0.098039 - The algorithm for each of the feature extraction techniques is given below in the Sections (3.3.1)–(3.3.3).
0.058761 - Texture based feature extraction Step 1: Start Step 2: Read the images with the isolated images Step 3: Construct the Gray Level Co-occurrence Matrix for the image Step 4: Using the values from the matrix, compute the features using Eqs.
0.114238 - (7)– (13) of Section 2.4.1 Step 5: List out the features for all the 200 images (both training and testing) Step 6: End 3.3.2.
0.048387 - Shape based feature extraction Step 1: Start Step 2: Read the images with the isolated tumor Step 3: Using Sobel's edge detection operator, detect the edge of the isolated tumor Step 4: From the edge detected image, calculate the area of the tumor in pixels 3.3.3.
0.025758 - Intensity based feature extraction Principle component analysis is performed by using the following steps: Step 1: The mean value is calculated from the given data Step 2: The new matrix A is computed by subtracting the mean from the data S Step 3: The covariance matrix is calculated from the new matrix A Step 4: The eigen values (V1V2V3....VN) and vectors are derived from the covariance matrix C and the eigen vector is also calculated from the data set S Step 5: From the large eigen values, a low dimension data set is created 3.4.
0.131151 - Feature selection If the extracted features are directly applied as an input to the classifier, the accuracy of the classifier is poor and it took more time for processing.
0.105432 - To overcome this problem, feature selection is applied to select the most discriminate feature.
0.086310 - Fig 7 Graphical Representation of Features: Top left- Area, Top right-Variance, Bottom left-Standard Deviation and Bottom right-Eigen Vector, exhibiting the difference between feature values of low grade and high grade Astrocytoma out of which the most predominant feature is chosen for classification.
0.093496 - From these graphs, we conclude that among these nine features, ‘Area’ is the prominent feature that shows a clear demarcation between low grade and high grade astrocytoma images.
0.041667 - The steps followed in Shuffling Frog Leaping Algorithm: Step 1: Initially the population P is generated, that is the entire feature is taken as a population Step 2: The fitness function (I) of population P is calculated Step 3: The population P is sorted in descending order for easy access Step 4: The entire population is divided into m memeplexes Step 5: The local search is performed Step 6: After a specific number of iteration, memeplexes are shuffled among.
0.073836 - Step 7: The best solution is generated if the criteria are satisfied; otherwise the algorithm goes to Step 3 3.5.
0.092356 - Classification The approach implements three classifiers, SVM ( Kumar, 2008), LVQ and Naive Bayes to classify the grades and the algorithms are as follows in Sections (3.5.1)–(3.5.3) 3.5.1.
0.045105 - Support vector machines (SVM) Step 1: Start Step 2: Obtain a linearly separable set Sand obtain its size Step 3: Initialize a threshold for checking the support vectors Step 4: Initialize and setup a Hessian Matrix Step 5: Find the ones of the vectors Step 6: Initialize the parameters for the optimization problem Step 7: Use a standard ‘qp’ function for quadratic optimization to obtain the Legranges multipliers vector Step 8: Find the support vector indices and the number of support vectors Step 9: Find the optimal bias by averaging all the support vectors Step 10: Obtain the classification from the decision region calculations using the support vector indices, the Legrange multiplier vector and the optimal bias Step 11: Display the classification Step 12: End 3.5.2.
0.030797 - Learning vector quantization (LVQ) Step 1: Start Step 2: Initialize the reference weight vectors Step 3: Start for, every input vector Step 4: Calculate the Euclidian distance between the reference weights and the data points Step 5: Find the vectors with the minimum Euclidian distance Step 6: Push the vector towards the input vector if the sample is correctly classified Step 7: If not, push the vector away from the input vector Step 9: Reduce the learning rate accordingly.
0.093750 - Step 10: Repeat Step 5 to Step 9 for all the vectors considered Step 11: End 3.5.3.
0.056106 - Naive Bayes classifier The classifier algorithm is based on the following steps: Step 1: The training data set is created for both low grade and high grade images which contains ‘Area’ as the feature and its corresponding labels Step 2: The probability of corresponding classes is calculated Step 3: The area of the testing image is calculated Step 4: Based on the area, the probability of low grade and high grade is calculated Step 5: From the greatest probability the tumor grade is identified and displayed 3.6.
0.109756 - Efficiency calculation This section describes the algorithm to compute the efficiency and elapse time for all three classifiers discussed in the Sections (3.5.1)–(3.5.3).
0.053640 - Step 1: Start Step 2: Store each of the classification result in a variable ans Step 3: Initialize another variables, tt = 0, k = 0, l = 0 Step 4: Subtract tt from ans and store it as E Step 5: Start fork=1: the number of test images Step 6: Start ifE(k)==0 Step 7: Increment l by one Step 8: End if Step 9: End for Step 10: Display efficiency as (l/no.
0.066667 - of test images)*100 Step 11: End
0.031746 - MR images offer limited information on tumor characterization.
0.104167 - This information concentrates more on texture and size of the tumor.
0.172872 - An attempt was made to develop a non-invasive grade identification system based on textural non-textural, intensity and shape based features.
0.170833 - In this regard, the evaluation of this approach critically suggested the following: fuzzy c-means segmentation performed was found to be a better solution for the grade identification of medical images compared to its counterpart, watershed segmentation.
0.106667 - The results obtained for each type of segmentation is shown by Figs.
0.062500 - 8 and 9.
0.095960 - Results showed that shape based features are of utmost relevance and thus the computation of area helped in efficient classification.
0.103874 - Area was a major factor because, the grade of the tumors depended immensely on their size.
0.085714 - Thus, Area was found to have much demarcation between the two Grades, compared to other features as displayed in Tables 1–4.
0.068607 - Moreover, it was observed that while some features displayed significant demarcation between the Grades, other features overlapped with each other and thus showed poor classification results.
0.062500 - Fig 7 represents the plots of some features showing a variation (Top Left and Top Right) and some features depicting minimum variation (Bottom Left and Bottom Right).
0.079365 - Pre-dominant features are important for accurate classification.
0.062500 - The features could be selected either manually or by automatic means.
0.072072 - The latter showed more accurate results that the former as it used the Shuffling Frog Leaping Algorithm (SFLA) to select the most discriminant feature.
0.072464 - The output of the SFLA is shown in Fig 10.
0.000000 - Fig 8.
0.129630 - Images showing the original image, the enhanced image, FCM segmented image and the isolated tumor image for low grade and high grade Astrocytoma.
0.000000 - Fig 9.
0.122807 - Images showing the original image, the enhanced image, Watershed segmented image and the isolated tumor image for low grade and high grade Astrocytoma Fig 10.
0.000000 - Screenshots from Matlab, revealing Shuffling Frog Leaping Algorithm output.
0.100289 - Table 5 lists out the results obtained from after classification of the 36 testing images using SVM, LVQ and Naive Bayes classifiers.
0.107069 - Results show that SVM and LVQ classifiers constructed could be used for bulk image classification, whereas the Naive Bayes classifier classified one image at a time.
0.102837 - Further, the efficiency of classification (Chart 1) for all the three classifiers showed that LVQ and Naive Bayes classifier exhibited more or less the same accuracy (Chart 2) when compared to the SVM classifier.
0.085366 - The time taken (Chart 3) to classify was more for SVM in comparison with Naive Bayes classifier, which took the least time to classify followed by LVQ classifier.
0.000000 - This is verified by Table 6.
0.098039 - The results were validated by renowned radiologists and physicians and hence we were successful in grading the astrocytoma brain tumors efficiently.
0.000000 - Table 5.
0.083333 - Classification results obtained from the SVM, LVQ and Naive Bayes classifiers.
0.022222 - Image no.
0.003854 - Original grade SVM LVQ Naive Bayes 1 LOW HIGH HIGH LOW 2 LOW LOW LOW LOW 3 LOW LOW LOW LOW 4 LOW LOW LOW LOW 5 LOW LOW LOW LOW 6 LOW LOW LOW LOW 7 LOW LOW LOW LOW 8 LOW LOW LOW LOW 9 LOW LOW LOW LOW 10 LOW LOW HIGH HIGH 11 LOW LOW LOW LOW 12 LOW LOW LOW HIGH 13 LOW LOW LOW LOW 14 LOW LOW LOW LOW 15 LOW LOW LOW HIGH 16 LOW LOW LOW HIGH 17 LOW LOW LOW LOW 18 LOW HIGH HIGH LOW 19 HIGH HIGH HIGH HIGH 20 HIGH HIGH HIGH HIGH 21 HIGH LOW HIGH HIGH 22 HIGH HIGH HIGH HIGH 23 HIGH HIGH HIGH HIGH 24 HIGH LOW HIGH LOW 25 HIGH HIGH HIGH LOW 26 HIGH HIGH HIGH HIGH 27 HIGH HIGH HIGH HIGH 28 HIGH HIGH HIGH HIGH 29 HIGH HIGH HIGH HIGH 30 HIGH HIGH HIGH HIGH 31 HIGH HIGH HIGH HIGH 32 HIGH HIGH HIGH HIGH 33 HIGH HIGH HIGH HIGH 34 HIGH HIGH HIGH HIGH 35 HIGH HIGH HIGH HIGH 36 HIGH HIGH HIGH HIGH Chart 1.
0.107843 - Efficiency of the classifiers.
0.000000 - Chart 2.
0.019608 - Error rate (%) in classification.
0.000000 - Chart 3.
0.069935 - Elapse time of classifiers.
0.000000 - Table 6.
0.107143 - Performance of classifiers.
0.034271 - Type of classifier SVM LVQ Naive Bayes % Efficiency 88.88% 91.67% 91% % Error 11.12% 8.33% 9% Elapse time (s) 0.5286 s 0.1572 s 0.0342 s
0.172027 - The traditional method involves finding the grade of the tumor by manual extraction, segmentation and then a series of tests for grade identification and confirmation.
0.083333 - This process is time consuming and unwanted for a preliminary diagnosis.
0.087647 - Moreover, they are invasive methods, which proved to be chaotic.
0.102521 - The proposed method implemented helps the physician to make an initial diagnosis without adhering to an invasive method.
0.159044 - The process comprised of brain image pre-processing, image segmentation, tumor isolation (ROI), feature extraction, feature selection and classification of selected features to discriminate the grade.
0.083333 - Median Filter and Pulse coupled neural network is applied for image pre-processing.
0.118687 - Fuzzy C Means and water shed are the segmentation techniques utilized.
0.089744 - Sobels's edge detection and morphological operators isolated the tumor from MR image.
0.129032 - The isolated images are subjected to extraction techniques to compute textural, non-textural, shape and intensity based features.
0.053333 - The most predominant parameter is automatically selected using Shuffling Frog Leaping Algorithm.
0.069444 - It combines the benefits of the both the genetic-based memetic algorithm (MA) and the social behavior-based Particle Swarm Optimization (PSO) algorithm.
0.055556 - The most distinguished benefit of SFLA is its fast convergence speed.
0.117284 - The selected feature list or the knowledge base is used to train the classifiers.
0.093750 - SVM, LVQ and Naive Bayes are the classifiers which demarcate data into low grade or high grade Glioma tumors.
0.087302 - The classification accuracy varied from 88 to 91%.
0.126374 - The performance of classifiers implemented showed that LVQ and Naive Bayes are better than SVM.
0.182796 - The efficiency and elapse time of each classifier calculated found to be promising in continuing non-invasive grade identification methods.
0.143723 - A comparative study among segmentation techniques proved that Fuzzy C Means segmentation is the best suitable technique for isolation of any tumor.
0.163317 - The developed method is very much discrete in providing a better means of medical image segmentation and is more suitable for classification of images in bulk.
0.083333 - The research problem focused on identifying the brain tumor grade from MR images.
0.072464 - The major challenge experienced was the preparation of the database.
0.125000 - The header information of the patients was removed, followed by image preprocessing techniques to remove motion artifacts and noise.
0.122222 - MR brain tumor images were collected for all the four grades and the process was time consuming.
0.100000 - The testing set and training set images were segregated into low grade and high grade with the help of radiologists and physicians.
0.086022 - The accuracy of the proposed method can be improved by increasing the number of images in the dataset.
0.161630 - This would definitely improve the efficiency and accuracy of the automated tumor grade identification system.
0.097222 - Segmentation of tumor was time consuming and difficult since the tumor boundary need to be preserved without losing shape and grey level information.
0.094697 - The proposed intelligent system can be further extended in the development of: (1) A clinical decision support system, comprising MRS, MRI and pathological images to automatically diagnose any brain disease/abnormalities.
0.087121 - The information in the database would contribute to the accurate determination of diseases, (2) An Automated brain tumor classification employing probabilistic neural network with image and data processing techniques, (3) A Radiology and computer assisted diagnosis (CAD) systems to aid histopathologists and clinicians in cancer diagnosis and research and (4) A novel method for the extraction of definable objects such as white matter, grey matter, tumour and tumor boundary by preserving its shape and grey level information.

[Frase 4] An analysis on the performance of the segmentation techniques, feature extraction methods, automatic feature selection (SFLA) and constructed classifiers (support vector machines, learning vector quantization and Naives Bayes) is done on the basis of accuracy, efficiency and elapsed time.
[Frase 2] The proposed method takes an effort to develop a non-invasive method for the tumor grade (Low/High) identification using magnetic resonant images.
[Frase 275] In this regard, the evaluation of this approach critically suggested the following: fuzzy c-means segmentation performed was found to be a better solution for the grade identification of medical images compared to its counterpart, watershed segmentation.
[Frase 314] The process comprised of brain image pre-processing, image segmentation, tumor isolation (ROI), feature extraction, feature selection and classification of selected features to discriminate the grade.
